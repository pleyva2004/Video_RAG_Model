{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emilia/.cache/pypoetry/virtualenvs/video-rag-model-_HJFAOPk-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"webdataset\", data_dir=\"ai-lectures-spring-24\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDatasetDict({\n",
      "    train: IterableDataset({\n",
      "        features: ['mp4', 'info.json', 'en.vtt', 'json', '__key__', '__url__'],\n",
      "        num_shards: 1\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDataset({\n",
      "    features: ['mp4', 'info.json', 'en.vtt', 'json', '__key__', '__url__'],\n",
      "    num_shards: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "stream = dataset[\"train\"]\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in stream:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"ai-lectures-spring-24/videos/9CGGh6ivg68/9CGGh6ivg68.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"ai-lectures-spring-24/videos/9CGGh6ivg68/9CGGh6ivg68.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def getTimestamps(vtt_path):\n",
    "    '''Takes in a .en.vtt file path and returns a list of timestamped words'''\n",
    "    word_list = []\n",
    "\n",
    "    with open(vtt_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    first_word_time_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2}.\\d{3}) -->')\n",
    "    timestamp_pattern = re.compile(r'<(\\d{2}:\\d{2}:\\d{2}.\\d{3})><c>([^<]*)</c>')\n",
    "    first_word_pattern = re.compile(r'^([^<]*)<')\n",
    "\n",
    "    first_word_time = None\n",
    "    for line in lines:\n",
    "        first_word_time_match = first_word_time_pattern.findall(line)\n",
    "        if len(first_word_time_match) != 0:\n",
    "            first_word_time = first_word_time_match[0]\n",
    "\n",
    "        timestamp_matches = timestamp_pattern.findall(line)\n",
    "        if len(timestamp_matches) != 0:\n",
    "            first_word = first_word_pattern.findall(line)[0]\n",
    "\n",
    "            word_list.append({\"start\": first_word_time, \"word\": first_word.strip()})\n",
    "            for time_str, word in timestamp_matches:\n",
    "                word_list.append({\"start\": time_str, \"word\": word.strip()})\n",
    "\n",
    "\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = getTimestamps('ai-lectures-spring-24/videos/9CGGh6ivg68/9CGGh6ivg68.en.vtt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:00.719 in\n",
      "00:00:00.919 this\n",
      "00:00:01.120 video\n",
      "00:00:01.880 I\n",
      "00:00:01.959 would\n",
      "00:00:02.159 like\n",
      "00:00:02.320 to\n",
      "00:00:02.480 start\n",
      "00:00:02.760 the\n",
      "00:00:03.000 discussion\n",
      "00:00:03.560 about\n",
      "00:00:03.959 convolutional\n",
      "00:00:04.600 new\n",
      "00:00:04.880 networks\n",
      "00:00:05.319 which\n",
      "00:00:05.400 is\n",
      "00:00:05.600 another\n",
      "00:00:06.399 architecture\n",
      "00:00:07.399 of\n",
      "00:00:07.799 uh\n",
      "00:00:08.000 neural\n",
      "00:00:08.280 networks\n",
      "00:00:08.679 that\n",
      "00:00:08.880 we\n",
      "00:00:09.400 are\n",
      "00:00:09.639 going\n",
      "00:00:09.840 to\n",
      "00:00:10.000 see\n",
      "00:00:10.400 specifically\n",
      "00:00:10.960 kind\n",
      "00:00:11.160 of\n",
      "00:00:11.799 engineered\n",
      "00:00:12.799 uh\n",
      "00:00:12.960 to\n",
      "00:00:13.719 um\n",
      "00:00:14.200 address\n",
      "00:00:14.879 problems\n",
      "00:00:15.360 that\n",
      "00:00:15.559 we\n",
      "00:00:15.679 are\n",
      "00:00:15.879 facing\n",
      "00:00:16.240 in\n",
      "00:00:16.440 computer\n",
      "00:00:16.840 vision\n",
      "00:00:17.160 I\n",
      "00:00:17.240 want\n",
      "00:00:17.400 to\n",
      "00:00:17.520 start\n",
      "00:00:17.880 this\n",
      "00:00:18.359 discussion\n",
      "00:00:19.359 with\n",
      "00:00:19.920 um\n",
      "00:00:20.119 just\n",
      "00:00:20.279 showing\n",
      "00:00:20.600 you\n",
      "00:00:20.760 a\n",
      "00:00:21.240 picture\n",
      "00:00:22.240 and\n",
      "00:00:22.720 uh\n",
      "00:00:23.039 if\n",
      "00:00:23.199 I\n",
      "00:00:23.400 ask\n",
      "00:00:23.680 you\n",
      "00:00:24.680 uh\n",
      "00:00:24.760 to\n",
      "00:00:24.920 tell\n",
      "00:00:25.160 me\n",
      "00:00:25.439 what\n",
      "00:00:25.640 would\n",
      "00:00:25.920 actually\n",
      "00:00:26.240 be\n",
      "00:00:26.480 the\n",
      "00:00:26.720 first\n",
      "00:00:27.240 object\n",
      "00:00:27.640 that\n",
      "00:00:27.720 you\n",
      "00:00:27.920 pay\n",
      "00:00:28.119 attention\n",
      "00:00:28.560 to\n",
      "00:00:29.560 then\n",
      "00:00:30.119 most\n",
      "00:00:30.439 people\n",
      "00:00:30.720 will\n",
      "00:00:31.000 probably\n",
      "00:00:31.400 respond\n",
      "00:00:31.920 to\n",
      "00:00:32.680 with\n",
      "00:00:33.160 yellow\n",
      "00:00:33.559 cab\n",
      "00:00:34.120 and\n",
      "00:00:34.239 it's\n",
      "00:00:34.440 not\n",
      "00:00:34.640 really\n",
      "00:00:34.920 accident\n",
      "00:00:35.360 that\n",
      "00:00:36.079 lot\n",
      "00:00:36.280 of\n",
      "00:00:36.520 cabs\n",
      "00:00:37.239 in\n",
      "00:00:38.239 a\n",
      "00:00:38.320 lot\n",
      "00:00:38.480 of\n",
      "00:00:38.640 capitals\n",
      "00:00:39.200 are\n",
      "00:00:40.200 painted\n",
      "00:00:40.879 uh\n",
      "00:00:41.520 yellow\n",
      "00:00:42.520 U\n",
      "00:00:42.680 and\n",
      "00:00:42.879 of\n",
      "00:00:43.000 course\n",
      "00:00:43.280 that\n",
      "00:00:44.039 attention\n",
      "00:00:45.039 uh\n",
      "00:00:45.160 to\n",
      "00:00:45.399 bright\n",
      "00:00:45.760 colors\n",
      "00:00:46.440 originates\n",
      "00:00:47.199 from\n",
      "00:00:48.199 thousands\n",
      "00:00:48.600 of\n",
      "00:00:48.760 years\n",
      "00:00:48.960 of\n",
      "00:00:49.199 evolution\n",
      "00:00:49.800 where\n",
      "00:00:50.039 people\n",
      "00:00:51.039 are\n",
      "00:00:51.559 of\n",
      "00:00:51.719 course\n",
      "00:00:52.320 trained\n",
      "00:00:52.840 to\n",
      "00:00:53.280 pay\n",
      "00:00:53.520 attention\n",
      "00:00:53.960 to\n",
      "00:00:54.480 uh\n",
      "00:00:54.800 bright\n",
      "00:00:55.160 colors\n",
      "00:00:55.680 which\n",
      "00:00:55.800 are\n",
      "00:00:56.120 typically\n",
      "00:00:57.000 sources\n",
      "00:00:57.399 of\n",
      "00:00:57.600 food\n",
      "00:00:57.879 such\n",
      "00:00:58.079 as\n",
      "00:00:58.559 fruits\n",
      "00:00:59.559 or\n",
      "00:01:00.000 in\n",
      "00:01:00.120 some\n",
      "00:01:00.320 instances\n",
      "00:01:01.239 sources\n",
      "00:01:01.800 of\n",
      "00:01:02.320 uh\n",
      "00:01:02.519 danger\n",
      "00:01:03.199 such\n",
      "00:01:03.440 as\n",
      "00:01:04.239 the\n",
      "00:01:04.439 yellow\n",
      "00:01:05.439 tiger\n",
      "00:01:05.960 that\n",
      "00:01:06.119 is\n",
      "00:01:06.280 coming\n",
      "00:01:06.600 towards\n",
      "00:01:07.320 us\n",
      "00:01:08.320 uh\n",
      "00:01:08.439 so\n",
      "00:01:09.439 kind\n",
      "00:01:09.560 of\n",
      "00:01:09.720 joking\n",
      "00:01:10.200 aside\n",
      "00:01:10.600 I\n",
      "00:01:10.720 think\n",
      "00:01:11.000 you\n",
      "00:01:11.240 can\n",
      "00:01:11.880 um\n",
      "00:01:13.280 associate\n",
      "00:01:14.280 uh\n",
      "00:01:14.520 this\n",
      "00:01:15.000 kind\n",
      "00:01:15.159 of\n",
      "00:01:15.400 image\n",
      "00:01:15.960 with\n",
      "00:01:16.360 the\n",
      "00:01:16.479 following\n",
      "00:01:16.880 kind\n",
      "00:01:17.000 of\n",
      "00:01:17.320 processing\n",
      "00:01:18.320 of\n",
      "00:01:18.960 uh\n",
      "00:01:19.680 various\n",
      "00:01:20.079 kind\n",
      "00:01:20.200 of\n",
      "00:01:20.320 stage\n",
      "00:01:20.720 processing\n",
      "00:01:21.360 that\n",
      "00:01:21.880 that\n",
      "00:01:22.000 is\n",
      "00:01:22.159 been\n",
      "00:01:22.400 going\n",
      "00:01:22.640 on\n",
      "00:01:22.799 in\n",
      "00:01:22.920 your\n",
      "00:01:23.320 brain\n",
      "00:01:24.320 uh\n",
      "00:01:24.600 trying\n",
      "00:01:24.920 to\n",
      "00:01:25.439 uh\n",
      "00:01:25.520 from\n",
      "00:01:25.720 the\n",
      "00:01:25.960 kind\n",
      "00:01:26.119 of\n",
      "00:01:26.320 perception\n",
      "00:01:26.799 system\n",
      "00:01:27.119 that\n",
      "00:01:27.520 embeds\n",
      "00:01:28.520 uh\n",
      "00:01:28.640 into\n",
      "00:01:28.920 it\n",
      "00:01:29.240 that\n",
      "00:01:29.360 we\n",
      "00:01:29.479 have\n",
      "00:01:29.600 embedded\n",
      "00:01:30.119 into\n",
      "00:01:30.320 it\n",
      "00:01:30.520 so\n",
      "00:01:30.840 if\n",
      "00:01:30.960 you\n",
      "00:01:31.079 can\n",
      "00:01:31.320 imagine\n",
      "00:01:31.799 the\n",
      "00:01:32.439 process\n",
      "00:01:33.439 um\n",
      "00:01:33.759 then\n",
      "00:01:33.960 the\n",
      "00:01:34.159 first\n",
      "00:01:34.439 thing\n",
      "00:01:34.640 that\n",
      "00:01:34.799 you\n",
      "00:01:35.159 open\n",
      "00:01:35.439 your\n",
      "00:01:35.680 eyes\n",
      "00:01:36.159 soon\n",
      "00:01:36.280 that\n",
      "00:01:36.439 you\n",
      "00:01:36.520 have\n",
      "00:01:36.680 your\n",
      "00:01:36.840 eyes\n",
      "00:01:37.119 closed\n",
      "00:01:38.040 and\n",
      "00:01:38.159 you\n",
      "00:01:38.320 see\n",
      "00:01:38.600 an\n",
      "00:01:38.799 image\n",
      "00:01:39.159 like\n",
      "00:01:39.799 this\n",
      "00:01:40.799 uh\n",
      "00:01:40.960 then\n",
      "00:01:41.159 the\n",
      "00:01:41.280 brain\n",
      "00:01:41.600 is\n",
      "00:01:41.799 actually\n",
      "00:01:42.759 in\n",
      "00:01:42.920 a\n",
      "00:01:43.360 uh\n",
      "00:01:43.799 first\n",
      "00:01:44.119 few\n",
      "00:01:44.439 milliseconds\n",
      "00:01:45.240 is\n",
      "00:01:46.040 uh\n",
      "00:01:46.159 sampling\n",
      "00:01:46.719 this\n",
      "00:01:46.960 image\n",
      "00:01:47.280 in\n",
      "00:01:47.399 a\n",
      "00:01:47.560 course\n",
      "00:01:48.000 kind\n",
      "00:01:48.159 of\n",
      "00:01:48.560 way\n",
      "00:01:49.560 uh\n",
      "00:01:49.840 and\n",
      "00:01:50.280 uh\n",
      "00:01:50.399 determines\n",
      "00:01:51.159 whether\n",
      "00:01:51.719 we\n",
      "00:01:52.000 have\n",
      "00:01:52.960 uh\n",
      "00:01:53.159 situations\n",
      "00:01:53.719 as\n",
      "00:01:53.920 as\n",
      "00:01:54.079 an\n",
      "00:01:54.240 immediate\n",
      "00:01:54.719 kind\n",
      "00:01:54.880 of\n",
      "00:01:55.040 threat\n",
      "00:01:55.520 or\n",
      "00:01:55.680 a\n",
      "00:01:55.840 source\n",
      "00:01:56.119 of\n",
      "00:01:56.280 food\n",
      "00:01:57.280 and\n",
      "00:01:57.439 then\n",
      "00:01:57.840 very\n",
      "00:01:58.159 quickly\n",
      "00:01:58.640 the\n",
      "00:01:58.799 brain\n",
      "00:01:59.159 switches\n",
      "00:02:00.399 softly\n",
      "00:02:01.640 into\n",
      "00:02:02.640 uh\n",
      "00:02:02.920 objects\n",
      "00:02:03.399 paying\n",
      "00:02:03.680 attention\n",
      "00:02:04.039 to\n",
      "00:02:04.360 objects\n",
      "00:02:04.799 which\n",
      "00:02:04.920 are\n",
      "00:02:05.200 associated\n",
      "00:02:05.759 with\n",
      "00:02:05.920 the\n",
      "00:02:06.119 task\n",
      "00:02:07.039 that\n",
      "00:02:07.240 we\n",
      "00:02:07.439 have\n",
      "00:02:07.960 uh\n",
      "00:02:08.800 we\n",
      "00:02:09.200 we\n",
      "00:02:09.399 we\n",
      "00:02:09.560 have\n",
      "00:02:10.000 to\n",
      "00:02:10.160 to\n",
      "00:02:10.319 execute\n",
      "00:02:11.160 so\n",
      "00:02:11.360 we\n",
      "00:02:11.520 have\n",
      "00:02:11.760 the\n",
      "00:02:12.000 uh\n",
      "00:02:12.120 for\n",
      "00:02:12.280 example\n",
      "00:02:12.560 if\n",
      "00:02:12.640 you're\n",
      "00:02:12.840 waiting\n",
      "00:02:13.120 for\n",
      "00:02:13.800 someone\n",
      "00:02:14.800 uh\n",
      "00:02:14.959 in\n",
      "00:02:15.160 this\n",
      "00:02:15.400 kind\n",
      "00:02:15.599 of\n",
      "00:02:15.720 a\n",
      "00:02:15.879 scene\n",
      "00:02:16.480 then\n",
      "00:02:16.640 you\n",
      "00:02:16.840 start\n",
      "00:02:17.160 paying\n",
      "00:02:17.680 more\n",
      "00:02:17.920 attention\n",
      "00:02:18.280 to\n",
      "00:02:18.519 people\n",
      "00:02:18.800 coming\n",
      "00:02:19.120 towards\n",
      "00:02:19.560 you\n",
      "00:02:19.800 people\n",
      "00:02:20.080 getting\n",
      "00:02:20.400 out\n",
      "00:02:20.680 of\n",
      "00:02:21.480 vehicles\n",
      "00:02:22.000 and\n",
      "00:02:23.360 on\n",
      "00:02:24.360 so\n",
      "00:02:24.680 now\n",
      "00:02:25.280 uh\n",
      "00:02:25.440 what\n",
      "00:02:25.640 I\n",
      "00:02:26.040 like\n",
      "00:02:26.280 to\n",
      "00:02:26.879 start\n",
      "00:02:27.280 getting\n",
      "00:02:27.680 into\n",
      "00:02:28.200 is\n",
      "00:02:28.640 uh\n",
      "00:02:28.800 the\n",
      "00:02:28.959 mechanics\n",
      "00:02:29.480 of\n",
      "00:02:29.959 a\n",
      "00:02:30.080 little\n",
      "00:02:30.280 bit\n",
      "00:02:30.440 of\n",
      "00:02:30.640 computer\n",
      "00:02:31.080 vision\n",
      "00:02:31.440 some\n",
      "00:02:31.680 kind\n",
      "00:02:31.800 of\n",
      "00:02:32.000 basic\n",
      "00:02:32.519 principles\n",
      "00:02:33.519 and\n",
      "00:02:33.680 I\n",
      "00:02:33.760 wanted\n",
      "00:02:34.080 to\n",
      "00:02:34.400 cover\n",
      "00:02:34.879 a\n",
      "00:02:35.000 little\n",
      "00:02:35.280 bit\n",
      "00:02:35.920 um\n",
      "00:02:36.200 you\n",
      "00:02:36.319 know\n",
      "00:02:36.560 the\n",
      "00:02:36.840 the\n",
      "00:02:37.000 question\n",
      "00:02:37.519 as\n",
      "00:02:37.680 to\n",
      "00:02:38.080 okay\n",
      "00:02:38.360 what\n",
      "00:02:38.760 is\n",
      "00:02:39.000 an\n",
      "00:02:39.239 image\n",
      "00:02:39.920 that\n",
      "00:02:40.200 like\n",
      "00:02:40.400 the\n",
      "00:02:40.519 one\n",
      "00:02:40.720 that\n",
      "00:02:40.840 we've\n",
      "00:02:41.040 seen\n",
      "00:02:41.440 earlier\n",
      "00:02:42.440 and\n",
      "00:02:42.800 how\n",
      "00:02:42.959 we're\n",
      "00:02:43.159 going\n",
      "00:02:43.280 to\n",
      "00:02:43.519 represent\n",
      "00:02:44.000 it\n",
      "00:02:44.640 and\n",
      "00:02:45.000 evidently\n",
      "00:02:45.519 an\n",
      "00:02:45.680 image\n",
      "00:02:46.000 is\n",
      "00:02:46.120 a\n",
      "00:02:46.480 matrix\n",
      "00:02:47.480 and\n",
      "00:02:47.800 I\n",
      "00:02:47.879 think\n",
      "00:02:48.040 we\n",
      "00:02:48.200 had\n",
      "00:02:48.360 some\n",
      "00:02:48.599 discussion\n",
      "00:02:49.080 about\n",
      "00:02:49.360 images\n",
      "00:02:50.159 uh\n",
      "00:02:50.360 before\n",
      "00:02:51.000 and\n",
      "00:02:51.319 a\n",
      "00:02:51.480 black\n",
      "00:02:52.360 white\n",
      "00:02:52.599 imag\n",
      "00:02:52.920 is\n",
      "00:02:53.480 or\n",
      "00:02:53.640 a\n",
      "00:02:53.800 grayscale\n",
      "00:02:54.319 image\n",
      "00:02:54.560 as\n",
      "00:02:54.680 you\n",
      "00:02:54.840 actually\n",
      "00:02:55.080 see\n",
      "00:02:55.480 over\n",
      "00:02:55.800 here\n",
      "00:02:56.280 is\n",
      "00:02:57.280 um\n",
      "00:02:57.800 a\n",
      "00:02:57.959 matrix\n",
      "00:02:58.720 of\n",
      "00:02:59.239 um\n",
      "00:02:59.560 that\n",
      "00:03:00.879 elements\n",
      "00:03:01.879 are\n",
      "00:03:02.280 integer\n",
      "00:03:03.040 numbers\n",
      "00:03:04.040 and\n",
      "00:03:04.599 um\n",
      "00:03:05.000 this\n",
      "00:03:05.280 integer\n",
      "00:03:05.760 numbers\n",
      "00:03:06.120 typically\n",
      "00:03:06.720 we\n",
      "00:03:06.879 are\n",
      "00:03:07.599 um\n",
      "00:03:07.959 you\n",
      "00:03:08.040 know\n",
      "00:03:08.200 each\n",
      "00:03:08.440 element\n",
      "00:03:08.879 corresponds\n",
      "00:03:09.319 to\n",
      "00:03:09.440 a\n",
      "00:03:09.599 pixel\n",
      "00:03:10.440 and\n",
      "00:03:10.599 the\n",
      "00:03:10.760 dynamic\n",
      "00:03:11.200 range\n",
      "00:03:11.760 that\n",
      "00:03:11.920 we\n",
      "00:03:12.159 associate\n",
      "00:03:12.879 with\n",
      "00:03:13.400 uh\n",
      "00:03:13.879 typically\n",
      "00:03:14.319 for\n",
      "00:03:14.440 in\n",
      "00:03:14.599 computer\n",
      "00:03:15.040 vision\n",
      "00:03:15.959 with\n",
      "00:03:16.120 those\n",
      "00:03:16.400 pixels\n",
      "00:03:16.799 are\n",
      "00:03:16.959 8\n",
      "00:03:17.280 Bits\n",
      "00:03:17.920 so\n",
      "00:03:18.239 we\n",
      "00:03:18.480 represent\n",
      "00:03:18.959 the\n",
      "00:03:19.120 information\n",
      "00:03:19.560 at\n",
      "00:03:19.760 each\n",
      "00:03:20.000 pixel\n",
      "00:03:20.440 and\n",
      "00:03:20.760 codes\n",
      "00:03:21.120 as\n",
      "00:03:21.319 8\n",
      "00:03:21.640 Bits\n",
      "00:03:22.400 which\n",
      "00:03:22.560 means\n",
      "00:03:22.760 that\n",
      "00:03:22.959 these\n",
      "00:03:23.120 integer\n",
      "00:03:23.519 numbers\n",
      "00:03:23.920 are\n",
      "00:03:24.159 zero\n",
      "00:03:24.560 from\n",
      "00:03:24.720 0\n",
      "00:03:25.000 to\n",
      "00:03:25.760 255\n",
      "00:03:26.760 and\n",
      "00:03:27.200 uh\n",
      "00:03:27.360 so\n",
      "00:03:28.080 um\n",
      "00:03:28.560 when\n",
      "00:03:28.720 we\n",
      "00:03:28.879 go\n",
      "00:03:29.040 to\n",
      "00:03:29.239 color\n",
      "00:03:29.519 IM\n",
      "00:03:30.120 es\n",
      "00:03:31.120 we\n",
      "00:03:31.280 need\n",
      "00:03:32.200 more\n",
      "00:03:32.760 than\n",
      "00:03:33.200 one\n",
      "00:03:33.959 of\n",
      "00:03:34.200 those\n",
      "00:03:34.480 matrices\n",
      "00:03:35.040 in\n",
      "00:03:35.200 fact\n",
      "00:03:35.400 we\n",
      "00:03:35.519 need\n",
      "00:03:35.799 three\n",
      "00:03:36.120 matrices\n",
      "00:03:36.680 typically\n",
      "00:03:37.159 again\n",
      "00:03:37.920 there\n",
      "00:03:38.040 are\n",
      "00:03:38.239 sensors\n",
      "00:03:38.760 which\n",
      "00:03:38.879 are\n",
      "00:03:39.599 of\n",
      "00:03:39.760 course\n",
      "00:03:40.000 encode\n",
      "00:03:40.480 the\n",
      "00:03:40.680 information\n",
      "00:03:41.120 to\n",
      "00:03:41.439 far\n",
      "00:03:41.680 more\n",
      "00:03:42.000 than\n",
      "00:03:42.799 uh\n",
      "00:03:42.920 three\n",
      "00:03:43.200 matrices\n",
      "00:03:44.000 uh\n",
      "00:03:44.159 but\n",
      "00:03:44.360 those\n",
      "00:03:44.560 three\n",
      "00:03:44.760 matrices\n",
      "00:03:45.319 are\n",
      "00:03:45.920 corresponds\n",
      "00:03:46.519 to\n",
      "00:03:46.720 the\n",
      "00:03:46.920 fundamental\n",
      "00:03:47.799 colors\n",
      "00:03:48.799 typically\n",
      "00:03:49.200 of\n",
      "00:03:49.439 red\n",
      "00:03:49.760 green\n",
      "00:03:50.120 and\n",
      "00:03:50.560 blue\n",
      "00:03:51.560 uh\n",
      "00:03:51.760 and\n",
      "00:03:52.079 this\n",
      "00:03:52.720 um\n",
      "00:03:53.159 uh\n",
      "00:03:53.400 which\n",
      "00:03:53.519 is\n",
      "00:03:53.680 actually\n",
      "00:03:54.120 what\n",
      "00:03:54.239 you\n",
      "00:03:54.400 see\n",
      "00:03:54.720 here\n",
      "00:03:55.480 and\n",
      "00:03:55.680 also\n",
      "00:03:56.000 probably\n",
      "00:03:56.319 you\n",
      "00:03:56.480 notice\n",
      "00:03:56.840 that\n",
      "00:03:57.000 these\n",
      "00:03:57.200 numbers\n",
      "00:03:57.480 are\n",
      "00:03:57.680 now\n",
      "00:03:57.840 floating\n",
      "00:03:58.280 Point\n",
      "00:03:58.560 numbers\n",
      "00:03:58.959 let's\n",
      "00:03:59.120 say\n",
      "00:03:59.280 from\n",
      "00:03:59.400 0\n",
      "00:03:59.879 to\n",
      "00:04:00.040 one\n",
      "00:04:00.799 and\n",
      "00:04:01.040 this\n",
      "00:04:01.519 results\n",
      "00:04:02.000 from\n",
      "00:04:02.319 normalizing\n",
      "00:04:03.200 these\n",
      "00:04:03.879 uh\n",
      "00:04:04.239 uh\n",
      "00:04:04.400 pixel\n",
      "00:04:04.799 numbers\n",
      "00:04:05.599 uh\n",
      "00:04:06.040 uh\n",
      "00:04:06.200 to\n",
      "00:04:06.799 uh\n",
      "00:04:07.040 with\n",
      "00:04:07.159 a\n",
      "00:04:07.280 number\n",
      "00:04:07.920 255\n",
      "00:04:08.920 because\n",
      "00:04:09.200 2\n",
      "00:04:09.400 to\n",
      "00:04:09.519 the\n",
      "00:04:09.640 power\n",
      "00:04:09.879 of\n",
      "00:04:10.000 8\n",
      "00:04:10.400 is\n",
      "00:04:11.360 256\n",
      "00:04:12.360 and\n",
      "00:04:12.879 uh\n",
      "00:04:13.319 uh\n",
      "00:04:13.480 therefore\n",
      "00:04:13.959 all\n",
      "00:04:14.159 our\n",
      "00:04:14.480 numbers\n",
      "00:04:14.840 will\n",
      "00:04:15.000 be\n",
      "00:04:15.200 from\n",
      "00:04:15.360 0\n",
      "00:04:15.680 to\n",
      "00:04:15.840 255\n",
      "00:04:16.600 in\n",
      "00:04:16.840 those\n",
      "00:04:17.079 matrices\n",
      "00:04:18.000 if\n",
      "00:04:18.120 we\n",
      "00:04:18.280 start\n",
      "00:04:18.600 dividing\n",
      "00:04:19.120 every\n",
      "00:04:19.400 element\n",
      "00:04:19.759 with\n",
      "00:04:20.120 255\n",
      "00:04:21.120 we\n",
      "00:04:21.320 get\n",
      "00:04:21.639 numbers\n",
      "00:04:22.120 between\n",
      "00:04:22.479 0\n",
      "00:04:22.840 and\n",
      "00:04:23.280 1\n",
      "00:04:24.280 and\n",
      "00:04:24.440 this\n",
      "00:04:24.560 is\n",
      "00:04:24.919 basically\n",
      "00:04:25.360 what\n",
      "00:04:25.479 we\n",
      "00:04:25.600 need\n",
      "00:04:25.759 to\n",
      "00:04:25.919 do\n",
      "00:04:26.400 in\n",
      "00:04:26.520 order\n",
      "00:04:26.800 to\n",
      "00:04:27.199 process\n",
      "00:04:28.199 uh\n",
      "00:04:28.360 the\n",
      "00:04:28.600 images\n",
      "00:04:29.280 in\n",
      "00:04:29.520 with\n",
      "00:04:29.759 with\n",
      "00:04:30.000 our\n",
      "00:04:30.440 new\n",
      "00:04:30.680 neural\n",
      "00:04:31.039 networks\n",
      "00:04:31.440 that\n",
      "00:04:31.600 we\n",
      "00:04:31.720 will\n",
      "00:04:31.919 introduce\n",
      "00:04:32.479 now\n",
      "00:04:32.759 called\n",
      "00:04:33.120 the\n",
      "00:04:33.280 convolutional\n",
      "00:04:33.880 neural\n",
      "00:04:34.440 networks\n",
      "00:04:35.440 so\n",
      "00:04:36.000 uh\n",
      "00:04:36.120 with\n",
      "00:04:36.360 convolutional\n",
      "00:04:36.919 neural\n",
      "00:04:37.240 networks\n",
      "00:04:38.199 we\n",
      "00:04:38.639 need\n",
      "00:04:38.919 to\n",
      "00:04:39.160 start\n",
      "00:04:39.639 the\n",
      "00:04:39.880 discussion\n",
      "00:04:40.840 on\n",
      "00:04:41.400 what\n",
      "00:04:41.560 is\n",
      "00:04:41.680 a\n",
      "00:04:42.039 convolution\n",
      "00:04:43.039 and\n",
      "00:04:43.400 uh\n",
      "00:04:43.520 this\n",
      "00:04:43.639 is\n",
      "00:04:43.840 what's\n",
      "00:04:44.039 coming\n"
     ]
    }
   ],
   "source": [
    "for x in text:\n",
    "    print(f'{x['start']} {x['word']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parseAndCleanVtt(vtt_path):\n",
    "    word_list = []\n",
    "\n",
    "    with open(vtt_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    first_word_time_pattern = re.compile(r'(\\d{2}:\\d{2}:\\d{2}.\\d{3}) -->')\n",
    "    timestamp_pattern = re.compile(r'<(\\d{2}:\\d{2}:\\d{2}.\\d{3})><c>([^<]*)</c>')\n",
    "    first_word_pattern = re.compile(r'^([^<]*)<')\n",
    "\n",
    "    words_to_remove = ['um','uh']\n",
    "\n",
    "    first_word_time = None\n",
    "    prev_word = ''\n",
    "    for line in lines:\n",
    "        first_word_time_match = first_word_time_pattern.findall(line)\n",
    "        if len(first_word_time_match) != 0:\n",
    "            first_word_time = first_word_time_match[0]\n",
    "\n",
    "        timestamp_matches = timestamp_pattern.findall(line)\n",
    "        if len(timestamp_matches) != 0:\n",
    "            first_word = first_word_pattern.findall(line)[0]\n",
    "\n",
    "            first_word = first_word.strip()\n",
    "\n",
    "            if first_word not in words_to_remove and first_word != prev_word:\n",
    "                word_list.append({\"start\": first_word_time, \"word\": first_word})\n",
    "                prev_word = first_word\n",
    "\n",
    "            for time_str, word in timestamp_matches:\n",
    "                word = word.strip()\n",
    "                if word not in words_to_remove and word != prev_word:\n",
    "                    word_list.append({\"start\": time_str, \"word\": word})\n",
    "                    prev_word = word\n",
    "\n",
    "\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = parseAndCleanVtt('ai-lectures-spring-24/videos/9CGGh6ivg68/9CGGh6ivg68.en.vtt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned_timestamps.txt', 'w') as file:\n",
    "    for timestamped_word in cleaned_text:\n",
    "        file.write(f'{timestamped_word['start']} {timestamped_word['word']}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned_transcript.txt', 'w') as file:\n",
    "    for timestamped_word in cleaned_text:\n",
    "        file.write(f\"{timestamped_word['word']} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this video I would like to start the discussion about convolutional new networks which is another architecture of uh neural networks that we are going to see specifically kind of engineered uh to um address problems that we are facing in computer vision I want to start this discussion with um just showing you a picture and uh if I ask you uh to tell me what would actually be the first object that you pay attention to then most people will probably respond to with yellow cab and it's not really accident that lot of cabs in a lot of capitals are painted uh yellow U and of course that attention uh to bright colors originates from thousands of years of evolution where people are of course trained to pay attention to uh bright colors which are typically sources of food such as fruits or in some instances sources of uh danger such as the yellow tiger that is coming towards us uh so kind of joking aside I think you can um associate uh this kind of image with the following kind of processing of uh various kind of stage processing that that is been going on in your brain uh trying to uh from the kind of perception system that embeds uh into it that we have embedded into it so if you can imagine the process um then the first thing that you open your eyes soon that you have your eyes closed and you see an image like this uh then the brain is actually in a uh first few milliseconds is uh sampling this image in a course kind of way uh and uh determines whether we have uh situations as as an immediate kind of threat or a source of food and then very quickly the brain switches softly into uh objects paying attention to objects which are associated with the task that we have uh we we we have to to execute so we have the uh for example if you're waiting for someone uh in this kind of a scene then you start paying more attention to people coming towards you people getting out of vehicles and on so now uh what I like to start getting into is uh the mechanics of a little bit of computer vision some kind of basic principles and I wanted to cover a little bit um you know the the question as to okay what is an image that like the one that we've seen earlier and how we're going to represent it and evidently an image is a matrix and I think we had some discussion about images uh before and a black white imag is or a grayscale image as you actually see over here is um a matrix of um that elements are integer numbers and um this integer numbers typically we are um you know each element corresponds to a pixel and the dynamic range that we associate with uh typically for in computer vision with those pixels are 8 Bits so we represent the information at each pixel and codes as 8 Bits which means that these integer numbers are zero from 0 to 255 and uh so um when we go to color IM es we need more than one of those matrices in fact we need three matrices typically again there are sensors which are of course encode the information to far more than uh three matrices uh but those three matrices are corresponds to the fundamental colors typically of red green and blue uh and this um uh which is actually what you see here and also probably you notice that these numbers are now floating Point numbers let's say from 0 to one and this results from normalizing these uh uh pixel numbers uh uh to uh with a number 255 because 2 to the power of 8 is 256 and uh uh therefore all our numbers will be from 0 to 255 in those matrices if we start dividing every element with 255 we get numbers between 0 and 1 and this is basically what we need to do in order to process uh the images in with with our new neural networks that we will introduce now called the convolutional neural networks so uh with convolutional neural networks we need to start the discussion on what is a convolution and uh this is what's coming "
     ]
    }
   ],
   "source": [
    "for x in text:\n",
    "    print(x['word'], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Load the JSON data from the file\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_storyboard_images(file_path):\n",
    "    json_data = load_json_from_file(file_path)\n",
    "\n",
    "    # Iterate through the formats to fetch the images\n",
    "    for format_info in json_data['formats']:\n",
    "        print(f\"Displaying storyboard images for format: {format_info['format']}\")\n",
    "        \n",
    "        # Iterate through the fragments to get image URLs\n",
    "        for fragment in format_info['fragments']:\n",
    "            image_url = fragment['url']\n",
    "            try:\n",
    "                # Fetch the image\n",
    "                response = requests.get(image_url)\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                \n",
    "                # Display the image\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')  # Hide axes\n",
    "                plt.show()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load image from {image_url}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_storyboard_images('ai-lectures-spring-24/videos/9CGGh6ivg68/9CGGh6ivg68.info.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-rag-model-_HJFAOPk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
