{
  "video_id": "TV-DjM8242s",
  "title": "3 cnn architectures",
  "captions": [
    {
      "start": "00:00:03.270",
      "end": "00:00:03.280",
      "text": "so this is basically what is happening"
    },
    {
      "start": "00:00:03.280",
      "end": "00:00:06.789",
      "text": "so this is basically what is happening um in a uh an example over here where we"
    },
    {
      "start": "00:00:06.789",
      "end": "00:00:06.799",
      "text": "um in a uh an example over here where we"
    },
    {
      "start": "00:00:06.799",
      "end": "00:00:08.750",
      "text": "um in a uh an example over here where we have an input"
    },
    {
      "start": "00:00:08.750",
      "end": "00:00:08.760",
      "text": "have an input"
    },
    {
      "start": "00:00:08.760",
      "end": "00:00:12.150",
      "text": "have an input image uh and uh we are actually sliding"
    },
    {
      "start": "00:00:12.150",
      "end": "00:00:12.160",
      "text": "image uh and uh we are actually sliding"
    },
    {
      "start": "00:00:12.160",
      "end": "00:00:16.029",
      "text": "image uh and uh we are actually sliding a kernel a 3X3 kernel uh and we are"
    },
    {
      "start": "00:00:16.029",
      "end": "00:00:16.039",
      "text": "a kernel a 3X3 kernel uh and we are"
    },
    {
      "start": "00:00:16.039",
      "end": "00:00:19.109",
      "text": "a kernel a 3X3 kernel uh and we are getting an an an output feature map so"
    },
    {
      "start": "00:00:19.109",
      "end": "00:00:19.119",
      "text": "getting an an an output feature map so"
    },
    {
      "start": "00:00:19.119",
      "end": "00:00:22.349",
      "text": "getting an an an output feature map so the input feature map here is uh just"
    },
    {
      "start": "00:00:22.349",
      "end": "00:00:22.359",
      "text": "the input feature map here is uh just"
    },
    {
      "start": "00:00:22.359",
      "end": "00:00:25.550",
      "text": "the input feature map here is uh just has one we will be calling sometimes"
    },
    {
      "start": "00:00:25.550",
      "end": "00:00:25.560",
      "text": "has one we will be calling sometimes"
    },
    {
      "start": "00:00:25.560",
      "end": "00:00:30.589",
      "text": "has one we will be calling sometimes this uh uh depth Channel um"
    },
    {
      "start": "00:00:30.589",
      "end": "00:00:30.599",
      "text": "this uh uh depth Channel um"
    },
    {
      "start": "00:00:30.599",
      "end": "00:00:32.830",
      "text": "this uh uh depth Channel um and uh the output feature map has again"
    },
    {
      "start": "00:00:32.830",
      "end": "00:00:32.840",
      "text": "and uh the output feature map has again"
    },
    {
      "start": "00:00:32.840",
      "end": "00:00:34.350",
      "text": "and uh the output feature map has again one channel over"
    },
    {
      "start": "00:00:34.350",
      "end": "00:00:34.360",
      "text": "one channel over"
    },
    {
      "start": "00:00:34.360",
      "end": "00:00:38.229",
      "text": "one channel over here and uh what we have here is we have"
    },
    {
      "start": "00:00:38.229",
      "end": "00:00:38.239",
      "text": "here and uh what we have here is we have"
    },
    {
      "start": "00:00:38.239",
      "end": "00:00:39.630",
      "text": "here and uh what we have here is we have a couple of things that we need to"
    },
    {
      "start": "00:00:39.630",
      "end": "00:00:39.640",
      "text": "a couple of things that we need to"
    },
    {
      "start": "00:00:39.640",
      "end": "00:00:43.389",
      "text": "a couple of things that we need to introduce as terms in uh convolutional"
    },
    {
      "start": "00:00:43.389",
      "end": "00:00:43.399",
      "text": "introduce as terms in uh convolutional"
    },
    {
      "start": "00:00:43.399",
      "end": "00:00:45.549",
      "text": "introduce as terms in uh convolutional uh operations that we actually doing and"
    },
    {
      "start": "00:00:45.549",
      "end": "00:00:45.559",
      "text": "uh operations that we actually doing and"
    },
    {
      "start": "00:00:45.559",
      "end": "00:00:47.869",
      "text": "uh operations that we actually doing and inside the convolutional new networks so"
    },
    {
      "start": "00:00:47.869",
      "end": "00:00:47.879",
      "text": "inside the convolutional new networks so"
    },
    {
      "start": "00:00:47.879",
      "end": "00:00:51.709",
      "text": "inside the convolutional new networks so the first is the form uh of the the"
    },
    {
      "start": "00:00:51.709",
      "end": "00:00:51.719",
      "text": "the first is the form uh of the the"
    },
    {
      "start": "00:00:51.719",
      "end": "00:00:55.910",
      "text": "the first is the form uh of the the concept of padding and uh typically we"
    },
    {
      "start": "00:00:55.910",
      "end": "00:00:55.920",
      "text": "concept of padding and uh typically we"
    },
    {
      "start": "00:00:55.920",
      "end": "00:01:00.869",
      "text": "concept of padding and uh typically we are padding uh the U input uh feature"
    },
    {
      "start": "00:01:00.869",
      "end": "00:01:00.879",
      "text": "are padding uh the U input uh feature"
    },
    {
      "start": "00:01:00.879",
      "end": "00:01:05.030",
      "text": "are padding uh the U input uh feature Maps uh in order to uh do two things uh"
    },
    {
      "start": "00:01:05.030",
      "end": "00:01:05.040",
      "text": "Maps uh in order to uh do two things uh"
    },
    {
      "start": "00:01:05.040",
      "end": "00:01:07.190",
      "text": "Maps uh in order to uh do two things uh we achieving two things probably you"
    },
    {
      "start": "00:01:07.190",
      "end": "00:01:07.200",
      "text": "we achieving two things probably you"
    },
    {
      "start": "00:01:07.200",
      "end": "00:01:09.270",
      "text": "we achieving two things probably you have noticed that in in an earlier kind"
    },
    {
      "start": "00:01:09.270",
      "end": "00:01:09.280",
      "text": "have noticed that in in an earlier kind"
    },
    {
      "start": "00:01:09.280",
      "end": "00:01:13.390",
      "text": "have noticed that in in an earlier kind of discussion or we had the uh operation"
    },
    {
      "start": "00:01:13.390",
      "end": "00:01:13.400",
      "text": "of discussion or we had the uh operation"
    },
    {
      "start": "00:01:13.400",
      "end": "00:01:16.030",
      "text": "of discussion or we had the uh operation of cross correlation operation in this"
    },
    {
      "start": "00:01:16.030",
      "end": "00:01:16.040",
      "text": "of cross correlation operation in this"
    },
    {
      "start": "00:01:16.040",
      "end": "00:01:18.630",
      "text": "of cross correlation operation in this in this kind of image over here uh the"
    },
    {
      "start": "00:01:18.630",
      "end": "00:01:18.640",
      "text": "in this kind of image over here uh the"
    },
    {
      "start": "00:01:18.640",
      "end": "00:01:22.429",
      "text": "in this kind of image over here uh the output feature map was always smaller in"
    },
    {
      "start": "00:01:22.429",
      "end": "00:01:22.439",
      "text": "output feature map was always smaller in"
    },
    {
      "start": "00:01:22.439",
      "end": "00:01:24.910",
      "text": "output feature map was always smaller in terms of speciaal dimensions compared to"
    },
    {
      "start": "00:01:24.910",
      "end": "00:01:24.920",
      "text": "terms of speciaal dimensions compared to"
    },
    {
      "start": "00:01:24.920",
      "end": "00:01:28.030",
      "text": "terms of speciaal dimensions compared to the input feature map and uh it is"
    },
    {
      "start": "00:01:28.030",
      "end": "00:01:28.040",
      "text": "the input feature map and uh it is"
    },
    {
      "start": "00:01:28.040",
      "end": "00:01:31.069",
      "text": "the input feature map and uh it is evidently so uh because the only way"
    },
    {
      "start": "00:01:31.069",
      "end": "00:01:31.079",
      "text": "evidently so uh because the only way"
    },
    {
      "start": "00:01:31.079",
      "end": "00:01:33.590",
      "text": "evidently so uh because the only way that this output feature MK can be"
    },
    {
      "start": "00:01:33.590",
      "end": "00:01:33.600",
      "text": "that this output feature MK can be"
    },
    {
      "start": "00:01:33.600",
      "end": "00:01:36.550",
      "text": "that this output feature MK can be exactly the same size as the input is"
    },
    {
      "start": "00:01:36.550",
      "end": "00:01:36.560",
      "text": "exactly the same size as the input is"
    },
    {
      "start": "00:01:36.560",
      "end": "00:01:38.789",
      "text": "exactly the same size as the input is when the kernel is 1 by one so when the"
    },
    {
      "start": "00:01:38.789",
      "end": "00:01:38.799",
      "text": "when the kernel is 1 by one so when the"
    },
    {
      "start": "00:01:38.799",
      "end": "00:01:41.670",
      "text": "when the kernel is 1 by one so when the Kel has a special extent of 1 by one uh"
    },
    {
      "start": "00:01:41.670",
      "end": "00:01:41.680",
      "text": "Kel has a special extent of 1 by one uh"
    },
    {
      "start": "00:01:41.680",
      "end": "00:01:44.109",
      "text": "Kel has a special extent of 1 by one uh then we have exactly that uh situation"
    },
    {
      "start": "00:01:44.109",
      "end": "00:01:44.119",
      "text": "then we have exactly that uh situation"
    },
    {
      "start": "00:01:44.119",
      "end": "00:01:46.910",
      "text": "then we have exactly that uh situation but in in most cases where the can won't"
    },
    {
      "start": "00:01:46.910",
      "end": "00:01:46.920",
      "text": "but in in most cases where the can won't"
    },
    {
      "start": "00:01:46.920",
      "end": "00:01:49.789",
      "text": "but in in most cases where the can won't be one by one we will expect this output"
    },
    {
      "start": "00:01:49.789",
      "end": "00:01:49.799",
      "text": "be one by one we will expect this output"
    },
    {
      "start": "00:01:49.799",
      "end": "00:01:51.630",
      "text": "be one by one we will expect this output feature maps to shrink in terms of"
    },
    {
      "start": "00:01:51.630",
      "end": "00:01:51.640",
      "text": "feature maps to shrink in terms of"
    },
    {
      "start": "00:01:51.640",
      "end": "00:01:54.190",
      "text": "feature maps to shrink in terms of spatial content and we do not want them"
    },
    {
      "start": "00:01:54.190",
      "end": "00:01:54.200",
      "text": "spatial content and we do not want them"
    },
    {
      "start": "00:01:54.200",
      "end": "00:01:57.550",
      "text": "spatial content and we do not want them to shrink too much uh because sooner or"
    },
    {
      "start": "00:01:57.550",
      "end": "00:01:57.560",
      "text": "to shrink too much uh because sooner or"
    },
    {
      "start": "00:01:57.560",
      "end": "00:02:00.029",
      "text": "to shrink too much uh because sooner or later uh we will be running out of"
    },
    {
      "start": "00:02:00.029",
      "end": "00:02:00.039",
      "text": "later uh we will be running out of"
    },
    {
      "start": "00:02:00.039",
      "end": "00:02:02.709",
      "text": "later uh we will be running out of spatial Dimensions uh in our outputs and"
    },
    {
      "start": "00:02:02.709",
      "end": "00:02:02.719",
      "text": "spatial Dimensions uh in our outputs and"
    },
    {
      "start": "00:02:02.719",
      "end": "00:02:05.029",
      "text": "spatial Dimensions uh in our outputs and therefore we cannot really go deep to"
    },
    {
      "start": "00:02:05.029",
      "end": "00:02:05.039",
      "text": "therefore we cannot really go deep to"
    },
    {
      "start": "00:02:05.039",
      "end": "00:02:07.350",
      "text": "therefore we cannot really go deep to construct deep architectures in these"
    },
    {
      "start": "00:02:07.350",
      "end": "00:02:07.360",
      "text": "construct deep architectures in these"
    },
    {
      "start": "00:02:07.360",
      "end": "00:02:09.830",
      "text": "construct deep architectures in these networks so what we expect to do what we"
    },
    {
      "start": "00:02:09.830",
      "end": "00:02:09.840",
      "text": "networks so what we expect to do what we"
    },
    {
      "start": "00:02:09.840",
      "end": "00:02:14.110",
      "text": "networks so what we expect to do what we are have done is we have with padding we"
    },
    {
      "start": "00:02:14.110",
      "end": "00:02:14.120",
      "text": "are have done is we have with padding we"
    },
    {
      "start": "00:02:14.120",
      "end": "00:02:16.470",
      "text": "are have done is we have with padding we are trying to manage this special extent"
    },
    {
      "start": "00:02:16.470",
      "end": "00:02:16.480",
      "text": "are trying to manage this special extent"
    },
    {
      "start": "00:02:16.480",
      "end": "00:02:20.030",
      "text": "are trying to manage this special extent reduction on one hand uh as you can see"
    },
    {
      "start": "00:02:20.030",
      "end": "00:02:20.040",
      "text": "reduction on one hand uh as you can see"
    },
    {
      "start": "00:02:20.040",
      "end": "00:02:23.509",
      "text": "reduction on one hand uh as you can see if we had this padding over here uh then"
    },
    {
      "start": "00:02:23.509",
      "end": "00:02:23.519",
      "text": "if we had this padding over here uh then"
    },
    {
      "start": "00:02:23.519",
      "end": "00:02:26.990",
      "text": "if we had this padding over here uh then uh the uh output feature map is uh going"
    },
    {
      "start": "00:02:26.990",
      "end": "00:02:27.000",
      "text": "uh the uh output feature map is uh going"
    },
    {
      "start": "00:02:27.000",
      "end": "00:02:31.509",
      "text": "uh the uh output feature map is uh going to be uh much larger uh than otherwise"
    },
    {
      "start": "00:02:31.509",
      "end": "00:02:31.519",
      "text": "to be uh much larger uh than otherwise"
    },
    {
      "start": "00:02:31.519",
      "end": "00:02:33.630",
      "text": "to be uh much larger uh than otherwise so if you can imagine that without a"
    },
    {
      "start": "00:02:33.630",
      "end": "00:02:33.640",
      "text": "so if you can imagine that without a"
    },
    {
      "start": "00:02:33.640",
      "end": "00:02:37.670",
      "text": "so if you can imagine that without a padding uh then this uh uh sort of"
    },
    {
      "start": "00:02:37.670",
      "end": "00:02:37.680",
      "text": "padding uh then this uh uh sort of"
    },
    {
      "start": "00:02:37.680",
      "end": "00:02:41.390",
      "text": "padding uh then this uh uh sort of output feature map would actually be um"
    },
    {
      "start": "00:02:41.390",
      "end": "00:02:41.400",
      "text": "output feature map would actually be um"
    },
    {
      "start": "00:02:41.400",
      "end": "00:02:43.509",
      "text": "output feature map would actually be um I can't really uh sort of tell you"
    },
    {
      "start": "00:02:43.509",
      "end": "00:02:43.519",
      "text": "I can't really uh sort of tell you"
    },
    {
      "start": "00:02:43.519",
      "end": "00:02:45.710",
      "text": "I can't really uh sort of tell you exactly the dimensions but if you do the"
    },
    {
      "start": "00:02:45.710",
      "end": "00:02:45.720",
      "text": "exactly the dimensions but if you do the"
    },
    {
      "start": "00:02:45.720",
      "end": "00:02:48.350",
      "text": "exactly the dimensions but if you do the if you see the sort of if you do it"
    },
    {
      "start": "00:02:48.350",
      "end": "00:02:48.360",
      "text": "if you see the sort of if you do it"
    },
    {
      "start": "00:02:48.360",
      "end": "00:02:49.949",
      "text": "if you see the sort of if you do it visually then you can actually see it's"
    },
    {
      "start": "00:02:49.949",
      "end": "00:02:49.959",
      "text": "visually then you can actually see it's"
    },
    {
      "start": "00:02:49.959",
      "end": "00:02:52.830",
      "text": "visually then you can actually see it's going to be probably something like a a"
    },
    {
      "start": "00:02:52.830",
      "end": "00:02:52.840",
      "text": "going to be probably something like a a"
    },
    {
      "start": "00:02:52.840",
      "end": "00:02:59.550",
      "text": "going to be probably something like a a 3X3 uh output uh now the um uh sort of"
    },
    {
      "start": "00:02:59.550",
      "end": "00:02:59.560",
      "text": "3X3 uh output uh now the um uh sort of"
    },
    {
      "start": "00:02:59.560",
      "end": "00:03:03.110",
      "text": "3X3 uh output uh now the um uh sort of uh another another advantage of padding"
    },
    {
      "start": "00:03:03.110",
      "end": "00:03:03.120",
      "text": "uh another another advantage of padding"
    },
    {
      "start": "00:03:03.120",
      "end": "00:03:05.430",
      "text": "uh another another advantage of padding is that we allow the Kel to actually"
    },
    {
      "start": "00:03:05.430",
      "end": "00:03:05.440",
      "text": "is that we allow the Kel to actually"
    },
    {
      "start": "00:03:05.440",
      "end": "00:03:08.949",
      "text": "is that we allow the Kel to actually move into locations which would not be"
    },
    {
      "start": "00:03:08.949",
      "end": "00:03:08.959",
      "text": "move into locations which would not be"
    },
    {
      "start": "00:03:08.959",
      "end": "00:03:12.789",
      "text": "move into locations which would not be able to move otherwise so a kernel as we"
    },
    {
      "start": "00:03:12.789",
      "end": "00:03:12.799",
      "text": "able to move otherwise so a kernel as we"
    },
    {
      "start": "00:03:12.799",
      "end": "00:03:14.910",
      "text": "able to move otherwise so a kernel as we discussed a bit earlier contains some"
    },
    {
      "start": "00:03:14.910",
      "end": "00:03:14.920",
      "text": "discussed a bit earlier contains some"
    },
    {
      "start": "00:03:14.920",
      "end": "00:03:17.470",
      "text": "discussed a bit earlier contains some values and we would like all of the"
    },
    {
      "start": "00:03:17.470",
      "end": "00:03:17.480",
      "text": "values and we would like all of the"
    },
    {
      "start": "00:03:17.480",
      "end": "00:03:20.869",
      "text": "values and we would like all of the pixels including the edge pixels of the"
    },
    {
      "start": "00:03:20.869",
      "end": "00:03:20.879",
      "text": "pixels including the edge pixels of the"
    },
    {
      "start": "00:03:20.879",
      "end": "00:03:22.869",
      "text": "pixels including the edge pixels of the input feature map to be able to be"
    },
    {
      "start": "00:03:22.869",
      "end": "00:03:22.879",
      "text": "input feature map to be able to be"
    },
    {
      "start": "00:03:22.879",
      "end": "00:03:25.390",
      "text": "input feature map to be able to be correlated with all of the other pixels"
    },
    {
      "start": "00:03:25.390",
      "end": "00:03:25.400",
      "text": "correlated with all of the other pixels"
    },
    {
      "start": "00:03:25.400",
      "end": "00:03:27.789",
      "text": "correlated with all of the other pixels of the all of the of the pixels of the"
    },
    {
      "start": "00:03:27.789",
      "end": "00:03:27.799",
      "text": "of the all of the of the pixels of the"
    },
    {
      "start": "00:03:27.799",
      "end": "00:03:30.990",
      "text": "of the all of the of the pixels of the Kel and therefore uh padding allows us"
    },
    {
      "start": "00:03:30.990",
      "end": "00:03:31.000",
      "text": "Kel and therefore uh padding allows us"
    },
    {
      "start": "00:03:31.000",
      "end": "00:03:34.630",
      "text": "Kel and therefore uh padding allows us to um to to do so um otherwise you can"
    },
    {
      "start": "00:03:34.630",
      "end": "00:03:34.640",
      "text": "to um to to do so um otherwise you can"
    },
    {
      "start": "00:03:34.640",
      "end": "00:03:37.070",
      "text": "to um to to do so um otherwise you can imagine this red kernel over here will"
    },
    {
      "start": "00:03:37.070",
      "end": "00:03:37.080",
      "text": "imagine this red kernel over here will"
    },
    {
      "start": "00:03:37.080",
      "end": "00:03:41.550",
      "text": "imagine this red kernel over here will actually be only be able to um correlate"
    },
    {
      "start": "00:03:41.550",
      "end": "00:03:41.560",
      "text": "actually be only be able to um correlate"
    },
    {
      "start": "00:03:41.560",
      "end": "00:03:44.670",
      "text": "actually be only be able to um correlate with uh those three pixels of the input"
    },
    {
      "start": "00:03:44.670",
      "end": "00:03:44.680",
      "text": "with uh those three pixels of the input"
    },
    {
      "start": "00:03:44.680",
      "end": "00:03:48.589",
      "text": "with uh those three pixels of the input feature map now uh this pixel over here"
    },
    {
      "start": "00:03:48.589",
      "end": "00:03:48.599",
      "text": "feature map now uh this pixel over here"
    },
    {
      "start": "00:03:48.599",
      "end": "00:03:51.670",
      "text": "feature map now uh this pixel over here can be correlated with both this pixel"
    },
    {
      "start": "00:03:51.670",
      "end": "00:03:51.680",
      "text": "can be correlated with both this pixel"
    },
    {
      "start": "00:03:51.680",
      "end": "00:03:55.390",
      "text": "can be correlated with both this pixel of the kernel and that pixel of the and"
    },
    {
      "start": "00:03:55.390",
      "end": "00:03:55.400",
      "text": "of the kernel and that pixel of the and"
    },
    {
      "start": "00:03:55.400",
      "end": "00:03:58.149",
      "text": "of the kernel and that pixel of the and this pixel and this pixel of the sort of"
    },
    {
      "start": "00:03:58.149",
      "end": "00:03:58.159",
      "text": "this pixel and this pixel of the sort of"
    },
    {
      "start": "00:03:58.159",
      "end": "00:04:02.589",
      "text": "this pixel and this pixel of the sort of uh uh Kel that we have so we have um the"
    },
    {
      "start": "00:04:02.589",
      "end": "00:04:02.599",
      "text": "uh uh Kel that we have so we have um the"
    },
    {
      "start": "00:04:02.599",
      "end": "00:04:05.429",
      "text": "uh uh Kel that we have so we have um the ability to uh sort of get more"
    },
    {
      "start": "00:04:05.429",
      "end": "00:04:05.439",
      "text": "ability to uh sort of get more"
    },
    {
      "start": "00:04:05.439",
      "end": "00:04:08.350",
      "text": "ability to uh sort of get more information especially towards the edges"
    },
    {
      "start": "00:04:08.350",
      "end": "00:04:08.360",
      "text": "information especially towards the edges"
    },
    {
      "start": "00:04:08.360",
      "end": "00:04:11.910",
      "text": "information especially towards the edges of that input feature map with"
    },
    {
      "start": "00:04:11.910",
      "end": "00:04:11.920",
      "text": "of that input feature map with"
    },
    {
      "start": "00:04:11.920",
      "end": "00:04:14.949",
      "text": "of that input feature map with padding another uh parameter that we"
    },
    {
      "start": "00:04:14.949",
      "end": "00:04:14.959",
      "text": "padding another uh parameter that we"
    },
    {
      "start": "00:04:14.959",
      "end": "00:04:18.550",
      "text": "padding another uh parameter that we should uh also uh sort of understand is"
    },
    {
      "start": "00:04:18.550",
      "end": "00:04:18.560",
      "text": "should uh also uh sort of understand is"
    },
    {
      "start": "00:04:18.560",
      "end": "00:04:22.390",
      "text": "should uh also uh sort of understand is this kind of stride so stride is uh the"
    },
    {
      "start": "00:04:22.390",
      "end": "00:04:22.400",
      "text": "this kind of stride so stride is uh the"
    },
    {
      "start": "00:04:22.400",
      "end": "00:04:24.270",
      "text": "this kind of stride so stride is uh the just like the stride that you as you"
    },
    {
      "start": "00:04:24.270",
      "end": "00:04:24.280",
      "text": "just like the stride that you as you"
    },
    {
      "start": "00:04:24.280",
      "end": "00:04:27.870",
      "text": "just like the stride that you as you walk um it this here actually refers to"
    },
    {
      "start": "00:04:27.870",
      "end": "00:04:27.880",
      "text": "walk um it this here actually refers to"
    },
    {
      "start": "00:04:27.880",
      "end": "00:04:30.230",
      "text": "walk um it this here actually refers to uh the uh number of"
    },
    {
      "start": "00:04:30.230",
      "end": "00:04:30.240",
      "text": "uh the uh number of"
    },
    {
      "start": "00:04:30.240",
      "end": "00:04:33.830",
      "text": "uh the uh number of pixels uh that you are skipping over uh"
    },
    {
      "start": "00:04:33.830",
      "end": "00:04:33.840",
      "text": "pixels uh that you are skipping over uh"
    },
    {
      "start": "00:04:33.840",
      "end": "00:04:37.150",
      "text": "pixels uh that you are skipping over uh the uh in order for you to be able to uh"
    },
    {
      "start": "00:04:37.150",
      "end": "00:04:37.160",
      "text": "the uh in order for you to be able to uh"
    },
    {
      "start": "00:04:37.160",
      "end": "00:04:39.310",
      "text": "the uh in order for you to be able to uh do the next correlation so here you see"
    },
    {
      "start": "00:04:39.310",
      "end": "00:04:39.320",
      "text": "do the next correlation so here you see"
    },
    {
      "start": "00:04:39.320",
      "end": "00:04:43.870",
      "text": "do the next correlation so here you see two locations of that kernel uh in that"
    },
    {
      "start": "00:04:43.870",
      "end": "00:04:43.880",
      "text": "two locations of that kernel uh in that"
    },
    {
      "start": "00:04:43.880",
      "end": "00:04:46.870",
      "text": "two locations of that kernel uh in that location and the blue location the red"
    },
    {
      "start": "00:04:46.870",
      "end": "00:04:46.880",
      "text": "location and the blue location the red"
    },
    {
      "start": "00:04:46.880",
      "end": "00:04:48.870",
      "text": "location and the blue location the red location the blue location if your"
    },
    {
      "start": "00:04:48.870",
      "end": "00:04:48.880",
      "text": "location the blue location if your"
    },
    {
      "start": "00:04:48.880",
      "end": "00:04:53.189",
      "text": "location the blue location if your stride was one uh then the blue K have"
    },
    {
      "start": "00:04:53.189",
      "end": "00:04:53.199",
      "text": "stride was one uh then the blue K have"
    },
    {
      "start": "00:04:53.199",
      "end": "00:04:54.430",
      "text": "stride was one uh then the blue K have been right"
    },
    {
      "start": "00:04:54.430",
      "end": "00:04:54.440",
      "text": "been right"
    },
    {
      "start": "00:04:54.440",
      "end": "00:04:57.990",
      "text": "been right here uh and while with a stride of two"
    },
    {
      "start": "00:04:57.990",
      "end": "00:04:58.000",
      "text": "here uh and while with a stride of two"
    },
    {
      "start": "00:04:58.000",
      "end": "00:05:01.110",
      "text": "here uh and while with a stride of two uh then we don't uh get one correlation"
    },
    {
      "start": "00:05:01.110",
      "end": "00:05:01.120",
      "text": "uh then we don't uh get one correlation"
    },
    {
      "start": "00:05:01.120",
      "end": "00:05:03.070",
      "text": "uh then we don't uh get one correlation operation for every pixel of the input"
    },
    {
      "start": "00:05:03.070",
      "end": "00:05:03.080",
      "text": "operation for every pixel of the input"
    },
    {
      "start": "00:05:03.080",
      "end": "00:05:05.590",
      "text": "operation for every pixel of the input feature map and this is obviously is"
    },
    {
      "start": "00:05:05.590",
      "end": "00:05:05.600",
      "text": "feature map and this is obviously is"
    },
    {
      "start": "00:05:05.600",
      "end": "00:05:09.230",
      "text": "feature map and this is obviously is helping us to manage uh the complexity"
    },
    {
      "start": "00:05:09.230",
      "end": "00:05:09.240",
      "text": "helping us to manage uh the complexity"
    },
    {
      "start": "00:05:09.240",
      "end": "00:05:11.909",
      "text": "helping us to manage uh the complexity of these filters in fact goes slightly"
    },
    {
      "start": "00:05:11.909",
      "end": "00:05:11.919",
      "text": "of these filters in fact goes slightly"
    },
    {
      "start": "00:05:11.919",
      "end": "00:05:13.670",
      "text": "of these filters in fact goes slightly to the opposite direction of what we"
    },
    {
      "start": "00:05:13.670",
      "end": "00:05:13.680",
      "text": "to the opposite direction of what we"
    },
    {
      "start": "00:05:13.680",
      "end": "00:05:17.110",
      "text": "to the opposite direction of what we have said earlier in a sense that in"
    },
    {
      "start": "00:05:17.110",
      "end": "00:05:17.120",
      "text": "have said earlier in a sense that in"
    },
    {
      "start": "00:05:17.120",
      "end": "00:05:21.270",
      "text": "have said earlier in a sense that in some instances we prefer to uh get for"
    },
    {
      "start": "00:05:21.270",
      "end": "00:05:21.280",
      "text": "some instances we prefer to uh get for"
    },
    {
      "start": "00:05:21.280",
      "end": "00:05:23.070",
      "text": "some instances we prefer to uh get for some of the layers uh of the"
    },
    {
      "start": "00:05:23.070",
      "end": "00:05:23.080",
      "text": "some of the layers uh of the"
    },
    {
      "start": "00:05:23.080",
      "end": "00:05:26.309",
      "text": "some of the layers uh of the convolutional neuron uh the The Stride"
    },
    {
      "start": "00:05:26.309",
      "end": "00:05:26.319",
      "text": "convolutional neuron uh the The Stride"
    },
    {
      "start": "00:05:26.319",
      "end": "00:05:28.430",
      "text": "convolutional neuron uh the The Stride parameter to be larger than one"
    },
    {
      "start": "00:05:28.430",
      "end": "00:05:28.440",
      "text": "parameter to be larger than one"
    },
    {
      "start": "00:05:28.440",
      "end": "00:05:30.710",
      "text": "parameter to be larger than one typically The Stride parameter of uh"
    },
    {
      "start": "00:05:30.710",
      "end": "00:05:30.720",
      "text": "typically The Stride parameter of uh"
    },
    {
      "start": "00:05:30.720",
      "end": "00:05:33.710",
      "text": "typically The Stride parameter of uh height and width um are going to be the"
    },
    {
      "start": "00:05:33.710",
      "end": "00:05:33.720",
      "text": "height and width um are going to be the"
    },
    {
      "start": "00:05:33.720",
      "end": "00:05:36.629",
      "text": "height and width um are going to be the same uh so that's what you see over here"
    },
    {
      "start": "00:05:36.629",
      "end": "00:05:36.639",
      "text": "same uh so that's what you see over here"
    },
    {
      "start": "00:05:36.639",
      "end": "00:05:38.629",
      "text": "same uh so that's what you see over here bottom line is that uh all of these"
    },
    {
      "start": "00:05:38.629",
      "end": "00:05:38.639",
      "text": "bottom line is that uh all of these"
    },
    {
      "start": "00:05:38.639",
      "end": "00:05:40.670",
      "text": "bottom line is that uh all of these parameters and far more that are to"
    },
    {
      "start": "00:05:40.670",
      "end": "00:05:40.680",
      "text": "parameters and far more that are to"
    },
    {
      "start": "00:05:40.680",
      "end": "00:05:44.150",
      "text": "parameters and far more that are to follow are hyper parameters and uh we"
    },
    {
      "start": "00:05:44.150",
      "end": "00:05:44.160",
      "text": "follow are hyper parameters and uh we"
    },
    {
      "start": "00:05:44.160",
      "end": "00:05:46.950",
      "text": "follow are hyper parameters and uh we are uh going to be optimizing them uh"
    },
    {
      "start": "00:05:46.950",
      "end": "00:05:46.960",
      "text": "are uh going to be optimizing them uh"
    },
    {
      "start": "00:05:46.960",
      "end": "00:05:50.110",
      "text": "are uh going to be optimizing them uh for using hyperparameter optimization in"
    },
    {
      "start": "00:05:50.110",
      "end": "00:05:50.120",
      "text": "for using hyperparameter optimization in"
    },
    {
      "start": "00:05:50.120",
      "end": "00:05:51.830",
      "text": "for using hyperparameter optimization in order for us to define the complete"
    },
    {
      "start": "00:05:51.830",
      "end": "00:05:51.840",
      "text": "order for us to define the complete"
    },
    {
      "start": "00:05:51.840",
      "end": "00:05:54.350",
      "text": "order for us to define the complete architecture of of of a"
    },
    {
      "start": "00:05:54.350",
      "end": "00:05:54.360",
      "text": "architecture of of of a"
    },
    {
      "start": "00:05:54.360",
      "end": "00:05:56.790",
      "text": "architecture of of of a CNN here you see some animations that"
    },
    {
      "start": "00:05:56.790",
      "end": "00:05:56.800",
      "text": "CNN here you see some animations that"
    },
    {
      "start": "00:05:56.800",
      "end": "00:05:59.110",
      "text": "CNN here you see some animations that kind of reinforce what we have uh just"
    },
    {
      "start": "00:05:59.110",
      "end": "00:05:59.120",
      "text": "kind of reinforce what we have uh just"
    },
    {
      "start": "00:05:59.120",
      "end": "00:06:03.189",
      "text": "kind of reinforce what we have uh just uh quoted Ed without padding uh the uh"
    },
    {
      "start": "00:06:03.189",
      "end": "00:06:03.199",
      "text": "uh quoted Ed without padding uh the uh"
    },
    {
      "start": "00:06:03.199",
      "end": "00:06:05.550",
      "text": "uh quoted Ed without padding uh the uh Kel the output feature map is going to"
    },
    {
      "start": "00:06:05.550",
      "end": "00:06:05.560",
      "text": "Kel the output feature map is going to"
    },
    {
      "start": "00:06:05.560",
      "end": "00:06:08.990",
      "text": "Kel the output feature map is going to be U potentially significantly reduced"
    },
    {
      "start": "00:06:08.990",
      "end": "00:06:09.000",
      "text": "be U potentially significantly reduced"
    },
    {
      "start": "00:06:09.000",
      "end": "00:06:11.309",
      "text": "be U potentially significantly reduced in terms of spatial extent something"
    },
    {
      "start": "00:06:11.309",
      "end": "00:06:11.319",
      "text": "in terms of spatial extent something"
    },
    {
      "start": "00:06:11.319",
      "end": "00:06:14.350",
      "text": "in terms of spatial extent something will make uh any subsequent um cor"
    },
    {
      "start": "00:06:14.350",
      "end": "00:06:14.360",
      "text": "will make uh any subsequent um cor"
    },
    {
      "start": "00:06:14.360",
      "end": "00:06:17.070",
      "text": "will make uh any subsequent um cor correlation with Kels uh you know not"
    },
    {
      "start": "00:06:17.070",
      "end": "00:06:17.080",
      "text": "correlation with Kels uh you know not"
    },
    {
      "start": "00:06:17.080",
      "end": "00:06:19.990",
      "text": "correlation with Kels uh you know not very useful uh with padding this is we"
    },
    {
      "start": "00:06:19.990",
      "end": "00:06:20.000",
      "text": "very useful uh with padding this is we"
    },
    {
      "start": "00:06:20.000",
      "end": "00:06:24.589",
      "text": "very useful uh with padding this is we avoid that and uh here we actually have"
    },
    {
      "start": "00:06:24.589",
      "end": "00:06:24.599",
      "text": "avoid that and uh here we actually have"
    },
    {
      "start": "00:06:24.599",
      "end": "00:06:26.710",
      "text": "avoid that and uh here we actually have uh padding combinations of padding and"
    },
    {
      "start": "00:06:26.710",
      "end": "00:06:26.720",
      "text": "uh padding combinations of padding and"
    },
    {
      "start": "00:06:26.720",
      "end": "00:06:29.790",
      "text": "uh padding combinations of padding and stride so I suggest that you study this"
    },
    {
      "start": "00:06:29.790",
      "end": "00:06:29.800",
      "text": "stride so I suggest that you study this"
    },
    {
      "start": "00:06:29.800",
      "end": "00:06:31.830",
      "text": "stride so I suggest that you study this kind of animations to just get the gist"
    },
    {
      "start": "00:06:31.830",
      "end": "00:06:31.840",
      "text": "kind of animations to just get the gist"
    },
    {
      "start": "00:06:31.840",
      "end": "00:06:33.830",
      "text": "kind of animations to just get the gist as to what padding and stride are"
    },
    {
      "start": "00:06:33.830",
      "end": "00:06:33.840",
      "text": "as to what padding and stride are"
    },
    {
      "start": "00:06:33.840",
      "end": "00:06:37.150",
      "text": "as to what padding and stride are actually offering to us but uh now the"
    },
    {
      "start": "00:06:37.150",
      "end": "00:06:37.160",
      "text": "actually offering to us but uh now the"
    },
    {
      "start": "00:06:37.160",
      "end": "00:06:40.150",
      "text": "actually offering to us but uh now the time has come to look at uh the"
    },
    {
      "start": "00:06:40.150",
      "end": "00:06:40.160",
      "text": "time has come to look at uh the"
    },
    {
      "start": "00:06:40.160",
      "end": "00:06:43.189",
      "text": "time has come to look at uh the operation of the convolutional neuron"
    },
    {
      "start": "00:06:43.189",
      "end": "00:06:43.199",
      "text": "operation of the convolutional neuron"
    },
    {
      "start": "00:06:43.199",
      "end": "00:06:47.110",
      "text": "operation of the convolutional neuron Network um and in fact the describe if"
    },
    {
      "start": "00:06:47.110",
      "end": "00:06:47.120",
      "text": "Network um and in fact the describe if"
    },
    {
      "start": "00:06:47.120",
      "end": "00:06:49.070",
      "text": "Network um and in fact the describe if you like the single convolutional kind"
    },
    {
      "start": "00:06:49.070",
      "end": "00:06:49.080",
      "text": "you like the single convolutional kind"
    },
    {
      "start": "00:06:49.080",
      "end": "00:06:52.950",
      "text": "you like the single convolutional kind of layer um in in detail we will uh"
    },
    {
      "start": "00:06:52.950",
      "end": "00:06:52.960",
      "text": "of layer um in in detail we will uh"
    },
    {
      "start": "00:06:52.960",
      "end": "00:06:56.189",
      "text": "of layer um in in detail we will uh start drawing a snapshot of a CNN layer"
    },
    {
      "start": "00:06:56.189",
      "end": "00:06:56.199",
      "text": "start drawing a snapshot of a CNN layer"
    },
    {
      "start": "00:06:56.199",
      "end": "00:06:58.510",
      "text": "start drawing a snapshot of a CNN layer operation that will actually help us to"
    },
    {
      "start": "00:06:58.510",
      "end": "00:06:58.520",
      "text": "operation that will actually help us to"
    },
    {
      "start": "00:06:58.520",
      "end": "00:07:00.270",
      "text": "operation that will actually help us to understand the general case"
    },
    {
      "start": "00:07:00.270",
      "end": "00:07:00.280",
      "text": "understand the general case"
    },
    {
      "start": "00:07:00.280",
      "end": "00:07:04.110",
      "text": "understand the general case where we have uh input U and output"
    },
    {
      "start": "00:07:04.110",
      "end": "00:07:04.120",
      "text": "where we have uh input U and output"
    },
    {
      "start": "00:07:04.120",
      "end": "00:07:06.909",
      "text": "where we have uh input U and output feature Maps coming into uh the CNN"
    },
    {
      "start": "00:07:06.909",
      "end": "00:07:06.919",
      "text": "feature Maps coming into uh the CNN"
    },
    {
      "start": "00:07:06.919",
      "end": "00:07:09.390",
      "text": "feature Maps coming into uh the CNN layer uh but however these input and"
    },
    {
      "start": "00:07:09.390",
      "end": "00:07:09.400",
      "text": "layer uh but however these input and"
    },
    {
      "start": "00:07:09.400",
      "end": "00:07:12.510",
      "text": "layer uh but however these input and output feature Maps possess different"
    },
    {
      "start": "00:07:12.510",
      "end": "00:07:12.520",
      "text": "output feature Maps possess different"
    },
    {
      "start": "00:07:12.520",
      "end": "00:07:15.309",
      "text": "output feature Maps possess different depths and this is another parameter"
    },
    {
      "start": "00:07:15.309",
      "end": "00:07:15.319",
      "text": "depths and this is another parameter"
    },
    {
      "start": "00:07:15.319",
      "end": "00:07:17.710",
      "text": "depths and this is another parameter that we have to uh understand you know"
    },
    {
      "start": "00:07:17.710",
      "end": "00:07:17.720",
      "text": "that we have to uh understand you know"
    },
    {
      "start": "00:07:17.720",
      "end": "00:07:19.589",
      "text": "that we have to uh understand you know that the we are responsible for"
    },
    {
      "start": "00:07:19.589",
      "end": "00:07:19.599",
      "text": "that the we are responsible for"
    },
    {
      "start": "00:07:19.599",
      "end": "00:07:22.749",
      "text": "that the we are responsible for Designing these layers with uh that that"
    },
    {
      "start": "00:07:22.749",
      "end": "00:07:22.759",
      "text": "Designing these layers with uh that that"
    },
    {
      "start": "00:07:22.759",
      "end": "00:07:25.150",
      "text": "Designing these layers with uh that that the depth of uh what we will produce is"
    },
    {
      "start": "00:07:25.150",
      "end": "00:07:25.160",
      "text": "the depth of uh what we will produce is"
    },
    {
      "start": "00:07:25.160",
      "end": "00:07:28.749",
      "text": "the depth of uh what we will produce is our responsibility to uh to to design so"
    },
    {
      "start": "00:07:28.749",
      "end": "00:07:28.759",
      "text": "our responsibility to uh to to design so"
    },
    {
      "start": "00:07:28.759",
      "end": "00:07:31.710",
      "text": "our responsibility to uh to to design so let's uh write now uh draw if you like a"
    },
    {
      "start": "00:07:31.710",
      "end": "00:07:31.720",
      "text": "let's uh write now uh draw if you like a"
    },
    {
      "start": "00:07:31.720",
      "end": "00:07:35.510",
      "text": "let's uh write now uh draw if you like a a picture of that CNN uh layer in"
    },
    {
      "start": "00:07:35.510",
      "end": "00:07:35.520",
      "text": "a picture of that CNN uh layer in"
    },
    {
      "start": "00:07:35.520",
      "end": "00:07:38.629",
      "text": "a picture of that CNN uh layer in operation okay let me call it the the"
    },
    {
      "start": "00:07:38.629",
      "end": "00:07:38.639",
      "text": "operation okay let me call it the the"
    },
    {
      "start": "00:07:38.639",
      "end": "00:07:40.670",
      "text": "operation okay let me call it the the snapshot we will see just a single"
    },
    {
      "start": "00:07:40.670",
      "end": "00:07:40.680",
      "text": "snapshot we will see just a single"
    },
    {
      "start": "00:07:40.680",
      "end": "00:07:42.670",
      "text": "snapshot we will see just a single snapshot of that"
    },
    {
      "start": "00:07:42.670",
      "end": "00:07:42.680",
      "text": "snapshot of that"
    },
    {
      "start": "00:07:42.680",
      "end": "00:07:45.270",
      "text": "snapshot of that layer and this will also help us"
    },
    {
      "start": "00:07:45.270",
      "end": "00:07:45.280",
      "text": "layer and this will also help us"
    },
    {
      "start": "00:07:45.280",
      "end": "00:07:47.710",
      "text": "layer and this will also help us understand the U what is the"
    },
    {
      "start": "00:07:47.710",
      "end": "00:07:47.720",
      "text": "understand the U what is the"
    },
    {
      "start": "00:07:47.720",
      "end": "00:07:49.350",
      "text": "understand the U what is the convolutional neuron we already have"
    },
    {
      "start": "00:07:49.350",
      "end": "00:07:49.360",
      "text": "convolutional neuron we already have"
    },
    {
      "start": "00:07:49.360",
      "end": "00:07:53.270",
      "text": "convolutional neuron we already have seen the um sort of sigmoidal kind of"
    },
    {
      "start": "00:07:53.270",
      "end": "00:07:53.280",
      "text": "seen the um sort of sigmoidal kind of"
    },
    {
      "start": "00:07:53.280",
      "end": "00:07:55.909",
      "text": "seen the um sort of sigmoidal kind of neuron um now we will see in the in the"
    },
    {
      "start": "00:07:55.909",
      "end": "00:07:55.919",
      "text": "neuron um now we will see in the in the"
    },
    {
      "start": "00:07:55.919",
      "end": "00:07:57.629",
      "text": "neuron um now we will see in the in the fully connected dense layer"
    },
    {
      "start": "00:07:57.629",
      "end": "00:07:57.639",
      "text": "fully connected dense layer"
    },
    {
      "start": "00:07:57.639",
      "end": "00:07:59.950",
      "text": "fully connected dense layer architectures now we'll see the"
    },
    {
      "start": "00:07:59.950",
      "end": "00:07:59.960",
      "text": "architectures now we'll see the"
    },
    {
      "start": "00:07:59.960",
      "end": "00:08:01.909",
      "text": "architectures now we'll see the convolutional neuron in front of us so"
    },
    {
      "start": "00:08:01.909",
      "end": "00:08:01.919",
      "text": "convolutional neuron in front of us so"
    },
    {
      "start": "00:08:01.919",
      "end": "00:08:03.909",
      "text": "convolutional neuron in front of us so the snapshot let me call it snapshot of"
    },
    {
      "start": "00:08:03.909",
      "end": "00:08:03.919",
      "text": "the snapshot let me call it snapshot of"
    },
    {
      "start": "00:08:03.919",
      "end": "00:08:05.430",
      "text": "the snapshot let me call it snapshot of a"
    },
    {
      "start": "00:08:05.430",
      "end": "00:08:05.440",
      "text": "a"
    },
    {
      "start": "00:08:05.440",
      "end": "00:08:09.990",
      "text": "a CNN of a CNN"
    },
    {
      "start": "00:08:19.230",
      "end": "00:08:19.240",
      "text": "operation all right so let's uh draw now"
    },
    {
      "start": "00:08:19.240",
      "end": "00:08:21.510",
      "text": "operation all right so let's uh draw now the general case as we discussed that we"
    },
    {
      "start": "00:08:21.510",
      "end": "00:08:21.520",
      "text": "the general case as we discussed that we"
    },
    {
      "start": "00:08:21.520",
      "end": "00:08:32.029",
      "text": "the general case as we discussed that we have an input volume"
    },
    {
      "start": "00:08:33.389",
      "end": "00:08:33.399",
      "text": "this input"
    },
    {
      "start": "00:08:33.399",
      "end": "00:08:38.630",
      "text": "this input volume um is uh associated with h uh the"
    },
    {
      "start": "00:08:38.630",
      "end": "00:08:38.640",
      "text": "volume um is uh associated with h uh the"
    },
    {
      "start": "00:08:38.640",
      "end": "00:08:41.790",
      "text": "volume um is uh associated with h uh the output feature map of an earlier layer"
    },
    {
      "start": "00:08:41.790",
      "end": "00:08:41.800",
      "text": "output feature map of an earlier layer"
    },
    {
      "start": "00:08:41.800",
      "end": "00:08:43.870",
      "text": "output feature map of an earlier layer let's call that layer l minus one this"
    },
    {
      "start": "00:08:43.870",
      "end": "00:08:43.880",
      "text": "let's call that layer l minus one this"
    },
    {
      "start": "00:08:43.880",
      "end": "00:08:46.190",
      "text": "let's call that layer l minus one this is basically the feature map that was"
    },
    {
      "start": "00:08:46.190",
      "end": "00:08:46.200",
      "text": "is basically the feature map that was"
    },
    {
      "start": "00:08:46.200",
      "end": "00:08:48.350",
      "text": "is basically the feature map that was generated by the previous layer in"
    },
    {
      "start": "00:08:48.350",
      "end": "00:08:48.360",
      "text": "generated by the previous layer in"
    },
    {
      "start": "00:08:48.360",
      "end": "00:08:52.470",
      "text": "generated by the previous layer in general and we'll have a depth of"
    },
    {
      "start": "00:08:52.470",
      "end": "00:08:52.480",
      "text": "general and we'll have a depth of"
    },
    {
      "start": "00:08:52.480",
      "end": "00:08:55.870",
      "text": "general and we'll have a depth of capital m l minus"
    },
    {
      "start": "00:08:55.870",
      "end": "00:08:55.880",
      "text": "capital m l minus"
    },
    {
      "start": "00:08:55.880",
      "end": "00:09:01.350",
      "text": "capital m l minus one it will have some kind of width"
    },
    {
      "start": "00:09:01.350",
      "end": "00:09:01.360",
      "text": "one it will have some kind of width"
    },
    {
      "start": "00:09:01.360",
      "end": "00:09:03.190",
      "text": "one it will have some kind of width let me uh make sure that you can"
    },
    {
      "start": "00:09:03.190",
      "end": "00:09:03.200",
      "text": "let me uh make sure that you can"
    },
    {
      "start": "00:09:03.200",
      "end": "00:09:04.710",
      "text": "let me uh make sure that you can actually"
    },
    {
      "start": "00:09:04.710",
      "end": "00:09:04.720",
      "text": "actually"
    },
    {
      "start": "00:09:04.720",
      "end": "00:09:08.230",
      "text": "actually see here this is WL minus"
    },
    {
      "start": "00:09:08.230",
      "end": "00:09:08.240",
      "text": "see here this is WL minus"
    },
    {
      "start": "00:09:08.240",
      "end": "00:09:09.870",
      "text": "see here this is WL minus one"
    },
    {
      "start": "00:09:09.870",
      "end": "00:09:09.880",
      "text": "one"
    },
    {
      "start": "00:09:09.880",
      "end": "00:09:13.630",
      "text": "one and uh the height over here would"
    },
    {
      "start": "00:09:13.630",
      "end": "00:09:13.640",
      "text": "and uh the height over here would"
    },
    {
      "start": "00:09:13.640",
      "end": "00:09:17.350",
      "text": "and uh the height over here would actually be um okay this is a depth and"
    },
    {
      "start": "00:09:17.350",
      "end": "00:09:17.360",
      "text": "actually be um okay this is a depth and"
    },
    {
      "start": "00:09:17.360",
      "end": "00:09:21.230",
      "text": "actually be um okay this is a depth and the height over here will actually be"
    },
    {
      "start": "00:09:21.230",
      "end": "00:09:21.240",
      "text": "the height over here will actually be"
    },
    {
      "start": "00:09:21.240",
      "end": "00:09:24.630",
      "text": "the height over here will actually be h l minus one all right so that's"
    },
    {
      "start": "00:09:24.630",
      "end": "00:09:24.640",
      "text": "h l minus one all right so that's"
    },
    {
      "start": "00:09:24.640",
      "end": "00:09:27.790",
      "text": "h l minus one all right so that's basically the dimensions of my incoming"
    },
    {
      "start": "00:09:27.790",
      "end": "00:09:27.800",
      "text": "basically the dimensions of my incoming"
    },
    {
      "start": "00:09:27.800",
      "end": "00:09:32.670",
      "text": "basically the dimensions of my incoming volume um and this incoming volume"
    },
    {
      "start": "00:09:32.670",
      "end": "00:09:32.680",
      "text": "volume um and this incoming volume"
    },
    {
      "start": "00:09:32.680",
      "end": "00:09:36.150",
      "text": "volume um and this incoming volume has some kind of resolution in terms of"
    },
    {
      "start": "00:09:36.150",
      "end": "00:09:36.160",
      "text": "has some kind of resolution in terms of"
    },
    {
      "start": "00:09:36.160",
      "end": "00:09:40.269",
      "text": "has some kind of resolution in terms of number of height and width pixels let me"
    },
    {
      "start": "00:09:40.269",
      "end": "00:09:40.279",
      "text": "number of height and width pixels let me"
    },
    {
      "start": "00:09:40.279",
      "end": "00:09:43.150",
      "text": "number of height and width pixels let me just draw them quickly because we would"
    },
    {
      "start": "00:09:43.150",
      "end": "00:09:43.160",
      "text": "just draw them quickly because we would"
    },
    {
      "start": "00:09:43.160",
      "end": "00:09:43.949",
      "text": "just draw them quickly because we would like"
    },
    {
      "start": "00:09:43.949",
      "end": "00:09:43.959",
      "text": "like"
    },
    {
      "start": "00:09:43.959",
      "end": "00:09:47.389",
      "text": "like to now draw the U what will be the"
    },
    {
      "start": "00:09:47.389",
      "end": "00:09:47.399",
      "text": "to now draw the U what will be the"
    },
    {
      "start": "00:09:47.399",
      "end": "00:09:49.590",
      "text": "to now draw the U what will be the output of out of this operation which is"
    },
    {
      "start": "00:09:49.590",
      "end": "00:09:49.600",
      "text": "output of out of this operation which is"
    },
    {
      "start": "00:09:49.600",
      "end": "00:09:53.750",
      "text": "output of out of this operation which is the output feature map now the"
    },
    {
      "start": "00:09:53.750",
      "end": "00:09:53.760",
      "text": "the output feature map now the"
    },
    {
      "start": "00:09:53.760",
      "end": "00:09:56.750",
      "text": "the output feature map now the um output is going to be generated at"
    },
    {
      "start": "00:09:56.750",
      "end": "00:09:56.760",
      "text": "um output is going to be generated at"
    },
    {
      "start": "00:09:56.760",
      "end": "00:09:59.710",
      "text": "um output is going to be generated at this specific moment in time I have in"
    },
    {
      "start": "00:09:59.710",
      "end": "00:09:59.720",
      "text": "this specific moment in time I have in"
    },
    {
      "start": "00:09:59.720",
      "end": "00:10:02.790",
      "text": "this specific moment in time I have in general a filter that"
    },
    {
      "start": "00:10:02.790",
      "end": "00:10:02.800",
      "text": "general a filter that"
    },
    {
      "start": "00:10:02.800",
      "end": "00:10:06.509",
      "text": "general a filter that has 3x3 special extent it is located"
    },
    {
      "start": "00:10:06.509",
      "end": "00:10:06.519",
      "text": "has 3x3 special extent it is located"
    },
    {
      "start": "00:10:06.519",
      "end": "00:10:08.310",
      "text": "has 3x3 special extent it is located let's say here at this moment in time"
    },
    {
      "start": "00:10:08.310",
      "end": "00:10:08.320",
      "text": "let's say here at this moment in time"
    },
    {
      "start": "00:10:08.320",
      "end": "00:10:09.910",
      "text": "let's say here at this moment in time because that's why you call it a"
    },
    {
      "start": "00:10:09.910",
      "end": "00:10:09.920",
      "text": "because that's why you call it a"
    },
    {
      "start": "00:10:09.920",
      "end": "00:10:15.350",
      "text": "because that's why you call it a snapshot and uh it has um some depth I"
    },
    {
      "start": "00:10:15.350",
      "end": "00:10:15.360",
      "text": "snapshot and uh it has um some depth I"
    },
    {
      "start": "00:10:15.360",
      "end": "00:10:17.150",
      "text": "snapshot and uh it has um some depth I want to discuss a little bit the depth"
    },
    {
      "start": "00:10:17.150",
      "end": "00:10:17.160",
      "text": "want to discuss a little bit the depth"
    },
    {
      "start": "00:10:17.160",
      "end": "00:10:18.790",
      "text": "want to discuss a little bit the depth what makes sense for this depth of the"
    },
    {
      "start": "00:10:18.790",
      "end": "00:10:18.800",
      "text": "what makes sense for this depth of the"
    },
    {
      "start": "00:10:18.800",
      "end": "00:10:21.470",
      "text": "what makes sense for this depth of the filter to be uh but it when it is"
    },
    {
      "start": "00:10:21.470",
      "end": "00:10:21.480",
      "text": "filter to be uh but it when it is"
    },
    {
      "start": "00:10:21.480",
      "end": "00:10:23.509",
      "text": "filter to be uh but it when it is located over here uh for sure I'm"
    },
    {
      "start": "00:10:23.509",
      "end": "00:10:23.519",
      "text": "located over here uh for sure I'm"
    },
    {
      "start": "00:10:23.519",
      "end": "00:10:27.069",
      "text": "located over here uh for sure I'm expecting to have some output feature"
    },
    {
      "start": "00:10:27.069",
      "end": "00:10:27.079",
      "text": "expecting to have some output feature"
    },
    {
      "start": "00:10:27.079",
      "end": "00:10:31.269",
      "text": "expecting to have some output feature map this output feature map will be uh"
    },
    {
      "start": "00:10:31.269",
      "end": "00:10:31.279",
      "text": "map this output feature map will be uh"
    },
    {
      "start": "00:10:31.279",
      "end": "00:10:36.629",
      "text": "map this output feature map will be uh probably"
    },
    {
      "start": "00:10:40.069",
      "end": "00:10:40.079",
      "text": "uh smaller in terms of spal extent"
    },
    {
      "start": "00:10:40.079",
      "end": "00:10:41.590",
      "text": "uh smaller in terms of spal extent that's why I'm kind of drawing it like"
    },
    {
      "start": "00:10:41.590",
      "end": "00:10:41.600",
      "text": "that's why I'm kind of drawing it like"
    },
    {
      "start": "00:10:41.600",
      "end": "00:10:45.470",
      "text": "that's why I'm kind of drawing it like this it has some kind of a number"
    },
    {
      "start": "00:10:45.470",
      "end": "00:10:45.480",
      "text": "this it has some kind of a number"
    },
    {
      "start": "00:10:45.480",
      "end": "00:10:50.069",
      "text": "this it has some kind of a number of"
    },
    {
      "start": "00:10:52.590",
      "end": "00:10:52.600",
      "text": "pixels okay and we have some kind of a"
    },
    {
      "start": "00:10:52.600",
      "end": "00:10:56.710",
      "text": "pixels okay and we have some kind of a depth and this depth is definitely um"
    },
    {
      "start": "00:10:56.710",
      "end": "00:10:56.720",
      "text": "depth and this depth is definitely um"
    },
    {
      "start": "00:10:56.720",
      "end": "00:10:59.550",
      "text": "depth and this depth is definitely um something that I need to control uh"
    },
    {
      "start": "00:10:59.550",
      "end": "00:10:59.560",
      "text": "something that I need to control uh"
    },
    {
      "start": "00:10:59.560",
      "end": "00:11:03.190",
      "text": "something that I need to control uh because uh uh it's one of my main design"
    },
    {
      "start": "00:11:03.190",
      "end": "00:11:03.200",
      "text": "because uh uh it's one of my main design"
    },
    {
      "start": "00:11:03.200",
      "end": "00:11:07.509",
      "text": "because uh uh it's one of my main design parameters I'll be calling this depth"
    },
    {
      "start": "00:11:07.509",
      "end": "00:11:07.519",
      "text": "parameters I'll be calling this depth"
    },
    {
      "start": "00:11:07.519",
      "end": "00:11:10.910",
      "text": "parameters I'll be calling this depth ML and evidently we have a"
    },
    {
      "start": "00:11:10.910",
      "end": "00:11:10.920",
      "text": "ML and evidently we have a"
    },
    {
      "start": "00:11:10.920",
      "end": "00:11:16.470",
      "text": "ML and evidently we have a different HL and WL"
    },
    {
      "start": "00:11:16.470",
      "end": "00:11:16.480",
      "text": "different HL and WL"
    },
    {
      "start": "00:11:16.480",
      "end": "00:11:19.310",
      "text": "different HL and WL dimensions and this is basically my uh"
    },
    {
      "start": "00:11:19.310",
      "end": "00:11:19.320",
      "text": "dimensions and this is basically my uh"
    },
    {
      "start": "00:11:19.320",
      "end": "00:11:21.550",
      "text": "dimensions and this is basically my uh you know volumes input and output"
    },
    {
      "start": "00:11:21.550",
      "end": "00:11:21.560",
      "text": "you know volumes input and output"
    },
    {
      "start": "00:11:21.560",
      "end": "00:11:23.069",
      "text": "you know volumes input and output volumes in general going to have input"
    },
    {
      "start": "00:11:23.069",
      "end": "00:11:23.079",
      "text": "volumes in general going to have input"
    },
    {
      "start": "00:11:23.079",
      "end": "00:11:26.389",
      "text": "volumes in general going to have input and output fors so um the question I"
    },
    {
      "start": "00:11:26.389",
      "end": "00:11:26.399",
      "text": "and output fors so um the question I"
    },
    {
      "start": "00:11:26.399",
      "end": "00:11:29.350",
      "text": "and output fors so um the question I actually have right now is to understand"
    },
    {
      "start": "00:11:29.350",
      "end": "00:11:29.360",
      "text": "actually have right now is to understand"
    },
    {
      "start": "00:11:29.360",
      "end": "00:11:32.110",
      "text": "actually have right now is to understand a little bit about the depth of the"
    },
    {
      "start": "00:11:32.110",
      "end": "00:11:32.120",
      "text": "a little bit about the depth of the"
    },
    {
      "start": "00:11:32.120",
      "end": "00:11:35.710",
      "text": "a little bit about the depth of the filter and we have three options either"
    },
    {
      "start": "00:11:35.710",
      "end": "00:11:35.720",
      "text": "filter and we have three options either"
    },
    {
      "start": "00:11:35.720",
      "end": "00:11:39.030",
      "text": "filter and we have three options either the depth of the filter will actually be"
    },
    {
      "start": "00:11:39.030",
      "end": "00:11:39.040",
      "text": "the depth of the filter will actually be"
    },
    {
      "start": "00:11:39.040",
      "end": "00:11:43.310",
      "text": "the depth of the filter will actually be uh deeper than the input feature map uh"
    },
    {
      "start": "00:11:43.310",
      "end": "00:11:43.320",
      "text": "uh deeper than the input feature map uh"
    },
    {
      "start": "00:11:43.320",
      "end": "00:11:46.509",
      "text": "uh deeper than the input feature map uh shallower than the input feature map or"
    },
    {
      "start": "00:11:46.509",
      "end": "00:11:46.519",
      "text": "shallower than the input feature map or"
    },
    {
      "start": "00:11:46.519",
      "end": "00:11:48.590",
      "text": "shallower than the input feature map or exactly the same depth as the input"
    },
    {
      "start": "00:11:48.590",
      "end": "00:11:48.600",
      "text": "exactly the same depth as the input"
    },
    {
      "start": "00:11:48.600",
      "end": "00:11:51.949",
      "text": "exactly the same depth as the input feature map so let's try to do some kind"
    },
    {
      "start": "00:11:51.949",
      "end": "00:11:51.959",
      "text": "feature map so let's try to do some kind"
    },
    {
      "start": "00:11:51.959",
      "end": "00:11:54.590",
      "text": "feature map so let's try to do some kind of reasoning over here does it make any"
    },
    {
      "start": "00:11:54.590",
      "end": "00:11:54.600",
      "text": "of reasoning over here does it make any"
    },
    {
      "start": "00:11:54.600",
      "end": "00:11:57.310",
      "text": "of reasoning over here does it make any sense for the filter to be deeper than"
    },
    {
      "start": "00:11:57.310",
      "end": "00:11:57.320",
      "text": "sense for the filter to be deeper than"
    },
    {
      "start": "00:11:57.320",
      "end": "00:11:59.750",
      "text": "sense for the filter to be deeper than the input feature map and"
    },
    {
      "start": "00:11:59.750",
      "end": "00:11:59.760",
      "text": "the input feature map and"
    },
    {
      "start": "00:11:59.760",
      "end": "00:12:01.750",
      "text": "the input feature map and if you think about it the answer is no"
    },
    {
      "start": "00:12:01.750",
      "end": "00:12:01.760",
      "text": "if you think about it the answer is no"
    },
    {
      "start": "00:12:01.760",
      "end": "00:12:03.949",
      "text": "if you think about it the answer is no it does not really make a lot of sense"
    },
    {
      "start": "00:12:03.949",
      "end": "00:12:03.959",
      "text": "it does not really make a lot of sense"
    },
    {
      "start": "00:12:03.959",
      "end": "00:12:06.190",
      "text": "it does not really make a lot of sense because uh at the end of the day we are"
    },
    {
      "start": "00:12:06.190",
      "end": "00:12:06.200",
      "text": "because uh at the end of the day we are"
    },
    {
      "start": "00:12:06.200",
      "end": "00:12:08.150",
      "text": "because uh at the end of the day we are going to be correlating the contents of"
    },
    {
      "start": "00:12:08.150",
      "end": "00:12:08.160",
      "text": "going to be correlating the contents of"
    },
    {
      "start": "00:12:08.160",
      "end": "00:12:11.190",
      "text": "going to be correlating the contents of that filter uh with the contents of the"
    },
    {
      "start": "00:12:11.190",
      "end": "00:12:11.200",
      "text": "that filter uh with the contents of the"
    },
    {
      "start": "00:12:11.200",
      "end": "00:12:13.910",
      "text": "that filter uh with the contents of the input feature map and if the filter is"
    },
    {
      "start": "00:12:13.910",
      "end": "00:12:13.920",
      "text": "input feature map and if the filter is"
    },
    {
      "start": "00:12:13.920",
      "end": "00:12:16.670",
      "text": "input feature map and if the filter is actually deeper then uh we are not going"
    },
    {
      "start": "00:12:16.670",
      "end": "00:12:16.680",
      "text": "actually deeper then uh we are not going"
    },
    {
      "start": "00:12:16.680",
      "end": "00:12:18.949",
      "text": "actually deeper then uh we are not going to be picking up anything from the input"
    },
    {
      "start": "00:12:18.949",
      "end": "00:12:18.959",
      "text": "to be picking up anything from the input"
    },
    {
      "start": "00:12:18.959",
      "end": "00:12:21.350",
      "text": "to be picking up anything from the input feature map because we are going to uh"
    },
    {
      "start": "00:12:21.350",
      "end": "00:12:21.360",
      "text": "feature map because we are going to uh"
    },
    {
      "start": "00:12:21.360",
      "end": "00:12:23.550",
      "text": "feature map because we are going to uh so why have it deeper okay so you know"
    },
    {
      "start": "00:12:23.550",
      "end": "00:12:23.560",
      "text": "so why have it deeper okay so you know"
    },
    {
      "start": "00:12:23.560",
      "end": "00:12:26.189",
      "text": "so why have it deeper okay so you know there's no point of of doing so if it is"
    },
    {
      "start": "00:12:26.189",
      "end": "00:12:26.199",
      "text": "there's no point of of doing so if it is"
    },
    {
      "start": "00:12:26.199",
      "end": "00:12:28.350",
      "text": "there's no point of of doing so if it is shallower than the input feature map"
    },
    {
      "start": "00:12:28.350",
      "end": "00:12:28.360",
      "text": "shallower than the input feature map"
    },
    {
      "start": "00:12:28.360",
      "end": "00:12:29.829",
      "text": "shallower than the input feature map also it does not really make a lot of"
    },
    {
      "start": "00:12:29.829",
      "end": "00:12:29.839",
      "text": "also it does not really make a lot of"
    },
    {
      "start": "00:12:29.839",
      "end": "00:12:33.069",
      "text": "also it does not really make a lot of sense because uh we are going to leave"
    },
    {
      "start": "00:12:33.069",
      "end": "00:12:33.079",
      "text": "sense because uh we are going to leave"
    },
    {
      "start": "00:12:33.079",
      "end": "00:12:36.910",
      "text": "sense because uh we are going to leave content uh that the input feature map U"
    },
    {
      "start": "00:12:36.910",
      "end": "00:12:36.920",
      "text": "content uh that the input feature map U"
    },
    {
      "start": "00:12:36.920",
      "end": "00:12:40.790",
      "text": "content uh that the input feature map U contains for us uh on the table so uh"
    },
    {
      "start": "00:12:40.790",
      "end": "00:12:40.800",
      "text": "contains for us uh on the table so uh"
    },
    {
      "start": "00:12:40.800",
      "end": "00:12:43.629",
      "text": "contains for us uh on the table so uh the so the only reasonable assumption is"
    },
    {
      "start": "00:12:43.629",
      "end": "00:12:43.639",
      "text": "the so the only reasonable assumption is"
    },
    {
      "start": "00:12:43.639",
      "end": "00:12:45.269",
      "text": "the so the only reasonable assumption is this filter to"
    },
    {
      "start": "00:12:45.269",
      "end": "00:12:45.279",
      "text": "this filter to"
    },
    {
      "start": "00:12:45.279",
      "end": "00:12:48.990",
      "text": "this filter to be exactly the same in terms of the"
    },
    {
      "start": "00:12:48.990",
      "end": "00:12:49.000",
      "text": "be exactly the same in terms of the"
    },
    {
      "start": "00:12:49.000",
      "end": "00:12:51.550",
      "text": "be exactly the same in terms of the input feature map depth right in terms"
    },
    {
      "start": "00:12:51.550",
      "end": "00:12:51.560",
      "text": "input feature map depth right in terms"
    },
    {
      "start": "00:12:51.560",
      "end": "00:12:54.670",
      "text": "input feature map depth right in terms of this terms of depth of the input F"
    },
    {
      "start": "00:12:54.670",
      "end": "00:12:54.680",
      "text": "of this terms of depth of the input F"
    },
    {
      "start": "00:12:54.680",
      "end": "00:12:56.910",
      "text": "of this terms of depth of the input F map so it's just basically draw it as as"
    },
    {
      "start": "00:12:56.910",
      "end": "00:12:56.920",
      "text": "map so it's just basically draw it as as"
    },
    {
      "start": "00:12:56.920",
      "end": "00:12:59.990",
      "text": "map so it's just basically draw it as as such and uh it in fact it is really this"
    },
    {
      "start": "00:12:59.990",
      "end": "00:13:00.000",
      "text": "such and uh it in fact it is really this"
    },
    {
      "start": "00:13:00.000",
      "end": "00:13:04.509",
      "text": "such and uh it in fact it is really this filter uh that is going to be"
    },
    {
      "start": "00:13:04.509",
      "end": "00:13:04.519",
      "text": "filter uh that is going to be"
    },
    {
      "start": "00:13:04.519",
      "end": "00:13:07.629",
      "text": "filter uh that is going to be a going to be the uh the one that we are"
    },
    {
      "start": "00:13:07.629",
      "end": "00:13:07.639",
      "text": "a going to be the uh the one that we are"
    },
    {
      "start": "00:13:07.639",
      "end": "00:13:09.750",
      "text": "a going to be the uh the one that we are going to be using to do this kind of a"
    },
    {
      "start": "00:13:09.750",
      "end": "00:13:09.760",
      "text": "going to be using to do this kind of a"
    },
    {
      "start": "00:13:09.760",
      "end": "00:13:12.550",
      "text": "going to be using to do this kind of a three-dimensional kind of a correlation"
    },
    {
      "start": "00:13:12.550",
      "end": "00:13:12.560",
      "text": "three-dimensional kind of a correlation"
    },
    {
      "start": "00:13:12.560",
      "end": "00:13:14.350",
      "text": "three-dimensional kind of a correlation over here now to understand the contents"
    },
    {
      "start": "00:13:14.350",
      "end": "00:13:14.360",
      "text": "over here now to understand the contents"
    },
    {
      "start": "00:13:14.360",
      "end": "00:13:17.189",
      "text": "over here now to understand the contents of that correlation is kind of important"
    },
    {
      "start": "00:13:17.189",
      "end": "00:13:17.199",
      "text": "of that correlation is kind of important"
    },
    {
      "start": "00:13:17.199",
      "end": "00:13:19.150",
      "text": "of that correlation is kind of important and what is actually even more important"
    },
    {
      "start": "00:13:19.150",
      "end": "00:13:19.160",
      "text": "and what is actually even more important"
    },
    {
      "start": "00:13:19.160",
      "end": "00:13:21.550",
      "text": "and what is actually even more important to understand what it will generate as"
    },
    {
      "start": "00:13:21.550",
      "end": "00:13:21.560",
      "text": "to understand what it will generate as"
    },
    {
      "start": "00:13:21.560",
      "end": "00:13:24.590",
      "text": "to understand what it will generate as we will see shortly what it will not"
    },
    {
      "start": "00:13:24.590",
      "end": "00:13:24.600",
      "text": "we will see shortly what it will not"
    },
    {
      "start": "00:13:24.600",
      "end": "00:13:26.829",
      "text": "we will see shortly what it will not generate it will not generate the whole"
    },
    {
      "start": "00:13:26.829",
      "end": "00:13:26.839",
      "text": "generate it will not generate the whole"
    },
    {
      "start": "00:13:26.839",
      "end": "00:13:29.110",
      "text": "generate it will not generate the whole volume over here but it will actually"
    },
    {
      "start": "00:13:29.110",
      "end": "00:13:29.120",
      "text": "volume over here but it will actually"
    },
    {
      "start": "00:13:29.120",
      "end": "00:13:31.189",
      "text": "volume over here but it will actually generate only one slice out of that"
    },
    {
      "start": "00:13:31.189",
      "end": "00:13:31.199",
      "text": "generate only one slice out of that"
    },
    {
      "start": "00:13:31.199",
      "end": "00:13:34.069",
      "text": "generate only one slice out of that output volume okay to understand that"
    },
    {
      "start": "00:13:34.069",
      "end": "00:13:34.079",
      "text": "output volume okay to understand that"
    },
    {
      "start": "00:13:34.079",
      "end": "00:13:37.110",
      "text": "output volume okay to understand that kind of important Point uh let's uh do"
    },
    {
      "start": "00:13:37.110",
      "end": "00:13:37.120",
      "text": "kind of important Point uh let's uh do"
    },
    {
      "start": "00:13:37.120",
      "end": "00:13:41.750",
      "text": "kind of important Point uh let's uh do the following let me take uh the uh um"
    },
    {
      "start": "00:13:41.750",
      "end": "00:13:41.760",
      "text": "the following let me take uh the uh um"
    },
    {
      "start": "00:13:41.760",
      "end": "00:13:45.590",
      "text": "the following let me take uh the uh um um sort of so for that specific snapshot"
    },
    {
      "start": "00:13:45.590",
      "end": "00:13:45.600",
      "text": "um sort of so for that specific snapshot"
    },
    {
      "start": "00:13:45.600",
      "end": "00:13:49.069",
      "text": "um sort of so for that specific snapshot that I'm actually uh right now I'm"
    },
    {
      "start": "00:13:49.069",
      "end": "00:13:49.079",
      "text": "that I'm actually uh right now I'm"
    },
    {
      "start": "00:13:49.079",
      "end": "00:13:52.910",
      "text": "that I'm actually uh right now I'm generating the"
    },
    {
      "start": "00:13:56.670",
      "end": "00:13:56.680",
      "text": "specific let me drew that like uh like"
    },
    {
      "start": "00:13:56.680",
      "end": "00:14:01.389",
      "text": "specific let me drew that like uh like there some"
    },
    {
      "start": "00:14:07.110",
      "end": "00:14:07.120",
      "text": "specific result which is a scaler"
    },
    {
      "start": "00:14:07.120",
      "end": "00:14:09.230",
      "text": "specific result which is a scaler therefore it's a result of a single"
    },
    {
      "start": "00:14:09.230",
      "end": "00:14:09.240",
      "text": "therefore it's a result of a single"
    },
    {
      "start": "00:14:09.240",
      "end": "00:14:12.710",
      "text": "therefore it's a result of a single Pixel uh from this column which is"
    },
    {
      "start": "00:14:12.710",
      "end": "00:14:12.720",
      "text": "Pixel uh from this column which is"
    },
    {
      "start": "00:14:12.720",
      "end": "00:14:17.069",
      "text": "Pixel uh from this column which is located at the coordinate I comma"
    },
    {
      "start": "00:14:17.069",
      "end": "00:14:17.079",
      "text": "located at the coordinate I comma"
    },
    {
      "start": "00:14:17.079",
      "end": "00:14:19.790",
      "text": "located at the coordinate I comma J so specially wise and I hope you"
    },
    {
      "start": "00:14:19.790",
      "end": "00:14:19.800",
      "text": "J so specially wise and I hope you"
    },
    {
      "start": "00:14:19.800",
      "end": "00:14:22.430",
      "text": "J so specially wise and I hope you remember what we have seen earlier in"
    },
    {
      "start": "00:14:22.430",
      "end": "00:14:22.440",
      "text": "remember what we have seen earlier in"
    },
    {
      "start": "00:14:22.440",
      "end": "00:14:25.269",
      "text": "remember what we have seen earlier in the uh sort of example architecture"
    },
    {
      "start": "00:14:25.269",
      "end": "00:14:25.279",
      "text": "the uh sort of example architecture"
    },
    {
      "start": "00:14:25.279",
      "end": "00:14:28.470",
      "text": "the uh sort of example architecture sorry in the CNN architecture diagram uh"
    },
    {
      "start": "00:14:28.470",
      "end": "00:14:28.480",
      "text": "sorry in the CNN architecture diagram uh"
    },
    {
      "start": "00:14:28.480",
      "end": "00:14:31.350",
      "text": "sorry in the CNN architecture diagram uh we are let just show you U that kind of"
    },
    {
      "start": "00:14:31.350",
      "end": "00:14:31.360",
      "text": "we are let just show you U that kind of"
    },
    {
      "start": "00:14:31.360",
      "end": "00:14:34.629",
      "text": "we are let just show you U that kind of diagram again for that specific snapshot"
    },
    {
      "start": "00:14:34.629",
      "end": "00:14:34.639",
      "text": "diagram again for that specific snapshot"
    },
    {
      "start": "00:14:34.639",
      "end": "00:14:36.910",
      "text": "diagram again for that specific snapshot let's say the blue La snapshot I'm"
    },
    {
      "start": "00:14:36.910",
      "end": "00:14:36.920",
      "text": "let's say the blue La snapshot I'm"
    },
    {
      "start": "00:14:36.920",
      "end": "00:14:40.110",
      "text": "let's say the blue La snapshot I'm actually generating this scalar result"
    },
    {
      "start": "00:14:40.110",
      "end": "00:14:40.120",
      "text": "actually generating this scalar result"
    },
    {
      "start": "00:14:40.120",
      "end": "00:14:43.670",
      "text": "actually generating this scalar result um and using just one uh kernel a filter"
    },
    {
      "start": "00:14:43.670",
      "end": "00:14:43.680",
      "text": "um and using just one uh kernel a filter"
    },
    {
      "start": "00:14:43.680",
      "end": "00:14:47.550",
      "text": "um and using just one uh kernel a filter of depth one in this case so as it will"
    },
    {
      "start": "00:14:47.550",
      "end": "00:14:47.560",
      "text": "of depth one in this case so as it will"
    },
    {
      "start": "00:14:47.560",
      "end": "00:14:49.949",
      "text": "of depth one in this case so as it will actually as it actually turns out uh"
    },
    {
      "start": "00:14:49.949",
      "end": "00:14:49.959",
      "text": "actually as it actually turns out uh"
    },
    {
      "start": "00:14:49.959",
      "end": "00:14:51.949",
      "text": "actually as it actually turns out uh that fil uh that"
    },
    {
      "start": "00:14:51.949",
      "end": "00:14:51.959",
      "text": "that fil uh that"
    },
    {
      "start": "00:14:51.959",
      "end": "00:14:55.990",
      "text": "that fil uh that filter uh at that specific snapshot it"
    },
    {
      "start": "00:14:55.990",
      "end": "00:14:56.000",
      "text": "filter uh at that specific snapshot it"
    },
    {
      "start": "00:14:56.000",
      "end": "00:14:58.430",
      "text": "filter uh at that specific snapshot it will do a three-dimensional correlation"
    },
    {
      "start": "00:14:58.430",
      "end": "00:14:58.440",
      "text": "will do a three-dimensional correlation"
    },
    {
      "start": "00:14:58.440",
      "end": "00:14:59.670",
      "text": "will do a three-dimensional correlation and it will"
    },
    {
      "start": "00:14:59.670",
      "end": "00:14:59.680",
      "text": "and it will"
    },
    {
      "start": "00:14:59.680",
      "end": "00:15:03.069",
      "text": "and it will still generate a single scaler uh for me"
    },
    {
      "start": "00:15:03.069",
      "end": "00:15:03.079",
      "text": "still generate a single scaler uh for me"
    },
    {
      "start": "00:15:03.079",
      "end": "00:15:05.629",
      "text": "still generate a single scaler uh for me okay and that single scalar will be at a"
    },
    {
      "start": "00:15:05.629",
      "end": "00:15:05.639",
      "text": "okay and that single scalar will be at a"
    },
    {
      "start": "00:15:05.639",
      "end": "00:15:09.509",
      "text": "okay and that single scalar will be at a specific depth okay uh and the special"
    },
    {
      "start": "00:15:09.509",
      "end": "00:15:09.519",
      "text": "specific depth okay uh and the special"
    },
    {
      "start": "00:15:09.519",
      "end": "00:15:11.910",
      "text": "specific depth okay uh and the special coordinates of that scalar is I comma J"
    },
    {
      "start": "00:15:11.910",
      "end": "00:15:11.920",
      "text": "coordinates of that scalar is I comma J"
    },
    {
      "start": "00:15:11.920",
      "end": "00:15:15.509",
      "text": "coordinates of that scalar is I comma J that the one I just drew now uh we will"
    },
    {
      "start": "00:15:15.509",
      "end": "00:15:15.519",
      "text": "that the one I just drew now uh we will"
    },
    {
      "start": "00:15:15.519",
      "end": "00:15:19.030",
      "text": "that the one I just drew now uh we will call that depth with an index in a"
    },
    {
      "start": "00:15:19.030",
      "end": "00:15:19.040",
      "text": "call that depth with an index in a"
    },
    {
      "start": "00:15:19.040",
      "end": "00:15:22.230",
      "text": "call that depth with an index in a moment but what I want to um do here is"
    },
    {
      "start": "00:15:22.230",
      "end": "00:15:22.240",
      "text": "moment but what I want to um do here is"
    },
    {
      "start": "00:15:22.240",
      "end": "00:15:24.389",
      "text": "moment but what I want to um do here is to just draw the complete"
    },
    {
      "start": "00:15:24.389",
      "end": "00:15:24.399",
      "text": "to just draw the complete"
    },
    {
      "start": "00:15:24.399",
      "end": "00:15:26.749",
      "text": "to just draw the complete column"
    },
    {
      "start": "00:15:26.749",
      "end": "00:15:26.759",
      "text": "column"
    },
    {
      "start": "00:15:26.759",
      "end": "00:15:30.790",
      "text": "column of pixels at I comma J"
    },
    {
      "start": "00:15:30.790",
      "end": "00:15:30.800",
      "text": "of pixels at I comma J"
    },
    {
      "start": "00:15:30.800",
      "end": "00:15:34.790",
      "text": "of pixels at I comma J location let me just rotate them this"
    },
    {
      "start": "00:15:34.790",
      "end": "00:15:34.800",
      "text": "location let me just rotate them this"
    },
    {
      "start": "00:15:34.800",
      "end": "00:15:35.749",
      "text": "location let me just rotate them this column"
    },
    {
      "start": "00:15:35.749",
      "end": "00:15:35.759",
      "text": "column"
    },
    {
      "start": "00:15:35.759",
      "end": "00:15:41.829",
      "text": "column 90\u00b0 and write it over here it will be"
    },
    {
      "start": "00:15:41.829",
      "end": "00:15:41.839",
      "text": "90\u00b0 and write it over here it will be"
    },
    {
      "start": "00:15:41.839",
      "end": "00:15:45.590",
      "text": "90\u00b0 and write it over here it will be evidently this Dimension will be ml the"
    },
    {
      "start": "00:15:45.590",
      "end": "00:15:45.600",
      "text": "evidently this Dimension will be ml the"
    },
    {
      "start": "00:15:45.600",
      "end": "00:15:49.550",
      "text": "evidently this Dimension will be ml the depth Dimension and this is the uh"
    },
    {
      "start": "00:15:49.550",
      "end": "00:15:49.560",
      "text": "depth Dimension and this is the uh"
    },
    {
      "start": "00:15:49.560",
      "end": "00:15:51.629",
      "text": "depth Dimension and this is the uh because we are correspond to the earth"
    },
    {
      "start": "00:15:51.629",
      "end": "00:15:51.639",
      "text": "because we are correspond to the earth"
    },
    {
      "start": "00:15:51.639",
      "end": "00:15:54.069",
      "text": "because we are correspond to the earth layer and let me just do exactly the"
    },
    {
      "start": "00:15:54.069",
      "end": "00:15:54.079",
      "text": "layer and let me just do exactly the"
    },
    {
      "start": "00:15:54.079",
      "end": "00:15:55.509",
      "text": "layer and let me just do exactly the same thing with the filter so I'm"
    },
    {
      "start": "00:15:55.509",
      "end": "00:15:55.519",
      "text": "same thing with the filter so I'm"
    },
    {
      "start": "00:15:55.519",
      "end": "00:15:58.309",
      "text": "same thing with the filter so I'm actually taking the filter and uh"
    },
    {
      "start": "00:15:58.309",
      "end": "00:15:58.319",
      "text": "actually taking the filter and uh"
    },
    {
      "start": "00:15:58.319",
      "end": "00:16:02.030",
      "text": "actually taking the filter and uh decompose it it over here to the 3X3"
    },
    {
      "start": "00:16:02.030",
      "end": "00:16:02.040",
      "text": "decompose it it over here to the 3X3"
    },
    {
      "start": "00:16:02.040",
      "end": "00:16:04.870",
      "text": "decompose it it over here to the 3X3 Kels that it"
    },
    {
      "start": "00:16:04.870",
      "end": "00:16:04.880",
      "text": "Kels that it"
    },
    {
      "start": "00:16:04.880",
      "end": "00:16:07.949",
      "text": "Kels that it contains and so these are going to be my"
    },
    {
      "start": "00:16:07.949",
      "end": "00:16:07.959",
      "text": "contains and so these are going to be my"
    },
    {
      "start": "00:16:07.959",
      "end": "00:16:09.030",
      "text": "contains and so these are going to be my uh"
    },
    {
      "start": "00:16:09.030",
      "end": "00:16:09.040",
      "text": "uh"
    },
    {
      "start": "00:16:09.040",
      "end": "00:16:17.350",
      "text": "uh 3x3 uh"
    },
    {
      "start": "00:16:19.790",
      "end": "00:16:19.800",
      "text": "kernels and this will"
    },
    {
      "start": "00:16:19.800",
      "end": "00:16:22.230",
      "text": "kernels and this will be of"
    },
    {
      "start": "00:16:22.230",
      "end": "00:16:22.240",
      "text": "be of"
    },
    {
      "start": "00:16:22.240",
      "end": "00:16:27.629",
      "text": "be of Dimension uh ml"
    },
    {
      "start": "00:16:30.629",
      "end": "00:16:30.639",
      "text": "minus1 so just took the filter rotated"
    },
    {
      "start": "00:16:30.639",
      "end": "00:16:33.870",
      "text": "minus1 so just took the filter rotated 90\u00b0 and just decompos into its Kels this"
    },
    {
      "start": "00:16:33.870",
      "end": "00:16:33.880",
      "text": "90\u00b0 and just decompos into its Kels this"
    },
    {
      "start": "00:16:33.880",
      "end": "00:16:35.550",
      "text": "90\u00b0 and just decompos into its Kels this is the L minus one"
    },
    {
      "start": "00:16:35.550",
      "end": "00:16:35.560",
      "text": "is the L minus one"
    },
    {
      "start": "00:16:35.560",
      "end": "00:16:39.949",
      "text": "is the L minus one layer and so um since I'm going to be"
    },
    {
      "start": "00:16:39.949",
      "end": "00:16:39.959",
      "text": "layer and so um since I'm going to be"
    },
    {
      "start": "00:16:39.959",
      "end": "00:16:41.710",
      "text": "layer and so um since I'm going to be generating a scaler let's assume that"
    },
    {
      "start": "00:16:41.710",
      "end": "00:16:41.720",
      "text": "generating a scaler let's assume that"
    },
    {
      "start": "00:16:41.720",
      "end": "00:16:43.389",
      "text": "generating a scaler let's assume that I'm generating right now at that"
    },
    {
      "start": "00:16:43.389",
      "end": "00:16:43.399",
      "text": "I'm generating right now at that"
    },
    {
      "start": "00:16:43.399",
      "end": "00:16:47.790",
      "text": "I'm generating right now at that specific snap sort uh the this is the I"
    },
    {
      "start": "00:16:47.790",
      "end": "00:16:47.800",
      "text": "specific snap sort uh the this is the I"
    },
    {
      "start": "00:16:47.800",
      "end": "00:16:50.509",
      "text": "specific snap sort uh the this is the I comma J coordinate this is the column"
    },
    {
      "start": "00:16:50.509",
      "end": "00:16:50.519",
      "text": "comma J coordinate this is the column"
    },
    {
      "start": "00:16:50.519",
      "end": "00:16:53.269",
      "text": "comma J coordinate this is the column that corresponds to the E layer and the"
    },
    {
      "start": "00:16:53.269",
      "end": "00:16:53.279",
      "text": "that corresponds to the E layer and the"
    },
    {
      "start": "00:16:53.279",
      "end": "00:16:56.550",
      "text": "that corresponds to the E layer and the I comma J"
    },
    {
      "start": "00:16:56.550",
      "end": "00:16:56.560",
      "text": "I comma J"
    },
    {
      "start": "00:16:56.560",
      "end": "00:16:58.309",
      "text": "I comma J coordinate let's assume that I'm"
    },
    {
      "start": "00:16:58.309",
      "end": "00:16:58.319",
      "text": "coordinate let's assume that I'm"
    },
    {
      "start": "00:16:58.319",
      "end": "00:17:00.870",
      "text": "coordinate let's assume that I'm generating this scalar over here this"
    },
    {
      "start": "00:17:00.870",
      "end": "00:17:00.880",
      "text": "generating this scalar over here this"
    },
    {
      "start": "00:17:00.880",
      "end": "00:17:03.430",
      "text": "generating this scalar over here this scalar is going to be represented by the"
    },
    {
      "start": "00:17:03.430",
      "end": "00:17:03.440",
      "text": "scalar is going to be represented by the"
    },
    {
      "start": "00:17:03.440",
      "end": "00:17:06.829",
      "text": "scalar is going to be represented by the letter"
    },
    {
      "start": "00:17:10.189",
      "end": "00:17:10.199",
      "text": "Z and we'll have evidently I comma J as"
    },
    {
      "start": "00:17:10.199",
      "end": "00:17:11.309",
      "text": "Z and we'll have evidently I comma J as a special"
    },
    {
      "start": "00:17:11.309",
      "end": "00:17:11.319",
      "text": "a special"
    },
    {
      "start": "00:17:11.319",
      "end": "00:17:13.669",
      "text": "a special coordinates and we have a depth"
    },
    {
      "start": "00:17:13.669",
      "end": "00:17:13.679",
      "text": "coordinates and we have a depth"
    },
    {
      "start": "00:17:13.679",
      "end": "00:17:15.630",
      "text": "coordinates and we have a depth coordinate which I will designate with"
    },
    {
      "start": "00:17:15.630",
      "end": "00:17:15.640",
      "text": "coordinate which I will designate with"
    },
    {
      "start": "00:17:15.640",
      "end": "00:17:17.590",
      "text": "coordinate which I will designate with the letter"
    },
    {
      "start": "00:17:17.590",
      "end": "00:17:17.600",
      "text": "the letter"
    },
    {
      "start": "00:17:17.600",
      "end": "00:17:21.829",
      "text": "the letter KL and evidently 1 is less than or equal"
    },
    {
      "start": "00:17:21.829",
      "end": "00:17:21.839",
      "text": "KL and evidently 1 is less than or equal"
    },
    {
      "start": "00:17:21.839",
      "end": "00:17:24.990",
      "text": "KL and evidently 1 is less than or equal to KL is less than or equal to"
    },
    {
      "start": "00:17:24.990",
      "end": "00:17:25.000",
      "text": "to KL is less than or equal to"
    },
    {
      "start": "00:17:25.000",
      "end": "00:17:29.070",
      "text": "to KL is less than or equal to ml and this will actually be the uh uh"
    },
    {
      "start": "00:17:29.070",
      "end": "00:17:29.080",
      "text": "ml and this will actually be the uh uh"
    },
    {
      "start": "00:17:29.080",
      "end": "00:17:31.470",
      "text": "ml and this will actually be the uh uh values that the KL index which is the"
    },
    {
      "start": "00:17:31.470",
      "end": "00:17:31.480",
      "text": "values that the KL index which is the"
    },
    {
      "start": "00:17:31.480",
      "end": "00:17:35.549",
      "text": "values that the KL index which is the depth index um can"
    },
    {
      "start": "00:17:35.549",
      "end": "00:17:35.559",
      "text": "depth index um can"
    },
    {
      "start": "00:17:35.559",
      "end": "00:17:39.029",
      "text": "depth index um can take and I will actually be using also a"
    },
    {
      "start": "00:17:39.029",
      "end": "00:17:39.039",
      "text": "take and I will actually be using also a"
    },
    {
      "start": "00:17:39.039",
      "end": "00:17:42.310",
      "text": "take and I will actually be using also a corresponding index uh to address each"
    },
    {
      "start": "00:17:42.310",
      "end": "00:17:42.320",
      "text": "corresponding index uh to address each"
    },
    {
      "start": "00:17:42.320",
      "end": "00:17:44.909",
      "text": "corresponding index uh to address each one of those uh Kels which are going to"
    },
    {
      "start": "00:17:44.909",
      "end": "00:17:44.919",
      "text": "one of those uh Kels which are going to"
    },
    {
      "start": "00:17:44.919",
      "end": "00:17:48.549",
      "text": "one of those uh Kels which are going to be used um for the uh determining that"
    },
    {
      "start": "00:17:48.549",
      "end": "00:17:48.559",
      "text": "be used um for the uh determining that"
    },
    {
      "start": "00:17:48.559",
      "end": "00:17:52.350",
      "text": "be used um for the uh determining that kind of scalar Z so that scalar Z is"
    },
    {
      "start": "00:17:52.350",
      "end": "00:17:52.360",
      "text": "kind of scalar Z so that scalar Z is"
    },
    {
      "start": "00:17:52.360",
      "end": "00:17:53.590",
      "text": "kind of scalar Z so that scalar Z is going to"
    },
    {
      "start": "00:17:53.590",
      "end": "00:17:53.600",
      "text": "going to"
    },
    {
      "start": "00:17:53.600",
      "end": "00:17:58.630",
      "text": "going to be produced by using all of the Kels of"
    },
    {
      "start": "00:17:58.630",
      "end": "00:17:58.640",
      "text": "be produced by using all of the Kels of"
    },
    {
      "start": "00:17:58.640",
      "end": "00:18:00.710",
      "text": "be produced by using all of the Kels of the the"
    },
    {
      "start": "00:18:00.710",
      "end": "00:18:00.720",
      "text": "the the"
    },
    {
      "start": "00:18:00.720",
      "end": "00:18:05.789",
      "text": "the the filter and uh I am going to also need to"
    },
    {
      "start": "00:18:05.789",
      "end": "00:18:05.799",
      "text": "filter and uh I am going to also need to"
    },
    {
      "start": "00:18:05.799",
      "end": "00:18:09.789",
      "text": "filter and uh I am going to also need to Define to Define two other"
    },
    {
      "start": "00:18:09.789",
      "end": "00:18:09.799",
      "text": "Define to Define two other"
    },
    {
      "start": "00:18:09.799",
      "end": "00:18:13.590",
      "text": "Define to Define two other indexes the first index is going to be U"
    },
    {
      "start": "00:18:13.590",
      "end": "00:18:13.600",
      "text": "indexes the first index is going to be U"
    },
    {
      "start": "00:18:13.600",
      "end": "00:18:15.430",
      "text": "indexes the first index is going to be U and the other index going to be V and"
    },
    {
      "start": "00:18:15.430",
      "end": "00:18:15.440",
      "text": "and the other index going to be V and"
    },
    {
      "start": "00:18:15.440",
      "end": "00:18:18.029",
      "text": "and the other index going to be V and this indices will actually be used to as"
    },
    {
      "start": "00:18:18.029",
      "end": "00:18:18.039",
      "text": "this indices will actually be used to as"
    },
    {
      "start": "00:18:18.039",
      "end": "00:18:21.430",
      "text": "this indices will actually be used to as spatial coordinates of the kernel okay"
    },
    {
      "start": "00:18:21.430",
      "end": "00:18:21.440",
      "text": "spatial coordinates of the kernel okay"
    },
    {
      "start": "00:18:21.440",
      "end": "00:18:24.830",
      "text": "spatial coordinates of the kernel okay so my"
    },
    {
      "start": "00:18:28.830",
      "end": "00:18:28.840",
      "text": "equation so is the following so given I"
    },
    {
      "start": "00:18:28.840",
      "end": "00:18:29.830",
      "text": "equation so is the following so given I comma"
    },
    {
      "start": "00:18:29.830",
      "end": "00:18:29.840",
      "text": "comma"
    },
    {
      "start": "00:18:29.840",
      "end": "00:18:34.470",
      "text": "comma J comma KL given in other words the"
    },
    {
      "start": "00:18:34.470",
      "end": "00:18:34.480",
      "text": "J comma KL given in other words the"
    },
    {
      "start": "00:18:34.480",
      "end": "00:18:36.990",
      "text": "J comma KL given in other words the coordinates of"
    },
    {
      "start": "00:18:36.990",
      "end": "00:18:37.000",
      "text": "coordinates of"
    },
    {
      "start": "00:18:37.000",
      "end": "00:18:39.750",
      "text": "coordinates of the scalar which I want to"
    },
    {
      "start": "00:18:39.750",
      "end": "00:18:39.760",
      "text": "the scalar which I want to"
    },
    {
      "start": "00:18:39.760",
      "end": "00:18:44.950",
      "text": "the scalar which I want to generate my scalar z i comma J comma KL"
    },
    {
      "start": "00:18:44.950",
      "end": "00:18:44.960",
      "text": "generate my scalar z i comma J comma KL"
    },
    {
      "start": "00:18:44.960",
      "end": "00:18:47.470",
      "text": "generate my scalar z i comma J comma KL are going to be given by three"
    },
    {
      "start": "00:18:47.470",
      "end": "00:18:47.480",
      "text": "are going to be given by three"
    },
    {
      "start": "00:18:47.480",
      "end": "00:18:49.990",
      "text": "are going to be given by three summations the first two summations I"
    },
    {
      "start": "00:18:49.990",
      "end": "00:18:50.000",
      "text": "summations the first two summations I"
    },
    {
      "start": "00:18:50.000",
      "end": "00:18:53.270",
      "text": "summations the first two summations I have seen already in the plain two-"
    },
    {
      "start": "00:18:53.270",
      "end": "00:18:53.280",
      "text": "have seen already in the plain two-"
    },
    {
      "start": "00:18:53.280",
      "end": "00:18:55.510",
      "text": "have seen already in the plain two- dimensional correlation operation the"
    },
    {
      "start": "00:18:55.510",
      "end": "00:18:55.520",
      "text": "dimensional correlation operation the"
    },
    {
      "start": "00:18:55.520",
      "end": "00:18:58.350",
      "text": "dimensional correlation operation the one that we just did in an in a earlier"
    },
    {
      "start": "00:18:58.350",
      "end": "00:18:58.360",
      "text": "one that we just did in an in a earlier"
    },
    {
      "start": "00:18:58.360",
      "end": "00:19:00.270",
      "text": "one that we just did in an in a earlier so this is"
    },
    {
      "start": "00:19:00.270",
      "end": "00:19:00.280",
      "text": "so this is"
    },
    {
      "start": "00:19:00.280",
      "end": "00:19:04.270",
      "text": "so this is U summation over u and v uh definitely"
    },
    {
      "start": "00:19:04.270",
      "end": "00:19:04.280",
      "text": "U summation over u and v uh definitely"
    },
    {
      "start": "00:19:04.280",
      "end": "00:19:08.270",
      "text": "U summation over u and v uh definitely I'm expecting uh the uh special uh"
    },
    {
      "start": "00:19:08.270",
      "end": "00:19:08.280",
      "text": "I'm expecting uh the uh special uh"
    },
    {
      "start": "00:19:08.280",
      "end": "00:19:10.470",
      "text": "I'm expecting uh the uh special uh content of that kind of filter to be"
    },
    {
      "start": "00:19:10.470",
      "end": "00:19:10.480",
      "text": "content of that kind of filter to be"
    },
    {
      "start": "00:19:10.480",
      "end": "00:19:13.390",
      "text": "content of that kind of filter to be correlated uh and uh therefore dot"
    },
    {
      "start": "00:19:13.390",
      "end": "00:19:13.400",
      "text": "correlated uh and uh therefore dot"
    },
    {
      "start": "00:19:13.400",
      "end": "00:19:15.710",
      "text": "correlated uh and uh therefore dot product uh to take the dot product with"
    },
    {
      "start": "00:19:15.710",
      "end": "00:19:15.720",
      "text": "product uh to take the dot product with"
    },
    {
      "start": "00:19:15.720",
      "end": "00:19:18.830",
      "text": "product uh to take the dot product with the contents of the input image okay so"
    },
    {
      "start": "00:19:18.830",
      "end": "00:19:18.840",
      "text": "the contents of the input image okay so"
    },
    {
      "start": "00:19:18.840",
      "end": "00:19:21.630",
      "text": "the contents of the input image okay so this is the two summations over here uh"
    },
    {
      "start": "00:19:21.630",
      "end": "00:19:21.640",
      "text": "this is the two summations over here uh"
    },
    {
      "start": "00:19:21.640",
      "end": "00:19:23.990",
      "text": "this is the two summations over here uh but also I'm expecting to now do a"
    },
    {
      "start": "00:19:23.990",
      "end": "00:19:24.000",
      "text": "but also I'm expecting to now do a"
    },
    {
      "start": "00:19:24.000",
      "end": "00:19:25.710",
      "text": "but also I'm expecting to now do a three-dimensional correlation operation"
    },
    {
      "start": "00:19:25.710",
      "end": "00:19:25.720",
      "text": "three-dimensional correlation operation"
    },
    {
      "start": "00:19:25.720",
      "end": "00:19:29.029",
      "text": "three-dimensional correlation operation that's a third summation over an index"
    },
    {
      "start": "00:19:29.029",
      "end": "00:19:29.039",
      "text": "that's a third summation over an index"
    },
    {
      "start": "00:19:29.039",
      "end": "00:19:34.870",
      "text": "that's a third summation over an index I'll be calling k l minus1 and this"
    },
    {
      "start": "00:19:34.870",
      "end": "00:19:34.880",
      "text": "I'll be calling k l minus1 and this"
    },
    {
      "start": "00:19:34.880",
      "end": "00:19:36.470",
      "text": "I'll be calling k l minus1 and this index"
    },
    {
      "start": "00:19:36.470",
      "end": "00:19:36.480",
      "text": "index"
    },
    {
      "start": "00:19:36.480",
      "end": "00:19:39.149",
      "text": "index addresses uh the specific kernel which"
    },
    {
      "start": "00:19:39.149",
      "end": "00:19:39.159",
      "text": "addresses uh the specific kernel which"
    },
    {
      "start": "00:19:39.159",
      "end": "00:19:41.950",
      "text": "addresses uh the specific kernel which I'm going to be using so KL minus one is"
    },
    {
      "start": "00:19:41.950",
      "end": "00:19:41.960",
      "text": "I'm going to be using so KL minus one is"
    },
    {
      "start": "00:19:41.960",
      "end": "00:19:44.110",
      "text": "I'm going to be using so KL minus one is definitely the less than or equal to one"
    },
    {
      "start": "00:19:44.110",
      "end": "00:19:44.120",
      "text": "definitely the less than or equal to one"
    },
    {
      "start": "00:19:44.120",
      "end": "00:19:46.789",
      "text": "definitely the less than or equal to one and less than or equal to ml minus one"
    },
    {
      "start": "00:19:46.789",
      "end": "00:19:46.799",
      "text": "and less than or equal to ml minus one"
    },
    {
      "start": "00:19:46.799",
      "end": "00:19:48.950",
      "text": "and less than or equal to ml minus one in a similar in a similar way as we have"
    },
    {
      "start": "00:19:48.950",
      "end": "00:19:48.960",
      "text": "in a similar in a similar way as we have"
    },
    {
      "start": "00:19:48.960",
      "end": "00:19:51.430",
      "text": "in a similar in a similar way as we have seen earlier so what is this kind of a"
    },
    {
      "start": "00:19:51.430",
      "end": "00:19:51.440",
      "text": "seen earlier so what is this kind of a"
    },
    {
      "start": "00:19:51.440",
      "end": "00:19:53.070",
      "text": "seen earlier so what is this kind of a correlation it will be"
    },
    {
      "start": "00:19:53.070",
      "end": "00:19:53.080",
      "text": "correlation it will be"
    },
    {
      "start": "00:19:53.080",
      "end": "00:19:58.789",
      "text": "correlation it will be X of I + u j + V"
    },
    {
      "start": "00:19:58.789",
      "end": "00:19:58.799",
      "text": "X of I + u j + V"
    },
    {
      "start": "00:19:58.799",
      "end": "00:20:01.110",
      "text": "X of I + u j + V comma"
    },
    {
      "start": "00:20:01.110",
      "end": "00:20:01.120",
      "text": "comma"
    },
    {
      "start": "00:20:01.120",
      "end": "00:20:06.669",
      "text": "comma kl-1 time W where W now are the contents"
    },
    {
      "start": "00:20:06.669",
      "end": "00:20:06.679",
      "text": "kl-1 time W where W now are the contents"
    },
    {
      "start": "00:20:06.679",
      "end": "00:20:08.029",
      "text": "kl-1 time W where W now are the contents of"
    },
    {
      "start": "00:20:08.029",
      "end": "00:20:08.039",
      "text": "of"
    },
    {
      "start": "00:20:08.039",
      "end": "00:20:11.350",
      "text": "of the of the um of the"
    },
    {
      "start": "00:20:11.350",
      "end": "00:20:11.360",
      "text": "the of the um of the"
    },
    {
      "start": "00:20:11.360",
      "end": "00:20:15.070",
      "text": "the of the um of the kernel that now has U comma"
    },
    {
      "start": "00:20:15.070",
      "end": "00:20:15.080",
      "text": "kernel that now has U comma"
    },
    {
      "start": "00:20:15.080",
      "end": "00:20:17.870",
      "text": "kernel that now has U comma V comma"
    },
    {
      "start": "00:20:17.870",
      "end": "00:20:17.880",
      "text": "V comma"
    },
    {
      "start": "00:20:17.880",
      "end": "00:20:24.070",
      "text": "V comma KL comma KL"
    },
    {
      "start": "00:20:27.590",
      "end": "00:20:27.600",
      "text": "minus1 all right so we have uh in fact"
    },
    {
      "start": "00:20:27.600",
      "end": "00:20:29.669",
      "text": "minus1 all right so we have uh in fact the W is not the cond of the kernel the"
    },
    {
      "start": "00:20:29.669",
      "end": "00:20:29.679",
      "text": "the W is not the cond of the kernel the"
    },
    {
      "start": "00:20:29.679",
      "end": "00:20:31.990",
      "text": "the W is not the cond of the kernel the cond of the kernel yes we can call them"
    },
    {
      "start": "00:20:31.990",
      "end": "00:20:32.000",
      "text": "cond of the kernel yes we can call them"
    },
    {
      "start": "00:20:32.000",
      "end": "00:20:36.630",
      "text": "cond of the kernel yes we can call them W but W I would associate W with this"
    },
    {
      "start": "00:20:36.630",
      "end": "00:20:36.640",
      "text": "W but W I would associate W with this"
    },
    {
      "start": "00:20:36.640",
      "end": "00:20:39.789",
      "text": "W but W I would associate W with this line over here"
    },
    {
      "start": "00:20:39.789",
      "end": "00:20:39.799",
      "text": "line over here"
    },
    {
      "start": "00:20:39.799",
      "end": "00:20:44.630",
      "text": "line over here that for specifying this line I have the"
    },
    {
      "start": "00:20:44.630",
      "end": "00:20:44.640",
      "text": "that for specifying this line I have the"
    },
    {
      "start": "00:20:44.640",
      "end": "00:20:47.630",
      "text": "that for specifying this line I have the U comma V coordinates spal coordinates"
    },
    {
      "start": "00:20:47.630",
      "end": "00:20:47.640",
      "text": "U comma V coordinates spal coordinates"
    },
    {
      "start": "00:20:47.640",
      "end": "00:20:50.549",
      "text": "U comma V coordinates spal coordinates of the kernel uh that specific kernel"
    },
    {
      "start": "00:20:50.549",
      "end": "00:20:50.559",
      "text": "of the kernel uh that specific kernel"
    },
    {
      "start": "00:20:50.559",
      "end": "00:20:54.350",
      "text": "of the kernel uh that specific kernel however is uh uh provided by this index"
    },
    {
      "start": "00:20:54.350",
      "end": "00:20:54.360",
      "text": "however is uh uh provided by this index"
    },
    {
      "start": "00:20:54.360",
      "end": "00:20:56.310",
      "text": "however is uh uh provided by this index is identified by this index so this"
    },
    {
      "start": "00:20:56.310",
      "end": "00:20:56.320",
      "text": "is identified by this index so this"
    },
    {
      "start": "00:20:56.320",
      "end": "00:20:59.310",
      "text": "is identified by this index so this specific Kel is by this index and the"
    },
    {
      "start": "00:20:59.310",
      "end": "00:20:59.320",
      "text": "specific Kel is by this index and the"
    },
    {
      "start": "00:20:59.320",
      "end": "00:21:03.430",
      "text": "specific Kel is by this index and the scalar it is going to be generating is"
    },
    {
      "start": "00:21:03.430",
      "end": "00:21:03.440",
      "text": "scalar it is going to be generating is"
    },
    {
      "start": "00:21:03.440",
      "end": "00:21:06.029",
      "text": "scalar it is going to be generating is uh the located at the KL depth that's"
    },
    {
      "start": "00:21:06.029",
      "end": "00:21:06.039",
      "text": "uh the located at the KL depth that's"
    },
    {
      "start": "00:21:06.039",
      "end": "00:21:12.350",
      "text": "uh the located at the KL depth that's why I need this W of uh Q comma V comma"
    },
    {
      "start": "00:21:12.350",
      "end": "00:21:12.360",
      "text": "why I need this W of uh Q comma V comma"
    },
    {
      "start": "00:21:12.360",
      "end": "00:21:17.350",
      "text": "why I need this W of uh Q comma V comma KL comma KL minus one okay so this will"
    },
    {
      "start": "00:21:17.350",
      "end": "00:21:17.360",
      "text": "KL comma KL minus one okay so this will"
    },
    {
      "start": "00:21:17.360",
      "end": "00:21:18.990",
      "text": "KL comma KL minus one okay so this will actually be the"
    },
    {
      "start": "00:21:18.990",
      "end": "00:21:19.000",
      "text": "actually be the"
    },
    {
      "start": "00:21:19.000",
      "end": "00:21:23.029",
      "text": "actually be the um uh weights uh that are going be so a"
    },
    {
      "start": "00:21:23.029",
      "end": "00:21:23.039",
      "text": "um uh weights uh that are going be so a"
    },
    {
      "start": "00:21:23.039",
      "end": "00:21:26.230",
      "text": "um uh weights uh that are going be so a four dimensional tensor is being used"
    },
    {
      "start": "00:21:26.230",
      "end": "00:21:26.240",
      "text": "four dimensional tensor is being used"
    },
    {
      "start": "00:21:26.240",
      "end": "00:21:29.310",
      "text": "four dimensional tensor is being used here for specifying those uh"
    },
    {
      "start": "00:21:29.310",
      "end": "00:21:29.320",
      "text": "here for specifying those uh"
    },
    {
      "start": "00:21:29.320",
      "end": "00:21:31.669",
      "text": "here for specifying those uh parameters uh that that that we are"
    },
    {
      "start": "00:21:31.669",
      "end": "00:21:31.679",
      "text": "parameters uh that that that we are"
    },
    {
      "start": "00:21:31.679",
      "end": "00:21:35.149",
      "text": "parameters uh that that that we are store in those uh in in those filters"
    },
    {
      "start": "00:21:35.149",
      "end": "00:21:35.159",
      "text": "store in those uh in in those filters"
    },
    {
      "start": "00:21:35.159",
      "end": "00:21:36.950",
      "text": "store in those uh in in those filters and in fact we only have one filter"
    },
    {
      "start": "00:21:36.950",
      "end": "00:21:36.960",
      "text": "and in fact we only have one filter"
    },
    {
      "start": "00:21:36.960",
      "end": "00:21:39.390",
      "text": "and in fact we only have one filter right now so a four dimensional tensor"
    },
    {
      "start": "00:21:39.390",
      "end": "00:21:39.400",
      "text": "right now so a four dimensional tensor"
    },
    {
      "start": "00:21:39.400",
      "end": "00:21:41.750",
      "text": "right now so a four dimensional tensor to identify the parameters that we have"
    },
    {
      "start": "00:21:41.750",
      "end": "00:21:41.760",
      "text": "to identify the parameters that we have"
    },
    {
      "start": "00:21:41.760",
      "end": "00:21:44.390",
      "text": "to identify the parameters that we have used in this specific dot product over"
    },
    {
      "start": "00:21:44.390",
      "end": "00:21:44.400",
      "text": "used in this specific dot product over"
    },
    {
      "start": "00:21:44.400",
      "end": "00:21:45.990",
      "text": "used in this specific dot product over here this is a three-dimensional dot"
    },
    {
      "start": "00:21:45.990",
      "end": "00:21:46.000",
      "text": "here this is a three-dimensional dot"
    },
    {
      "start": "00:21:46.000",
      "end": "00:21:49.029",
      "text": "here this is a three-dimensional dot product and as you can imagine as I'm"
    },
    {
      "start": "00:21:49.029",
      "end": "00:21:49.039",
      "text": "product and as you can imagine as I'm"
    },
    {
      "start": "00:21:49.039",
      "end": "00:21:52.350",
      "text": "product and as you can imagine as I'm sliding the filter uh to another"
    },
    {
      "start": "00:21:52.350",
      "end": "00:21:52.360",
      "text": "sliding the filter uh to another"
    },
    {
      "start": "00:21:52.360",
      "end": "00:21:55.470",
      "text": "sliding the filter uh to another location um in the next snapshot the"
    },
    {
      "start": "00:21:55.470",
      "end": "00:21:55.480",
      "text": "location um in the next snapshot the"
    },
    {
      "start": "00:21:55.480",
      "end": "00:21:58.110",
      "text": "location um in the next snapshot the only thing actually is changing is the"
    },
    {
      "start": "00:21:58.110",
      "end": "00:21:58.120",
      "text": "only thing actually is changing is the"
    },
    {
      "start": "00:21:58.120",
      "end": "00:22:00.430",
      "text": "only thing actually is changing is the space"
    },
    {
      "start": "00:22:00.430",
      "end": "00:22:00.440",
      "text": "space"
    },
    {
      "start": "00:22:00.440",
      "end": "00:22:03.990",
      "text": "space coordinate that is being produced uh in"
    },
    {
      "start": "00:22:03.990",
      "end": "00:22:04.000",
      "text": "coordinate that is being produced uh in"
    },
    {
      "start": "00:22:04.000",
      "end": "00:22:06.549",
      "text": "coordinate that is being produced uh in this scaler so the only thing so by"
    },
    {
      "start": "00:22:06.549",
      "end": "00:22:06.559",
      "text": "this scaler so the only thing so by"
    },
    {
      "start": "00:22:06.559",
      "end": "00:22:08.470",
      "text": "this scaler so the only thing so by moving the filter around I'm changing"
    },
    {
      "start": "00:22:08.470",
      "end": "00:22:08.480",
      "text": "moving the filter around I'm changing"
    },
    {
      "start": "00:22:08.480",
      "end": "00:22:11.590",
      "text": "moving the filter around I'm changing the I comma J of what I'm producing"
    },
    {
      "start": "00:22:11.590",
      "end": "00:22:11.600",
      "text": "the I comma J of what I'm producing"
    },
    {
      "start": "00:22:11.600",
      "end": "00:22:13.430",
      "text": "the I comma J of what I'm producing therefore what I'm actually going to be"
    },
    {
      "start": "00:22:13.430",
      "end": "00:22:13.440",
      "text": "therefore what I'm actually going to be"
    },
    {
      "start": "00:22:13.440",
      "end": "00:22:14.870",
      "text": "therefore what I'm actually going to be producing"
    },
    {
      "start": "00:22:14.870",
      "end": "00:22:14.880",
      "text": "producing"
    },
    {
      "start": "00:22:14.880",
      "end": "00:22:16.789",
      "text": "producing is a"
    },
    {
      "start": "00:22:16.789",
      "end": "00:22:16.799",
      "text": "is a"
    },
    {
      "start": "00:22:16.799",
      "end": "00:22:20.630",
      "text": "is a slice a specific slice out of this uh uh"
    },
    {
      "start": "00:22:20.630",
      "end": "00:22:20.640",
      "text": "slice a specific slice out of this uh uh"
    },
    {
      "start": "00:22:20.640",
      "end": "00:22:23.390",
      "text": "slice a specific slice out of this uh uh sort of uh output feature map so the"
    },
    {
      "start": "00:22:23.390",
      "end": "00:22:23.400",
      "text": "sort of uh output feature map so the"
    },
    {
      "start": "00:22:23.400",
      "end": "00:22:25.230",
      "text": "sort of uh output feature map so the specific slice I'm just drawing over"
    },
    {
      "start": "00:22:25.230",
      "end": "00:22:25.240",
      "text": "specific slice I'm just drawing over"
    },
    {
      "start": "00:22:25.240",
      "end": "00:22:29.230",
      "text": "specific slice I'm just drawing over here just one of the ml slices"
    },
    {
      "start": "00:22:29.230",
      "end": "00:22:29.240",
      "text": "here just one of the ml slices"
    },
    {
      "start": "00:22:29.240",
      "end": "00:22:31.710",
      "text": "here just one of the ml slices so ml slices generates the complete"
    },
    {
      "start": "00:22:31.710",
      "end": "00:22:31.720",
      "text": "so ml slices generates the complete"
    },
    {
      "start": "00:22:31.720",
      "end": "00:22:34.390",
      "text": "so ml slices generates the complete volume so this slice is the one that I"
    },
    {
      "start": "00:22:34.390",
      "end": "00:22:34.400",
      "text": "volume so this slice is the one that I"
    },
    {
      "start": "00:22:34.400",
      "end": "00:22:37.510",
      "text": "volume so this slice is the one that I am going to be uh generating this"
    },
    {
      "start": "00:22:37.510",
      "end": "00:22:37.520",
      "text": "am going to be uh generating this"
    },
    {
      "start": "00:22:37.520",
      "end": "00:22:40.230",
      "text": "am going to be uh generating this complete slice so effectively a"
    },
    {
      "start": "00:22:40.230",
      "end": "00:22:40.240",
      "text": "complete slice so effectively a"
    },
    {
      "start": "00:22:40.240",
      "end": "00:22:44.070",
      "text": "complete slice so effectively a matrix and uh uh so from one filter I'll"
    },
    {
      "start": "00:22:44.070",
      "end": "00:22:44.080",
      "text": "matrix and uh uh so from one filter I'll"
    },
    {
      "start": "00:22:44.080",
      "end": "00:22:46.990",
      "text": "matrix and uh uh so from one filter I'll be generating a single Matrix and"
    },
    {
      "start": "00:22:46.990",
      "end": "00:22:47.000",
      "text": "be generating a single Matrix and"
    },
    {
      "start": "00:22:47.000",
      "end": "00:22:49.510",
      "text": "be generating a single Matrix and therefore and this is the important"
    },
    {
      "start": "00:22:49.510",
      "end": "00:22:49.520",
      "text": "therefore and this is the important"
    },
    {
      "start": "00:22:49.520",
      "end": "00:22:53.909",
      "text": "therefore and this is the important conclusion from uh we"
    },
    {
      "start": "00:22:53.909",
      "end": "00:22:53.919",
      "text": "conclusion from uh we"
    },
    {
      "start": "00:22:53.919",
      "end": "00:22:56.789",
      "text": "conclusion from uh we need"
    },
    {
      "start": "00:22:56.789",
      "end": "00:22:56.799",
      "text": "need"
    },
    {
      "start": "00:22:56.799",
      "end": "00:23:02.990",
      "text": "need multiple we need multiple"
    },
    {
      "start": "00:23:14.149",
      "end": "00:23:14.159",
      "text": "output"
    },
    {
      "start": "00:23:14.159",
      "end": "00:23:18.710",
      "text": "output feature map"
    },
    {
      "start": "00:23:21.630",
      "end": "00:23:21.640",
      "text": "volume so for a volume for the whole"
    },
    {
      "start": "00:23:21.640",
      "end": "00:23:23.950",
      "text": "volume so for a volume for the whole thing for the output feature map we need"
    },
    {
      "start": "00:23:23.950",
      "end": "00:23:23.960",
      "text": "thing for the output feature map we need"
    },
    {
      "start": "00:23:23.960",
      "end": "00:23:27.390",
      "text": "thing for the output feature map we need to be creating multiple fatures in fact"
    },
    {
      "start": "00:23:27.390",
      "end": "00:23:27.400",
      "text": "to be creating multiple fatures in fact"
    },
    {
      "start": "00:23:27.400",
      "end": "00:23:29.310",
      "text": "to be creating multiple fatures in fact this thing over here"
    },
    {
      "start": "00:23:29.310",
      "end": "00:23:29.320",
      "text": "this thing over here"
    },
    {
      "start": "00:23:29.320",
      "end": "00:23:33.029",
      "text": "this thing over here is really the connectivity diagram of uh"
    },
    {
      "start": "00:23:33.029",
      "end": "00:23:33.039",
      "text": "is really the connectivity diagram of uh"
    },
    {
      "start": "00:23:33.039",
      "end": "00:23:34.990",
      "text": "is really the connectivity diagram of uh the convolutional neuron what we call a"
    },
    {
      "start": "00:23:34.990",
      "end": "00:23:35.000",
      "text": "the convolutional neuron what we call a"
    },
    {
      "start": "00:23:35.000",
      "end": "00:23:38.230",
      "text": "the convolutional neuron what we call a convolutional a single filter is and the"
    },
    {
      "start": "00:23:38.230",
      "end": "00:23:38.240",
      "text": "convolutional a single filter is and the"
    },
    {
      "start": "00:23:38.240",
      "end": "00:23:40.230",
      "text": "convolutional a single filter is and the operation actually we see over here is"
    },
    {
      "start": "00:23:40.230",
      "end": "00:23:40.240",
      "text": "operation actually we see over here is"
    },
    {
      "start": "00:23:40.240",
      "end": "00:23:42.549",
      "text": "operation actually we see over here is the operation of the convolutional"
    },
    {
      "start": "00:23:42.549",
      "end": "00:23:42.559",
      "text": "the operation of the convolutional"
    },
    {
      "start": "00:23:42.559",
      "end": "00:23:46.870",
      "text": "the operation of the convolutional neuron um and this is um all of these"
    },
    {
      "start": "00:23:46.870",
      "end": "00:23:46.880",
      "text": "neuron um and this is um all of these"
    },
    {
      "start": "00:23:46.880",
      "end": "00:23:49.230",
      "text": "neuron um and this is um all of these parameters that we have used over here"
    },
    {
      "start": "00:23:49.230",
      "end": "00:23:49.240",
      "text": "parameters that we have used over here"
    },
    {
      "start": "00:23:49.240",
      "end": "00:23:51.870",
      "text": "parameters that we have used over here the contents if you like the filter are"
    },
    {
      "start": "00:23:51.870",
      "end": "00:23:51.880",
      "text": "the contents if you like the filter are"
    },
    {
      "start": "00:23:51.880",
      "end": "00:24:01.510",
      "text": "the contents if you like the filter are the so-called trainable parameters"
    },
    {
      "start": "00:24:04.149",
      "end": "00:24:04.159",
      "text": "and uh we will now uh see an animation"
    },
    {
      "start": "00:24:04.159",
      "end": "00:24:07.669",
      "text": "and uh we will now uh see an animation of of this thing uh in uh in our core"
    },
    {
      "start": "00:24:07.669",
      "end": "00:24:07.679",
      "text": "of of this thing uh in uh in our core"
    },
    {
      "start": "00:24:07.679",
      "end": "00:24:10.630",
      "text": "of of this thing uh in uh in our core site so if I go to my core site and"
    },
    {
      "start": "00:24:10.630",
      "end": "00:24:10.640",
      "text": "site so if I go to my core site and"
    },
    {
      "start": "00:24:10.640",
      "end": "00:24:13.190",
      "text": "site so if I go to my core site and actually scroll down a little bit then"
    },
    {
      "start": "00:24:13.190",
      "end": "00:24:13.200",
      "text": "actually scroll down a little bit then"
    },
    {
      "start": "00:24:13.200",
      "end": "00:24:15.510",
      "text": "actually scroll down a little bit then you can see now the"
    },
    {
      "start": "00:24:15.510",
      "end": "00:24:15.520",
      "text": "you can see now the"
    },
    {
      "start": "00:24:15.520",
      "end": "00:24:17.430",
      "text": "you can see now the three-dimensional um so first of all"
    },
    {
      "start": "00:24:17.430",
      "end": "00:24:17.440",
      "text": "three-dimensional um so first of all"
    },
    {
      "start": "00:24:17.440",
      "end": "00:24:19.510",
      "text": "three-dimensional um so first of all before we see the animation we can"
    },
    {
      "start": "00:24:19.510",
      "end": "00:24:19.520",
      "text": "before we see the animation we can"
    },
    {
      "start": "00:24:19.520",
      "end": "00:24:21.549",
      "text": "before we see the animation we can actually see it's exactly the diagram I"
    },
    {
      "start": "00:24:21.549",
      "end": "00:24:21.559",
      "text": "actually see it's exactly the diagram I"
    },
    {
      "start": "00:24:21.559",
      "end": "00:24:24.070",
      "text": "actually see it's exactly the diagram I just drew a bit a different I have an"
    },
    {
      "start": "00:24:24.070",
      "end": "00:24:24.080",
      "text": "just drew a bit a different I have an"
    },
    {
      "start": "00:24:24.080",
      "end": "00:24:26.510",
      "text": "just drew a bit a different I have an input volume uh which is the blue over"
    },
    {
      "start": "00:24:26.510",
      "end": "00:24:26.520",
      "text": "input volume uh which is the blue over"
    },
    {
      "start": "00:24:26.520",
      "end": "00:24:29.830",
      "text": "input volume uh which is the blue over here with has a depth D"
    },
    {
      "start": "00:24:29.830",
      "end": "00:24:29.840",
      "text": "here with has a depth D"
    },
    {
      "start": "00:24:29.840",
      "end": "00:24:32.789",
      "text": "here with has a depth D in uh definitely as we mentioned the"
    },
    {
      "start": "00:24:32.789",
      "end": "00:24:32.799",
      "text": "in uh definitely as we mentioned the"
    },
    {
      "start": "00:24:32.799",
      "end": "00:24:35.110",
      "text": "in uh definitely as we mentioned the input uh sorry the filter that we're"
    },
    {
      "start": "00:24:35.110",
      "end": "00:24:35.120",
      "text": "input uh sorry the filter that we're"
    },
    {
      "start": "00:24:35.120",
      "end": "00:24:37.950",
      "text": "input uh sorry the filter that we're going to be using has the same depth D"
    },
    {
      "start": "00:24:37.950",
      "end": "00:24:37.960",
      "text": "going to be using has the same depth D"
    },
    {
      "start": "00:24:37.960",
      "end": "00:24:39.909",
      "text": "going to be using has the same depth D in as the input volume doesn't make"
    },
    {
      "start": "00:24:39.909",
      "end": "00:24:39.919",
      "text": "in as the input volume doesn't make"
    },
    {
      "start": "00:24:39.919",
      "end": "00:24:40.870",
      "text": "in as the input volume doesn't make sense"
    },
    {
      "start": "00:24:40.870",
      "end": "00:24:40.880",
      "text": "sense"
    },
    {
      "start": "00:24:40.880",
      "end": "00:24:43.310",
      "text": "sense otherwise and then in terms of the"
    },
    {
      "start": "00:24:43.310",
      "end": "00:24:43.320",
      "text": "otherwise and then in terms of the"
    },
    {
      "start": "00:24:43.320",
      "end": "00:24:46.669",
      "text": "otherwise and then in terms of the output volume a single filter is going"
    },
    {
      "start": "00:24:46.669",
      "end": "00:24:46.679",
      "text": "output volume a single filter is going"
    },
    {
      "start": "00:24:46.679",
      "end": "00:24:49.950",
      "text": "output volume a single filter is going to be generating one slice out of the D"
    },
    {
      "start": "00:24:49.950",
      "end": "00:24:49.960",
      "text": "to be generating one slice out of the D"
    },
    {
      "start": "00:24:49.960",
      "end": "00:24:52.990",
      "text": "to be generating one slice out of the D out slices so on one slices let's say"
    },
    {
      "start": "00:24:52.990",
      "end": "00:24:53.000",
      "text": "out slices so on one slices let's say"
    },
    {
      "start": "00:24:53.000",
      "end": "00:24:55.070",
      "text": "out slices so on one slices let's say this specific Matrix over here where my"
    },
    {
      "start": "00:24:55.070",
      "end": "00:24:55.080",
      "text": "this specific Matrix over here where my"
    },
    {
      "start": "00:24:55.080",
      "end": "00:24:57.870",
      "text": "this specific Matrix over here where my mouse pointer is that is going to be"
    },
    {
      "start": "00:24:57.870",
      "end": "00:24:57.880",
      "text": "mouse pointer is that is going to be"
    },
    {
      "start": "00:24:57.880",
      "end": "00:24:59.549",
      "text": "mouse pointer is that is going to be what is going to be produced by a single"
    },
    {
      "start": "00:24:59.549",
      "end": "00:24:59.559",
      "text": "what is going to be produced by a single"
    },
    {
      "start": "00:24:59.559",
      "end": "00:25:01.950",
      "text": "what is going to be produced by a single filter and this dotted line here"
    },
    {
      "start": "00:25:01.950",
      "end": "00:25:01.960",
      "text": "filter and this dotted line here"
    },
    {
      "start": "00:25:01.960",
      "end": "00:25:04.230",
      "text": "filter and this dotted line here indicates that if you want to generate"
    },
    {
      "start": "00:25:04.230",
      "end": "00:25:04.240",
      "text": "indicates that if you want to generate"
    },
    {
      "start": "00:25:04.240",
      "end": "00:25:07.549",
      "text": "indicates that if you want to generate the complete output uh volume with a"
    },
    {
      "start": "00:25:07.549",
      "end": "00:25:07.559",
      "text": "the complete output uh volume with a"
    },
    {
      "start": "00:25:07.559",
      "end": "00:25:10.389",
      "text": "the complete output uh volume with a depth D out you need D out of these"
    },
    {
      "start": "00:25:10.389",
      "end": "00:25:10.399",
      "text": "depth D out you need D out of these"
    },
    {
      "start": "00:25:10.399",
      "end": "00:25:14.350",
      "text": "depth D out you need D out of these filters you need D out of these orange"
    },
    {
      "start": "00:25:14.350",
      "end": "00:25:14.360",
      "text": "filters you need D out of these orange"
    },
    {
      "start": "00:25:14.360",
      "end": "00:25:16.230",
      "text": "filters you need D out of these orange cubes in order for you to be able to"
    },
    {
      "start": "00:25:16.230",
      "end": "00:25:16.240",
      "text": "cubes in order for you to be able to"
    },
    {
      "start": "00:25:16.240",
      "end": "00:25:19.669",
      "text": "cubes in order for you to be able to generate a complete green uh output uh"
    },
    {
      "start": "00:25:19.669",
      "end": "00:25:19.679",
      "text": "generate a complete green uh output uh"
    },
    {
      "start": "00:25:19.679",
      "end": "00:25:22.510",
      "text": "generate a complete green uh output uh feature map so I think it's worth"
    },
    {
      "start": "00:25:22.510",
      "end": "00:25:22.520",
      "text": "feature map so I think it's worth"
    },
    {
      "start": "00:25:22.520",
      "end": "00:25:25.909",
      "text": "feature map so I think it's worth spending some time in this animation in"
    },
    {
      "start": "00:25:25.909",
      "end": "00:25:25.919",
      "text": "spending some time in this animation in"
    },
    {
      "start": "00:25:25.919",
      "end": "00:25:27.590",
      "text": "spending some time in this animation in this animation you can actually see"
    },
    {
      "start": "00:25:27.590",
      "end": "00:25:27.600",
      "text": "this animation you can actually see"
    },
    {
      "start": "00:25:27.600",
      "end": "00:25:30.070",
      "text": "this animation you can actually see exactly what what I just discussed here"
    },
    {
      "start": "00:25:30.070",
      "end": "00:25:30.080",
      "text": "exactly what what I just discussed here"
    },
    {
      "start": "00:25:30.080",
      "end": "00:25:32.950",
      "text": "exactly what what I just discussed here in this example I have an input feature"
    },
    {
      "start": "00:25:32.950",
      "end": "00:25:32.960",
      "text": "in this example I have an input feature"
    },
    {
      "start": "00:25:32.960",
      "end": "00:25:34.510",
      "text": "in this example I have an input feature map of depth"
    },
    {
      "start": "00:25:34.510",
      "end": "00:25:34.520",
      "text": "map of depth"
    },
    {
      "start": "00:25:34.520",
      "end": "00:25:38.230",
      "text": "map of depth three uh and I have a output feature map"
    },
    {
      "start": "00:25:38.230",
      "end": "00:25:38.240",
      "text": "three uh and I have a output feature map"
    },
    {
      "start": "00:25:38.240",
      "end": "00:25:40.549",
      "text": "three uh and I have a output feature map of depth two let's assume that that is"
    },
    {
      "start": "00:25:40.549",
      "end": "00:25:40.559",
      "text": "of depth two let's assume that that is"
    },
    {
      "start": "00:25:40.559",
      "end": "00:25:43.389",
      "text": "of depth two let's assume that that is the uh sort of a design parameter which"
    },
    {
      "start": "00:25:43.389",
      "end": "00:25:43.399",
      "text": "the uh sort of a design parameter which"
    },
    {
      "start": "00:25:43.399",
      "end": "00:25:46.070",
      "text": "the uh sort of a design parameter which I want to implement uh therefore if I"
    },
    {
      "start": "00:25:46.070",
      "end": "00:25:46.080",
      "text": "I want to implement uh therefore if I"
    },
    {
      "start": "00:25:46.080",
      "end": "00:25:48.350",
      "text": "I want to implement uh therefore if I have an output feat map of two I need"
    },
    {
      "start": "00:25:48.350",
      "end": "00:25:48.360",
      "text": "have an output feat map of two I need"
    },
    {
      "start": "00:25:48.360",
      "end": "00:25:50.590",
      "text": "have an output feat map of two I need two filters and these are the two"
    },
    {
      "start": "00:25:50.590",
      "end": "00:25:50.600",
      "text": "two filters and these are the two"
    },
    {
      "start": "00:25:50.600",
      "end": "00:25:53.470",
      "text": "two filters and these are the two filters this is the filter w0 and this"
    },
    {
      "start": "00:25:53.470",
      "end": "00:25:53.480",
      "text": "filters this is the filter w0 and this"
    },
    {
      "start": "00:25:53.480",
      "end": "00:25:55.190",
      "text": "filters this is the filter w0 and this is the filter"
    },
    {
      "start": "00:25:55.190",
      "end": "00:25:55.200",
      "text": "is the filter"
    },
    {
      "start": "00:25:55.200",
      "end": "00:25:58.549",
      "text": "is the filter W1 and uh evidently the each each of"
    },
    {
      "start": "00:25:58.549",
      "end": "00:25:58.559",
      "text": "W1 and uh evidently the each each of"
    },
    {
      "start": "00:25:58.559",
      "end": "00:26:01.510",
      "text": "W1 and uh evidently the each each of these filters has of dep depth three"
    },
    {
      "start": "00:26:01.510",
      "end": "00:26:01.520",
      "text": "these filters has of dep depth three"
    },
    {
      "start": "00:26:01.520",
      "end": "00:26:04.269",
      "text": "these filters has of dep depth three because three is also the depth of the"
    },
    {
      "start": "00:26:04.269",
      "end": "00:26:04.279",
      "text": "because three is also the depth of the"
    },
    {
      "start": "00:26:04.279",
      "end": "00:26:08.110",
      "text": "because three is also the depth of the input feature map and at every specific"
    },
    {
      "start": "00:26:08.110",
      "end": "00:26:08.120",
      "text": "input feature map and at every specific"
    },
    {
      "start": "00:26:08.120",
      "end": "00:26:10.070",
      "text": "input feature map and at every specific snapshot let's assume this is the"
    },
    {
      "start": "00:26:10.070",
      "end": "00:26:10.080",
      "text": "snapshot let's assume this is the"
    },
    {
      "start": "00:26:10.080",
      "end": "00:26:12.830",
      "text": "snapshot let's assume this is the snapshot that I just drew on piece of"
    },
    {
      "start": "00:26:12.830",
      "end": "00:26:12.840",
      "text": "snapshot that I just drew on piece of"
    },
    {
      "start": "00:26:12.840",
      "end": "00:26:17.909",
      "text": "snapshot that I just drew on piece of paper this uh filter is located at this"
    },
    {
      "start": "00:26:17.909",
      "end": "00:26:17.919",
      "text": "paper this uh filter is located at this"
    },
    {
      "start": "00:26:17.919",
      "end": "00:26:21.110",
      "text": "paper this uh filter is located at this specific uh location in my input feature"
    },
    {
      "start": "00:26:21.110",
      "end": "00:26:21.120",
      "text": "specific uh location in my input feature"
    },
    {
      "start": "00:26:21.120",
      "end": "00:26:24.909",
      "text": "specific uh location in my input feature map and it is responsible for creating"
    },
    {
      "start": "00:26:24.909",
      "end": "00:26:24.919",
      "text": "map and it is responsible for creating"
    },
    {
      "start": "00:26:24.919",
      "end": "00:26:29.789",
      "text": "map and it is responsible for creating this scalar Z which is nine in this case"
    },
    {
      "start": "00:26:29.789",
      "end": "00:26:29.799",
      "text": "this scalar Z which is nine in this case"
    },
    {
      "start": "00:26:29.799",
      "end": "00:26:33.630",
      "text": "this scalar Z which is nine in this case okay so if I may uh and and and as far"
    },
    {
      "start": "00:26:33.630",
      "end": "00:26:33.640",
      "text": "okay so if I may uh and and and as far"
    },
    {
      "start": "00:26:33.640",
      "end": "00:26:36.750",
      "text": "okay so if I may uh and and and as far as the output feature map is concerned"
    },
    {
      "start": "00:26:36.750",
      "end": "00:26:36.760",
      "text": "as the output feature map is concerned"
    },
    {
      "start": "00:26:36.760",
      "end": "00:26:38.630",
      "text": "as the output feature map is concerned this filter is"
    },
    {
      "start": "00:26:38.630",
      "end": "00:26:38.640",
      "text": "this filter is"
    },
    {
      "start": "00:26:38.640",
      "end": "00:26:42.549",
      "text": "this filter is only uh able to plot if you like to"
    },
    {
      "start": "00:26:42.549",
      "end": "00:26:42.559",
      "text": "only uh able to plot if you like to"
    },
    {
      "start": "00:26:42.559",
      "end": "00:26:46.389",
      "text": "only uh able to plot if you like to determine the this specific slice of the"
    },
    {
      "start": "00:26:46.389",
      "end": "00:26:46.399",
      "text": "determine the this specific slice of the"
    },
    {
      "start": "00:26:46.399",
      "end": "00:26:47.950",
      "text": "determine the this specific slice of the output feature"
    },
    {
      "start": "00:26:47.950",
      "end": "00:26:47.960",
      "text": "output feature"
    },
    {
      "start": "00:26:47.960",
      "end": "00:26:52.110",
      "text": "output feature map uh if I want to continue then we"
    },
    {
      "start": "00:26:52.110",
      "end": "00:26:52.120",
      "text": "map uh if I want to continue then we"
    },
    {
      "start": "00:26:52.120",
      "end": "00:26:54.950",
      "text": "map uh if I want to continue then we will see that the second filter is the"
    },
    {
      "start": "00:26:54.950",
      "end": "00:26:54.960",
      "text": "will see that the second filter is the"
    },
    {
      "start": "00:26:54.960",
      "end": "00:26:58.230",
      "text": "will see that the second filter is the one which is involved in the creation of"
    },
    {
      "start": "00:26:58.230",
      "end": "00:26:58.240",
      "text": "one which is involved in the creation of"
    },
    {
      "start": "00:26:58.240",
      "end": "00:27:00.470",
      "text": "one which is involved in the creation of of the second slice of the output"
    },
    {
      "start": "00:27:00.470",
      "end": "00:27:00.480",
      "text": "of the second slice of the output"
    },
    {
      "start": "00:27:00.480",
      "end": "00:27:04.070",
      "text": "of the second slice of the output feature this is really the essence of a"
    },
    {
      "start": "00:27:04.070",
      "end": "00:27:04.080",
      "text": "feature this is really the essence of a"
    },
    {
      "start": "00:27:04.080",
      "end": "00:27:06.430",
      "text": "feature this is really the essence of a three-dimensional convolution I suggest"
    },
    {
      "start": "00:27:06.430",
      "end": "00:27:06.440",
      "text": "three-dimensional convolution I suggest"
    },
    {
      "start": "00:27:06.440",
      "end": "00:27:07.830",
      "text": "three-dimensional convolution I suggest that you spend some time on this"
    },
    {
      "start": "00:27:07.830",
      "end": "00:27:07.840",
      "text": "that you spend some time on this"
    },
    {
      "start": "00:27:07.840",
      "end": "00:27:10.190",
      "text": "that you spend some time on this animation trying to understand what is"
    },
    {
      "start": "00:27:10.190",
      "end": "00:27:10.200",
      "text": "animation trying to understand what is"
    },
    {
      "start": "00:27:10.200",
      "end": "00:27:13.110",
      "text": "animation trying to understand what is what is going on and you can toggle the"
    },
    {
      "start": "00:27:13.110",
      "end": "00:27:13.120",
      "text": "what is going on and you can toggle the"
    },
    {
      "start": "00:27:13.120",
      "end": "00:27:15.630",
      "text": "what is going on and you can toggle the movement just to be able to replicate"
    },
    {
      "start": "00:27:15.630",
      "end": "00:27:15.640",
      "text": "movement just to be able to replicate"
    },
    {
      "start": "00:27:15.640",
      "end": "00:27:18.750",
      "text": "movement just to be able to replicate the output scaler uh from the input"
    },
    {
      "start": "00:27:18.750",
      "end": "00:27:18.760",
      "text": "the output scaler uh from the input"
    },
    {
      "start": "00:27:18.760",
      "end": "00:27:23.070",
      "text": "the output scaler uh from the input values which have been provided over"
    },
    {
      "start": "00:27:26.630",
      "end": "00:27:26.640",
      "text": "here a bit on this presentation of the"
    },
    {
      "start": "00:27:26.640",
      "end": "00:27:29.990",
      "text": "here a bit on this presentation of the snapshot operation of a layer uh the"
    },
    {
      "start": "00:27:29.990",
      "end": "00:27:30.000",
      "text": "snapshot operation of a layer uh the"
    },
    {
      "start": "00:27:30.000",
      "end": "00:27:34.549",
      "text": "snapshot operation of a layer uh the site over here has uh is squatting some"
    },
    {
      "start": "00:27:34.549",
      "end": "00:27:34.559",
      "text": "site over here has uh is squatting some"
    },
    {
      "start": "00:27:34.559",
      "end": "00:27:37.350",
      "text": "site over here has uh is squatting some kind of important formulas regarding the"
    },
    {
      "start": "00:27:37.350",
      "end": "00:27:37.360",
      "text": "kind of important formulas regarding the"
    },
    {
      "start": "00:27:37.360",
      "end": "00:27:38.990",
      "text": "kind of important formulas regarding the size the special dimensions of the"
    },
    {
      "start": "00:27:38.990",
      "end": "00:27:39.000",
      "text": "size the special dimensions of the"
    },
    {
      "start": "00:27:39.000",
      "end": "00:27:40.789",
      "text": "size the special dimensions of the output feature map I think it's"
    },
    {
      "start": "00:27:40.789",
      "end": "00:27:40.799",
      "text": "output feature map I think it's"
    },
    {
      "start": "00:27:40.799",
      "end": "00:27:45.310",
      "text": "output feature map I think it's important to uh note them down um and so"
    },
    {
      "start": "00:27:45.310",
      "end": "00:27:45.320",
      "text": "important to uh note them down um and so"
    },
    {
      "start": "00:27:45.320",
      "end": "00:27:50.990",
      "text": "important to uh note them down um and so uh it is uh the floor of the height of"
    },
    {
      "start": "00:27:50.990",
      "end": "00:27:51.000",
      "text": "uh it is uh the floor of the height of"
    },
    {
      "start": "00:27:51.000",
      "end": "00:27:53.950",
      "text": "uh it is uh the floor of the height of the input feure map plus two * the"
    },
    {
      "start": "00:27:53.950",
      "end": "00:27:53.960",
      "text": "the input feure map plus two * the"
    },
    {
      "start": "00:27:53.960",
      "end": "00:27:56.830",
      "text": "the input feure map plus two * the padding size minus the kernel size"
    },
    {
      "start": "00:27:56.830",
      "end": "00:27:56.840",
      "text": "padding size minus the kernel size"
    },
    {
      "start": "00:27:56.840",
      "end": "00:27:59.389",
      "text": "padding size minus the kernel size divided by the strides"
    },
    {
      "start": "00:27:59.389",
      "end": "00:27:59.399",
      "text": "divided by the strides"
    },
    {
      "start": "00:27:59.399",
      "end": "00:28:01.950",
      "text": "divided by the strides uh and plus one okay so this is the"
    },
    {
      "start": "00:28:01.950",
      "end": "00:28:01.960",
      "text": "uh and plus one okay so this is the"
    },
    {
      "start": "00:28:01.960",
      "end": "00:28:04.509",
      "text": "uh and plus one okay so this is the formula that will uh that you can"
    },
    {
      "start": "00:28:04.509",
      "end": "00:28:04.519",
      "text": "formula that will uh that you can"
    },
    {
      "start": "00:28:04.519",
      "end": "00:28:06.830",
      "text": "formula that will uh that you can actually use to understand exactly what"
    },
    {
      "start": "00:28:06.830",
      "end": "00:28:06.840",
      "text": "actually use to understand exactly what"
    },
    {
      "start": "00:28:06.840",
      "end": "00:28:09.149",
      "text": "actually use to understand exactly what will be your output feature maps are in"
    },
    {
      "start": "00:28:09.149",
      "end": "00:28:09.159",
      "text": "will be your output feature maps are in"
    },
    {
      "start": "00:28:09.159",
      "end": "00:28:11.029",
      "text": "will be your output feature maps are in terms of spatial dimensions and of"
    },
    {
      "start": "00:28:11.029",
      "end": "00:28:11.039",
      "text": "terms of spatial dimensions and of"
    },
    {
      "start": "00:28:11.039",
      "end": "00:28:13.029",
      "text": "terms of spatial dimensions and of course this will be the input feature"
    },
    {
      "start": "00:28:13.029",
      "end": "00:28:13.039",
      "text": "course this will be the input feature"
    },
    {
      "start": "00:28:13.039",
      "end": "00:28:16.549",
      "text": "course this will be the input feature map sizes uh for the for the layer that"
    },
    {
      "start": "00:28:16.549",
      "end": "00:28:16.559",
      "text": "map sizes uh for the for the layer that"
    },
    {
      "start": "00:28:16.559",
      "end": "00:28:19.669",
      "text": "map sizes uh for the for the layer that follows um okay so what will actually be"
    },
    {
      "start": "00:28:19.669",
      "end": "00:28:19.679",
      "text": "follows um okay so what will actually be"
    },
    {
      "start": "00:28:19.679",
      "end": "00:28:23.909",
      "text": "follows um okay so what will actually be those layers I think um it's uh you know"
    },
    {
      "start": "00:28:23.909",
      "end": "00:28:23.919",
      "text": "those layers I think um it's uh you know"
    },
    {
      "start": "00:28:23.919",
      "end": "00:28:26.669",
      "text": "those layers I think um it's uh you know it's quite important to get into the U"
    },
    {
      "start": "00:28:26.669",
      "end": "00:28:26.679",
      "text": "it's quite important to get into the U"
    },
    {
      "start": "00:28:26.679",
      "end": "00:28:28.669",
      "text": "it's quite important to get into the U discussion now about other architectural"
    },
    {
      "start": "00:28:28.669",
      "end": "00:28:28.679",
      "text": "discussion now about other architectural"
    },
    {
      "start": "00:28:28.679",
      "end": "00:28:31.870",
      "text": "discussion now about other architectural features before we go into uh some kind"
    },
    {
      "start": "00:28:31.870",
      "end": "00:28:31.880",
      "text": "features before we go into uh some kind"
    },
    {
      "start": "00:28:31.880",
      "end": "00:28:34.470",
      "text": "features before we go into uh some kind of a discussion about the advantages of"
    },
    {
      "start": "00:28:34.470",
      "end": "00:28:34.480",
      "text": "of a discussion about the advantages of"
    },
    {
      "start": "00:28:34.480",
      "end": "00:28:36.990",
      "text": "of a discussion about the advantages of convolution layers as compared to fully"
    },
    {
      "start": "00:28:36.990",
      "end": "00:28:37.000",
      "text": "convolution layers as compared to fully"
    },
    {
      "start": "00:28:37.000",
      "end": "00:28:39.470",
      "text": "convolution layers as compared to fully connected layers which I think is best"
    },
    {
      "start": "00:28:39.470",
      "end": "00:28:39.480",
      "text": "connected layers which I think is best"
    },
    {
      "start": "00:28:39.480",
      "end": "00:28:42.509",
      "text": "connected layers which I think is best uh demonstrated using an example before"
    },
    {
      "start": "00:28:42.509",
      "end": "00:28:42.519",
      "text": "uh demonstrated using an example before"
    },
    {
      "start": "00:28:42.519",
      "end": "00:28:45.350",
      "text": "uh demonstrated using an example before we go into that example let's uh look at"
    },
    {
      "start": "00:28:45.350",
      "end": "00:28:45.360",
      "text": "we go into that example let's uh look at"
    },
    {
      "start": "00:28:45.360",
      "end": "00:28:47.990",
      "text": "we go into that example let's uh look at another um operation that we'll be"
    },
    {
      "start": "00:28:47.990",
      "end": "00:28:48.000",
      "text": "another um operation that we'll be"
    },
    {
      "start": "00:28:48.000",
      "end": "00:28:50.830",
      "text": "another um operation that we'll be calling uh the max pulling layer or in"
    },
    {
      "start": "00:28:50.830",
      "end": "00:28:50.840",
      "text": "calling uh the max pulling layer or in"
    },
    {
      "start": "00:28:50.840",
      "end": "00:28:53.470",
      "text": "calling uh the max pulling layer or in general pulling layer uh which is"
    },
    {
      "start": "00:28:53.470",
      "end": "00:28:53.480",
      "text": "general pulling layer uh which is"
    },
    {
      "start": "00:28:53.480",
      "end": "00:28:54.789",
      "text": "general pulling layer uh which is actually described here and it's best"
    },
    {
      "start": "00:28:54.789",
      "end": "00:28:54.799",
      "text": "actually described here and it's best"
    },
    {
      "start": "00:28:54.799",
      "end": "00:28:57.710",
      "text": "actually described here and it's best demonstrated with this kind of image um"
    },
    {
      "start": "00:28:57.710",
      "end": "00:28:57.720",
      "text": "demonstrated with this kind of image um"
    },
    {
      "start": "00:28:57.720",
      "end": "00:29:00.149",
      "text": "demonstrated with this kind of image um and this this case what we see we have"
    },
    {
      "start": "00:29:00.149",
      "end": "00:29:00.159",
      "text": "and this this case what we see we have"
    },
    {
      "start": "00:29:00.159",
      "end": "00:29:03.789",
      "text": "and this this case what we see we have an input feature map uh that uh has a"
    },
    {
      "start": "00:29:03.789",
      "end": "00:29:03.799",
      "text": "an input feature map uh that uh has a"
    },
    {
      "start": "00:29:03.799",
      "end": "00:29:08.070",
      "text": "an input feature map uh that uh has a depth of one in this case and uh we do"
    },
    {
      "start": "00:29:08.070",
      "end": "00:29:08.080",
      "text": "depth of one in this case and uh we do"
    },
    {
      "start": "00:29:08.080",
      "end": "00:29:09.950",
      "text": "depth of one in this case and uh we do still have the concept of if you like of"
    },
    {
      "start": "00:29:09.950",
      "end": "00:29:09.960",
      "text": "still have the concept of if you like of"
    },
    {
      "start": "00:29:09.960",
      "end": "00:29:11.750",
      "text": "still have the concept of if you like of a kernel that we slide around just like"
    },
    {
      "start": "00:29:11.750",
      "end": "00:29:11.760",
      "text": "a kernel that we slide around just like"
    },
    {
      "start": "00:29:11.760",
      "end": "00:29:14.310",
      "text": "a kernel that we slide around just like in the convolutional layer uh but in"
    },
    {
      "start": "00:29:14.310",
      "end": "00:29:14.320",
      "text": "in the convolutional layer uh but in"
    },
    {
      "start": "00:29:14.320",
      "end": "00:29:17.269",
      "text": "in the convolutional layer uh but in this case instead of a nonlinear"
    },
    {
      "start": "00:29:17.269",
      "end": "00:29:17.279",
      "text": "this case instead of a nonlinear"
    },
    {
      "start": "00:29:17.279",
      "end": "00:29:21.870",
      "text": "this case instead of a nonlinear function uh like a reu that we have"
    },
    {
      "start": "00:29:21.870",
      "end": "00:29:21.880",
      "text": "function uh like a reu that we have"
    },
    {
      "start": "00:29:21.880",
      "end": "00:29:23.269",
      "text": "function uh like a reu that we have actually also seen in the fully"
    },
    {
      "start": "00:29:23.269",
      "end": "00:29:23.279",
      "text": "actually also seen in the fully"
    },
    {
      "start": "00:29:23.279",
      "end": "00:29:26.909",
      "text": "actually also seen in the fully connected layers that uh we are still"
    },
    {
      "start": "00:29:26.909",
      "end": "00:29:26.919",
      "text": "connected layers that uh we are still"
    },
    {
      "start": "00:29:26.919",
      "end": "00:29:30.190",
      "text": "connected layers that uh we are still going to see in the evolutional layer uh"
    },
    {
      "start": "00:29:30.190",
      "end": "00:29:30.200",
      "text": "going to see in the evolutional layer uh"
    },
    {
      "start": "00:29:30.200",
      "end": "00:29:32.750",
      "text": "going to see in the evolutional layer uh as we will uh see in that example we"
    },
    {
      "start": "00:29:32.750",
      "end": "00:29:32.760",
      "text": "as we will uh see in that example we"
    },
    {
      "start": "00:29:32.760",
      "end": "00:29:36.230",
      "text": "as we will uh see in that example we will have another function uh let's call"
    },
    {
      "start": "00:29:36.230",
      "end": "00:29:36.240",
      "text": "will have another function uh let's call"
    },
    {
      "start": "00:29:36.240",
      "end": "00:29:38.149",
      "text": "will have another function uh let's call that function in this specific case it's"
    },
    {
      "start": "00:29:38.149",
      "end": "00:29:38.159",
      "text": "that function in this specific case it's"
    },
    {
      "start": "00:29:38.159",
      "end": "00:29:41.630",
      "text": "that function in this specific case it's shown as the max function uh where the"
    },
    {
      "start": "00:29:41.630",
      "end": "00:29:41.640",
      "text": "shown as the max function uh where the"
    },
    {
      "start": "00:29:41.640",
      "end": "00:29:44.549",
      "text": "shown as the max function uh where the the idea behind this is that uh we are"
    },
    {
      "start": "00:29:44.549",
      "end": "00:29:44.559",
      "text": "the idea behind this is that uh we are"
    },
    {
      "start": "00:29:44.559",
      "end": "00:29:47.070",
      "text": "the idea behind this is that uh we are going to um not form a correlation"
    },
    {
      "start": "00:29:47.070",
      "end": "00:29:47.080",
      "text": "going to um not form a correlation"
    },
    {
      "start": "00:29:47.080",
      "end": "00:29:49.590",
      "text": "going to um not form a correlation result over here uh like a DOT product"
    },
    {
      "start": "00:29:49.590",
      "end": "00:29:49.600",
      "text": "result over here uh like a DOT product"
    },
    {
      "start": "00:29:49.600",
      "end": "00:29:50.990",
      "text": "result over here uh like a DOT product but we're going to select the maximum"
    },
    {
      "start": "00:29:50.990",
      "end": "00:29:51.000",
      "text": "but we're going to select the maximum"
    },
    {
      "start": "00:29:51.000",
      "end": "00:29:53.710",
      "text": "but we're going to select the maximum element of what we see in the input uh"
    },
    {
      "start": "00:29:53.710",
      "end": "00:29:53.720",
      "text": "element of what we see in the input uh"
    },
    {
      "start": "00:29:53.720",
      "end": "00:29:56.630",
      "text": "element of what we see in the input uh feature map typically we apply the that"
    },
    {
      "start": "00:29:56.630",
      "end": "00:29:56.640",
      "text": "feature map typically we apply the that"
    },
    {
      "start": "00:29:56.640",
      "end": "00:29:59.350",
      "text": "feature map typically we apply the that function at for each of of the channels"
    },
    {
      "start": "00:29:59.350",
      "end": "00:29:59.360",
      "text": "function at for each of of the channels"
    },
    {
      "start": "00:29:59.360",
      "end": "00:30:01.509",
      "text": "function at for each of of the channels of the input feature map but in some"
    },
    {
      "start": "00:30:01.509",
      "end": "00:30:01.519",
      "text": "of the input feature map but in some"
    },
    {
      "start": "00:30:01.519",
      "end": "00:30:03.590",
      "text": "of the input feature map but in some instances we may apply it also across"
    },
    {
      "start": "00:30:03.590",
      "end": "00:30:03.600",
      "text": "instances we may apply it also across"
    },
    {
      "start": "00:30:03.600",
      "end": "00:30:05.590",
      "text": "instances we may apply it also across the depth Dimension what we are"
    },
    {
      "start": "00:30:05.590",
      "end": "00:30:05.600",
      "text": "the depth Dimension what we are"
    },
    {
      "start": "00:30:05.600",
      "end": "00:30:07.710",
      "text": "the depth Dimension what we are achieving is evidently we are achieving"
    },
    {
      "start": "00:30:07.710",
      "end": "00:30:07.720",
      "text": "achieving is evidently we are achieving"
    },
    {
      "start": "00:30:07.720",
      "end": "00:30:11.830",
      "text": "achieving is evidently we are achieving some reduction in the um uh spatial"
    },
    {
      "start": "00:30:11.830",
      "end": "00:30:11.840",
      "text": "some reduction in the um uh spatial"
    },
    {
      "start": "00:30:11.840",
      "end": "00:30:15.590",
      "text": "some reduction in the um uh spatial dimensions of the uh output feature map"
    },
    {
      "start": "00:30:15.590",
      "end": "00:30:15.600",
      "text": "dimensions of the uh output feature map"
    },
    {
      "start": "00:30:15.600",
      "end": "00:30:17.430",
      "text": "dimensions of the uh output feature map and uh that kind of intuitively"
    },
    {
      "start": "00:30:17.430",
      "end": "00:30:17.440",
      "text": "and uh that kind of intuitively"
    },
    {
      "start": "00:30:17.440",
      "end": "00:30:20.430",
      "text": "and uh that kind of intuitively understood as trying to select the most"
    },
    {
      "start": "00:30:20.430",
      "end": "00:30:20.440",
      "text": "understood as trying to select the most"
    },
    {
      "start": "00:30:20.440",
      "end": "00:30:23.549",
      "text": "understood as trying to select the most important features of the input feature"
    },
    {
      "start": "00:30:23.549",
      "end": "00:30:23.559",
      "text": "important features of the input feature"
    },
    {
      "start": "00:30:23.559",
      "end": "00:30:26.350",
      "text": "important features of the input feature map and transfer out into the layer"
    },
    {
      "start": "00:30:26.350",
      "end": "00:30:26.360",
      "text": "map and transfer out into the layer"
    },
    {
      "start": "00:30:26.360",
      "end": "00:30:29.149",
      "text": "map and transfer out into the layer above for further process say okay so"
    },
    {
      "start": "00:30:29.149",
      "end": "00:30:29.159",
      "text": "above for further process say okay so"
    },
    {
      "start": "00:30:29.159",
      "end": "00:30:31.470",
      "text": "above for further process say okay so that is the uh Max pooling layer in this"
    },
    {
      "start": "00:30:31.470",
      "end": "00:30:31.480",
      "text": "that is the uh Max pooling layer in this"
    },
    {
      "start": "00:30:31.480",
      "end": "00:30:33.830",
      "text": "that is the uh Max pooling layer in this case which is typically interl with"
    },
    {
      "start": "00:30:33.830",
      "end": "00:30:33.840",
      "text": "case which is typically interl with"
    },
    {
      "start": "00:30:33.840",
      "end": "00:30:37.029",
      "text": "case which is typically interl with convolutional layers as we will see in"
    },
    {
      "start": "00:30:37.029",
      "end": "00:30:37.039",
      "text": "convolutional layers as we will see in"
    },
    {
      "start": "00:30:37.039",
      "end": "00:30:39.310",
      "text": "convolutional layers as we will see in some example architectures closing I"
    },
    {
      "start": "00:30:39.310",
      "end": "00:30:39.320",
      "text": "some example architectures closing I"
    },
    {
      "start": "00:30:39.320",
      "end": "00:30:43.149",
      "text": "some example architectures closing I want to emphasize the another U kind of"
    },
    {
      "start": "00:30:43.149",
      "end": "00:30:43.159",
      "text": "want to emphasize the another U kind of"
    },
    {
      "start": "00:30:43.159",
      "end": "00:30:45.310",
      "text": "want to emphasize the another U kind of specific parameterization of the"
    },
    {
      "start": "00:30:45.310",
      "end": "00:30:45.320",
      "text": "specific parameterization of the"
    },
    {
      "start": "00:30:45.320",
      "end": "00:30:47.750",
      "text": "specific parameterization of the convolutional layer we call here the one"
    },
    {
      "start": "00:30:47.750",
      "end": "00:30:47.760",
      "text": "convolutional layer we call here the one"
    },
    {
      "start": "00:30:47.760",
      "end": "00:30:51.230",
      "text": "convolutional layer we call here the one by one convolutional layer um and it is"
    },
    {
      "start": "00:30:51.230",
      "end": "00:30:51.240",
      "text": "by one convolutional layer um and it is"
    },
    {
      "start": "00:30:51.240",
      "end": "00:30:54.549",
      "text": "by one convolutional layer um and it is definitely a a sort of a layer that it"
    },
    {
      "start": "00:30:54.549",
      "end": "00:30:54.559",
      "text": "definitely a a sort of a layer that it"
    },
    {
      "start": "00:30:54.559",
      "end": "00:30:57.549",
      "text": "definitely a a sort of a layer that it is um being met in various kind of"
    },
    {
      "start": "00:30:57.549",
      "end": "00:30:57.559",
      "text": "is um being met in various kind of"
    },
    {
      "start": "00:30:57.559",
      "end": "00:31:00.669",
      "text": "is um being met in various kind of architect lectures and and maybe it does"
    },
    {
      "start": "00:31:00.669",
      "end": "00:31:00.679",
      "text": "architect lectures and and maybe it does"
    },
    {
      "start": "00:31:00.679",
      "end": "00:31:02.629",
      "text": "architect lectures and and maybe it does not really make a lot of sense to you"
    },
    {
      "start": "00:31:02.629",
      "end": "00:31:02.639",
      "text": "not really make a lot of sense to you"
    },
    {
      "start": "00:31:02.639",
      "end": "00:31:04.430",
      "text": "not really make a lot of sense to you the moment you see this kind of"
    },
    {
      "start": "00:31:04.430",
      "end": "00:31:04.440",
      "text": "the moment you see this kind of"
    },
    {
      "start": "00:31:04.440",
      "end": "00:31:06.549",
      "text": "the moment you see this kind of Animation over here why in Earth we're"
    },
    {
      "start": "00:31:06.549",
      "end": "00:31:06.559",
      "text": "Animation over here why in Earth we're"
    },
    {
      "start": "00:31:06.559",
      "end": "00:31:09.870",
      "text": "Animation over here why in Earth we're going to do one by one convolutions uh"
    },
    {
      "start": "00:31:09.870",
      "end": "00:31:09.880",
      "text": "going to do one by one convolutions uh"
    },
    {
      "start": "00:31:09.880",
      "end": "00:31:11.750",
      "text": "going to do one by one convolutions uh since we as we discussed we're trying to"
    },
    {
      "start": "00:31:11.750",
      "end": "00:31:11.760",
      "text": "since we as we discussed we're trying to"
    },
    {
      "start": "00:31:11.760",
      "end": "00:31:14.269",
      "text": "since we as we discussed we're trying to detect features and typically the kernel"
    },
    {
      "start": "00:31:14.269",
      "end": "00:31:14.279",
      "text": "detect features and typically the kernel"
    },
    {
      "start": "00:31:14.279",
      "end": "00:31:16.669",
      "text": "detect features and typically the kernel sizes have larger Dimensions than one by"
    },
    {
      "start": "00:31:16.669",
      "end": "00:31:16.679",
      "text": "sizes have larger Dimensions than one by"
    },
    {
      "start": "00:31:16.679",
      "end": "00:31:20.590",
      "text": "sizes have larger Dimensions than one by one but I think um the the explanation"
    },
    {
      "start": "00:31:20.590",
      "end": "00:31:20.600",
      "text": "one but I think um the the explanation"
    },
    {
      "start": "00:31:20.600",
      "end": "00:31:23.590",
      "text": "one but I think um the the explanation potentially could be uh more intuitively"
    },
    {
      "start": "00:31:23.590",
      "end": "00:31:23.600",
      "text": "potentially could be uh more intuitively"
    },
    {
      "start": "00:31:23.600",
      "end": "00:31:25.070",
      "text": "potentially could be uh more intuitively understood if we see the"
    },
    {
      "start": "00:31:25.070",
      "end": "00:31:25.080",
      "text": "understood if we see the"
    },
    {
      "start": "00:31:25.080",
      "end": "00:31:27.509",
      "text": "understood if we see the three-dimensional version of uh of this"
    },
    {
      "start": "00:31:27.509",
      "end": "00:31:27.519",
      "text": "three-dimensional version of uh of this"
    },
    {
      "start": "00:31:27.519",
      "end": "00:31:31.149",
      "text": "three-dimensional version of uh of this one by one convolution so we have a see"
    },
    {
      "start": "00:31:31.149",
      "end": "00:31:31.159",
      "text": "one by one convolution so we have a see"
    },
    {
      "start": "00:31:31.159",
      "end": "00:31:35.350",
      "text": "one by one convolution so we have a see here the uh orange U filter that"
    },
    {
      "start": "00:31:35.350",
      "end": "00:31:35.360",
      "text": "here the uh orange U filter that"
    },
    {
      "start": "00:31:35.360",
      "end": "00:31:38.590",
      "text": "here the uh orange U filter that evidently the K size is one by one um"
    },
    {
      "start": "00:31:38.590",
      "end": "00:31:38.600",
      "text": "evidently the K size is one by one um"
    },
    {
      "start": "00:31:38.600",
      "end": "00:31:41.350",
      "text": "evidently the K size is one by one um and we have as we discussed earlier"
    },
    {
      "start": "00:31:41.350",
      "end": "00:31:41.360",
      "text": "and we have as we discussed earlier"
    },
    {
      "start": "00:31:41.360",
      "end": "00:31:43.629",
      "text": "and we have as we discussed earlier depth D that matches the depth of the"
    },
    {
      "start": "00:31:43.629",
      "end": "00:31:43.639",
      "text": "depth D that matches the depth of the"
    },
    {
      "start": "00:31:43.639",
      "end": "00:31:45.870",
      "text": "depth D that matches the depth of the input feature map and as we also"
    },
    {
      "start": "00:31:45.870",
      "end": "00:31:45.880",
      "text": "input feature map and as we also"
    },
    {
      "start": "00:31:45.880",
      "end": "00:31:49.669",
      "text": "input feature map and as we also discussed earlier the um um the this"
    },
    {
      "start": "00:31:49.669",
      "end": "00:31:49.679",
      "text": "discussed earlier the um um the this"
    },
    {
      "start": "00:31:49.679",
      "end": "00:31:54.149",
      "text": "discussed earlier the um um the this filter operation will move around uh we"
    },
    {
      "start": "00:31:54.149",
      "end": "00:31:54.159",
      "text": "filter operation will move around uh we"
    },
    {
      "start": "00:31:54.159",
      "end": "00:31:56.269",
      "text": "filter operation will move around uh we we're sliding around this filter and"
    },
    {
      "start": "00:31:56.269",
      "end": "00:31:56.279",
      "text": "we're sliding around this filter and"
    },
    {
      "start": "00:31:56.279",
      "end": "00:31:58.389",
      "text": "we're sliding around this filter and we're creating one slice"
    },
    {
      "start": "00:31:58.389",
      "end": "00:31:58.399",
      "text": "we're creating one slice"
    },
    {
      "start": "00:31:58.399",
      "end": "00:32:01.549",
      "text": "we're creating one slice uh for for this filter so in this one by"
    },
    {
      "start": "00:32:01.549",
      "end": "00:32:01.559",
      "text": "uh for for this filter so in this one by"
    },
    {
      "start": "00:32:01.559",
      "end": "00:32:04.149",
      "text": "uh for for this filter so in this one by one convolution we have just one slice"
    },
    {
      "start": "00:32:04.149",
      "end": "00:32:04.159",
      "text": "one convolution we have just one slice"
    },
    {
      "start": "00:32:04.159",
      "end": "00:32:06.909",
      "text": "one convolution we have just one slice and as you can see what we are achieving"
    },
    {
      "start": "00:32:06.909",
      "end": "00:32:06.919",
      "text": "and as you can see what we are achieving"
    },
    {
      "start": "00:32:06.919",
      "end": "00:32:11.389",
      "text": "and as you can see what we are achieving here we are forming a scalar uh by"
    },
    {
      "start": "00:32:11.389",
      "end": "00:32:11.399",
      "text": "here we are forming a scalar uh by"
    },
    {
      "start": "00:32:11.399",
      "end": "00:32:14.590",
      "text": "here we are forming a scalar uh by combining uh the uh depth compressing"
    },
    {
      "start": "00:32:14.590",
      "end": "00:32:14.600",
      "text": "combining uh the uh depth compressing"
    },
    {
      "start": "00:32:14.600",
      "end": "00:32:16.909",
      "text": "combining uh the uh depth compressing the whole depth Dimension so we actually"
    },
    {
      "start": "00:32:16.909",
      "end": "00:32:16.919",
      "text": "the whole depth Dimension so we actually"
    },
    {
      "start": "00:32:16.919",
      "end": "00:32:20.389",
      "text": "the whole depth Dimension so we actually have uh we are seeing typically this uh"
    },
    {
      "start": "00:32:20.389",
      "end": "00:32:20.399",
      "text": "have uh we are seeing typically this uh"
    },
    {
      "start": "00:32:20.399",
      "end": "00:32:23.350",
      "text": "have uh we are seeing typically this uh type of uh layers let's say towards the"
    },
    {
      "start": "00:32:23.350",
      "end": "00:32:23.360",
      "text": "type of uh layers let's say towards the"
    },
    {
      "start": "00:32:23.360",
      "end": "00:32:25.629",
      "text": "type of uh layers let's say towards the end of an network uh the top of the"
    },
    {
      "start": "00:32:25.629",
      "end": "00:32:25.639",
      "text": "end of an network uh the top of the"
    },
    {
      "start": "00:32:25.639",
      "end": "00:32:29.110",
      "text": "end of an network uh the top of the network where we uh just before the head"
    },
    {
      "start": "00:32:29.110",
      "end": "00:32:29.120",
      "text": "network where we uh just before the head"
    },
    {
      "start": "00:32:29.120",
      "end": "00:32:31.310",
      "text": "network where we uh just before the head where we want to just uh summarize"
    },
    {
      "start": "00:32:31.310",
      "end": "00:32:31.320",
      "text": "where we want to just uh summarize"
    },
    {
      "start": "00:32:31.320",
      "end": "00:32:33.350",
      "text": "where we want to just uh summarize everything we have done uh and we have"
    },
    {
      "start": "00:32:33.350",
      "end": "00:32:33.360",
      "text": "everything we have done uh and we have"
    },
    {
      "start": "00:32:33.360",
      "end": "00:32:36.350",
      "text": "everything we have done uh and we have learned in terms of uh U convolutions"
    },
    {
      "start": "00:32:36.350",
      "end": "00:32:36.360",
      "text": "learned in terms of uh U convolutions"
    },
    {
      "start": "00:32:36.360",
      "end": "00:32:38.789",
      "text": "learned in terms of uh U convolutions operations and across all depth"
    },
    {
      "start": "00:32:38.789",
      "end": "00:32:38.799",
      "text": "operations and across all depth"
    },
    {
      "start": "00:32:38.799",
      "end": "00:32:41.669",
      "text": "operations and across all depth Dimensions that we have uh uh decided to"
    },
    {
      "start": "00:32:41.669",
      "end": "00:32:41.679",
      "text": "Dimensions that we have uh uh decided to"
    },
    {
      "start": "00:32:41.679",
      "end": "00:32:43.909",
      "text": "Dimensions that we have uh uh decided to do and then we just need to compress"
    },
    {
      "start": "00:32:43.909",
      "end": "00:32:43.919",
      "text": "do and then we just need to compress"
    },
    {
      "start": "00:32:43.919",
      "end": "00:32:45.669",
      "text": "do and then we just need to compress that information to a matrix and"
    },
    {
      "start": "00:32:45.669",
      "end": "00:32:45.679",
      "text": "that information to a matrix and"
    },
    {
      "start": "00:32:45.679",
      "end": "00:32:48.950",
      "text": "that information to a matrix and potentially that kind of uh slice um is"
    },
    {
      "start": "00:32:48.950",
      "end": "00:32:48.960",
      "text": "potentially that kind of uh slice um is"
    },
    {
      "start": "00:32:48.960",
      "end": "00:32:51.029",
      "text": "potentially that kind of uh slice um is going to be flattened in order to be"
    },
    {
      "start": "00:32:51.029",
      "end": "00:32:51.039",
      "text": "going to be flattened in order to be"
    },
    {
      "start": "00:32:51.039",
      "end": "00:32:53.149",
      "text": "going to be flattened in order to be passed over into the"
    },
    {
      "start": "00:32:53.149",
      "end": "00:32:53.159",
      "text": "passed over into the"
    },
    {
      "start": "00:32:53.159",
      "end": "00:32:55.909",
      "text": "passed over into the head uh which may consist of fully"
    },
    {
      "start": "00:32:55.909",
      "end": "00:32:55.919",
      "text": "head uh which may consist of fully"
    },
    {
      "start": "00:32:55.919",
      "end": "00:32:58.269",
      "text": "head uh which may consist of fully connected layers as we'll see that in a"
    },
    {
      "start": "00:32:58.269",
      "end": "00:32:58.279",
      "text": "connected layers as we'll see that in a"
    },
    {
      "start": "00:32:58.279",
      "end": "00:33:00.190",
      "text": "connected layers as we'll see that in a moment okay so that's one application of"
    },
    {
      "start": "00:33:00.190",
      "end": "00:33:00.200",
      "text": "moment okay so that's one application of"
    },
    {
      "start": "00:33:00.200",
      "end": "00:33:02.830",
      "text": "moment okay so that's one application of the one by one convol uh convolution"
    },
    {
      "start": "00:33:02.830",
      "end": "00:33:02.840",
      "text": "the one by one convol uh convolution"
    },
    {
      "start": "00:33:02.840",
      "end": "00:33:06.230",
      "text": "the one by one convol uh convolution operation all right so um it it it kind"
    },
    {
      "start": "00:33:06.230",
      "end": "00:33:06.240",
      "text": "operation all right so um it it it kind"
    },
    {
      "start": "00:33:06.240",
      "end": "00:33:08.990",
      "text": "operation all right so um it it it kind of looks like an multi-layer Petron or a"
    },
    {
      "start": "00:33:08.990",
      "end": "00:33:09.000",
      "text": "of looks like an multi-layer Petron or a"
    },
    {
      "start": "00:33:09.000",
      "end": "00:33:12.190",
      "text": "of looks like an multi-layer Petron or a dense layer as it is combining these uh"
    },
    {
      "start": "00:33:12.190",
      "end": "00:33:12.200",
      "text": "dense layer as it is combining these uh"
    },
    {
      "start": "00:33:12.200",
      "end": "00:33:15.269",
      "text": "dense layer as it is combining these uh depth Dimensions into that scaler all"
    },
    {
      "start": "00:33:15.269",
      "end": "00:33:15.279",
      "text": "depth Dimensions into that scaler all"
    },
    {
      "start": "00:33:15.279",
      "end": "00:33:20.629",
      "text": "depth Dimensions into that scaler all right so um let's now see some example"
    },
    {
      "start": "00:33:20.629",
      "end": "00:33:20.639",
      "text": "right so um let's now see some example"
    },
    {
      "start": "00:33:20.639",
      "end": "00:33:23.110",
      "text": "right so um let's now see some example architectures uh these example"
    },
    {
      "start": "00:33:23.110",
      "end": "00:33:23.120",
      "text": "architectures uh these example"
    },
    {
      "start": "00:33:23.120",
      "end": "00:33:26.549",
      "text": "architectures uh these example architectures um could potentially be"
    },
    {
      "start": "00:33:26.549",
      "end": "00:33:26.559",
      "text": "architectures um could potentially be"
    },
    {
      "start": "00:33:26.559",
      "end": "00:33:29.549",
      "text": "architectures um could potentially be like the toy Network that we see here um"
    },
    {
      "start": "00:33:29.549",
      "end": "00:33:29.559",
      "text": "like the toy Network that we see here um"
    },
    {
      "start": "00:33:29.559",
      "end": "00:33:32.110",
      "text": "like the toy Network that we see here um where we have uh as we discussed the"
    },
    {
      "start": "00:33:32.110",
      "end": "00:33:32.120",
      "text": "where we have uh as we discussed the"
    },
    {
      "start": "00:33:32.120",
      "end": "00:33:34.710",
      "text": "where we have uh as we discussed the convolutional layer followed by"
    },
    {
      "start": "00:33:34.710",
      "end": "00:33:34.720",
      "text": "convolutional layer followed by"
    },
    {
      "start": "00:33:34.720",
      "end": "00:33:38.190",
      "text": "convolutional layer followed by nonlinearity and Max pulling layers and"
    },
    {
      "start": "00:33:38.190",
      "end": "00:33:38.200",
      "text": "nonlinearity and Max pulling layers and"
    },
    {
      "start": "00:33:38.200",
      "end": "00:33:40.629",
      "text": "nonlinearity and Max pulling layers and finally at the end we expect to see a"
    },
    {
      "start": "00:33:40.629",
      "end": "00:33:40.639",
      "text": "finally at the end we expect to see a"
    },
    {
      "start": "00:33:40.639",
      "end": "00:33:43.350",
      "text": "finally at the end we expect to see a fully connected uh layer that is going"
    },
    {
      "start": "00:33:43.350",
      "end": "00:33:43.360",
      "text": "fully connected uh layer that is going"
    },
    {
      "start": "00:33:43.360",
      "end": "00:33:46.950",
      "text": "fully connected uh layer that is going to play the uh the role of the of the"
    },
    {
      "start": "00:33:46.950",
      "end": "00:33:46.960",
      "text": "to play the uh the role of the of the"
    },
    {
      "start": "00:33:46.960",
      "end": "00:33:49.269",
      "text": "to play the uh the role of the of the head of the network uh where we have"
    },
    {
      "start": "00:33:49.269",
      "end": "00:33:49.279",
      "text": "head of the network uh where we have"
    },
    {
      "start": "00:33:49.279",
      "end": "00:33:52.230",
      "text": "head of the network uh where we have let's say in this case uh five classes"
    },
    {
      "start": "00:33:52.230",
      "end": "00:33:52.240",
      "text": "let's say in this case uh five classes"
    },
    {
      "start": "00:33:52.240",
      "end": "00:33:53.590",
      "text": "let's say in this case uh five classes that we would like to do a"
    },
    {
      "start": "00:33:53.590",
      "end": "00:33:53.600",
      "text": "that we would like to do a"
    },
    {
      "start": "00:33:53.600",
      "end": "00:33:56.110",
      "text": "that we would like to do a classification on but uh instead of"
    },
    {
      "start": "00:33:56.110",
      "end": "00:33:56.120",
      "text": "classification on but uh instead of"
    },
    {
      "start": "00:33:56.120",
      "end": "00:33:58.230",
      "text": "classification on but uh instead of looking at this toy Network work and I"
    },
    {
      "start": "00:33:58.230",
      "end": "00:33:58.240",
      "text": "looking at this toy Network work and I"
    },
    {
      "start": "00:33:58.240",
      "end": "00:33:59.830",
      "text": "looking at this toy Network work and I think it's a bit more instructive to"
    },
    {
      "start": "00:33:59.830",
      "end": "00:33:59.840",
      "text": "think it's a bit more instructive to"
    },
    {
      "start": "00:33:59.840",
      "end": "00:34:02.590",
      "text": "think it's a bit more instructive to look at uh I will call it canonical"
    },
    {
      "start": "00:34:02.590",
      "end": "00:34:02.600",
      "text": "look at uh I will call it canonical"
    },
    {
      "start": "00:34:02.600",
      "end": "00:34:04.549",
      "text": "look at uh I will call it canonical architecture called vgg from the"
    },
    {
      "start": "00:34:04.549",
      "end": "00:34:04.559",
      "text": "architecture called vgg from the"
    },
    {
      "start": "00:34:04.559",
      "end": "00:34:08.030",
      "text": "architecture called vgg from the initials of the uh authors uh of that"
    },
    {
      "start": "00:34:08.030",
      "end": "00:34:08.040",
      "text": "initials of the uh authors uh of that"
    },
    {
      "start": "00:34:08.040",
      "end": "00:34:10.310",
      "text": "initials of the uh authors uh of that kind of architecture this architecture"
    },
    {
      "start": "00:34:10.310",
      "end": "00:34:10.320",
      "text": "kind of architecture this architecture"
    },
    {
      "start": "00:34:10.320",
      "end": "00:34:13.510",
      "text": "kind of architecture this architecture uh is um I call an architecture that I"
    },
    {
      "start": "00:34:13.510",
      "end": "00:34:13.520",
      "text": "uh is um I call an architecture that I"
    },
    {
      "start": "00:34:13.520",
      "end": "00:34:15.950",
      "text": "uh is um I call an architecture that I suggest students to start from every"
    },
    {
      "start": "00:34:15.950",
      "end": "00:34:15.960",
      "text": "suggest students to start from every"
    },
    {
      "start": "00:34:15.960",
      "end": "00:34:17.270",
      "text": "suggest students to start from every time they want to look at these"
    },
    {
      "start": "00:34:17.270",
      "end": "00:34:17.280",
      "text": "time they want to look at these"
    },
    {
      "start": "00:34:17.280",
      "end": "00:34:19.829",
      "text": "time they want to look at these convolutional uh networks because they"
    },
    {
      "start": "00:34:19.829",
      "end": "00:34:19.839",
      "text": "convolutional uh networks because they"
    },
    {
      "start": "00:34:19.839",
      "end": "00:34:22.829",
      "text": "convolutional uh networks because they do represent some kind of a initial good"
    },
    {
      "start": "00:34:22.829",
      "end": "00:34:22.839",
      "text": "do represent some kind of a initial good"
    },
    {
      "start": "00:34:22.839",
      "end": "00:34:25.270",
      "text": "do represent some kind of a initial good architecture that we can uh sort of make"
    },
    {
      "start": "00:34:25.270",
      "end": "00:34:25.280",
      "text": "architecture that we can uh sort of make"
    },
    {
      "start": "00:34:25.280",
      "end": "00:34:27.790",
      "text": "architecture that we can uh sort of make some conclusions in regarding the"
    },
    {
      "start": "00:34:27.790",
      "end": "00:34:27.800",
      "text": "some conclusions in regarding the"
    },
    {
      "start": "00:34:27.800",
      "end": "00:34:30.149",
      "text": "some conclusions in regarding the dimensionality and the patterns that we"
    },
    {
      "start": "00:34:30.149",
      "end": "00:34:30.159",
      "text": "dimensionality and the patterns that we"
    },
    {
      "start": "00:34:30.159",
      "end": "00:34:32.629",
      "text": "dimensionality and the patterns that we expect to see in a typical uh CNN"
    },
    {
      "start": "00:34:32.629",
      "end": "00:34:32.639",
      "text": "expect to see in a typical uh CNN"
    },
    {
      "start": "00:34:32.639",
      "end": "00:34:34.069",
      "text": "expect to see in a typical uh CNN architecture instead of looking if you"
    },
    {
      "start": "00:34:34.069",
      "end": "00:34:34.079",
      "text": "architecture instead of looking if you"
    },
    {
      "start": "00:34:34.079",
      "end": "00:34:36.829",
      "text": "architecture instead of looking if you like in the most modern uh versions of"
    },
    {
      "start": "00:34:36.829",
      "end": "00:34:36.839",
      "text": "like in the most modern uh versions of"
    },
    {
      "start": "00:34:36.839",
      "end": "00:34:39.069",
      "text": "like in the most modern uh versions of CNN I think it's worthwhile looking at"
    },
    {
      "start": "00:34:39.069",
      "end": "00:34:39.079",
      "text": "CNN I think it's worthwhile looking at"
    },
    {
      "start": "00:34:39.079",
      "end": "00:34:41.389",
      "text": "CNN I think it's worthwhile looking at this uh to understand a couple of things"
    },
    {
      "start": "00:34:41.389",
      "end": "00:34:41.399",
      "text": "this uh to understand a couple of things"
    },
    {
      "start": "00:34:41.399",
      "end": "00:34:43.790",
      "text": "this uh to understand a couple of things so the first thing that we'd like to um"
    },
    {
      "start": "00:34:43.790",
      "end": "00:34:43.800",
      "text": "so the first thing that we'd like to um"
    },
    {
      "start": "00:34:43.800",
      "end": "00:34:47.109",
      "text": "so the first thing that we'd like to um capture over here is this image uh and"
    },
    {
      "start": "00:34:47.109",
      "end": "00:34:47.119",
      "text": "capture over here is this image uh and"
    },
    {
      "start": "00:34:47.119",
      "end": "00:34:48.589",
      "text": "capture over here is this image uh and understand what is really"
    },
    {
      "start": "00:34:48.589",
      "end": "00:34:48.599",
      "text": "understand what is really"
    },
    {
      "start": "00:34:48.599",
      "end": "00:34:52.869",
      "text": "understand what is really happening okay so uh the image is uh the"
    },
    {
      "start": "00:34:52.869",
      "end": "00:34:52.879",
      "text": "happening okay so uh the image is uh the"
    },
    {
      "start": "00:34:52.879",
      "end": "00:34:56.589",
      "text": "happening okay so uh the image is uh the in this figure we see um a CNN layer uh"
    },
    {
      "start": "00:34:56.589",
      "end": "00:34:56.599",
      "text": "in this figure we see um a CNN layer uh"
    },
    {
      "start": "00:34:56.599",
      "end": "00:34:58.670",
      "text": "in this figure we see um a CNN layer uh so a CNN Network that consist of"
    },
    {
      "start": "00:34:58.670",
      "end": "00:34:58.680",
      "text": "so a CNN Network that consist of"
    },
    {
      "start": "00:34:58.680",
      "end": "00:35:01.550",
      "text": "so a CNN Network that consist of multiple layers and one striking thing"
    },
    {
      "start": "00:35:01.550",
      "end": "00:35:01.560",
      "text": "multiple layers and one striking thing"
    },
    {
      "start": "00:35:01.560",
      "end": "00:35:04.630",
      "text": "multiple layers and one striking thing from the get-go that you can see is that"
    },
    {
      "start": "00:35:04.630",
      "end": "00:35:04.640",
      "text": "from the get-go that you can see is that"
    },
    {
      "start": "00:35:04.640",
      "end": "00:35:07.670",
      "text": "from the get-go that you can see is that the CNN is um the"
    },
    {
      "start": "00:35:07.670",
      "end": "00:35:07.680",
      "text": "the CNN is um the"
    },
    {
      "start": "00:35:07.680",
      "end": "00:35:10.870",
      "text": "the CNN is um the dimensionality of the CNN is in terms of"
    },
    {
      "start": "00:35:10.870",
      "end": "00:35:10.880",
      "text": "dimensionality of the CNN is in terms of"
    },
    {
      "start": "00:35:10.880",
      "end": "00:35:13.670",
      "text": "dimensionality of the CNN is in terms of spatial Dimensions is evidently"
    },
    {
      "start": "00:35:13.670",
      "end": "00:35:13.680",
      "text": "spatial Dimensions is evidently"
    },
    {
      "start": "00:35:13.680",
      "end": "00:35:16.430",
      "text": "spatial Dimensions is evidently shrinking as we are going deeper so we"
    },
    {
      "start": "00:35:16.430",
      "end": "00:35:16.440",
      "text": "shrinking as we are going deeper so we"
    },
    {
      "start": "00:35:16.440",
      "end": "00:35:18.870",
      "text": "shrinking as we are going deeper so we see the uh convolutional layers followed"
    },
    {
      "start": "00:35:18.870",
      "end": "00:35:18.880",
      "text": "see the uh convolutional layers followed"
    },
    {
      "start": "00:35:18.880",
      "end": "00:35:20.270",
      "text": "see the uh convolutional layers followed by Max pulling"
    },
    {
      "start": "00:35:20.270",
      "end": "00:35:20.280",
      "text": "by Max pulling"
    },
    {
      "start": "00:35:20.280",
      "end": "00:35:23.750",
      "text": "by Max pulling layers U for and then towards the end we"
    },
    {
      "start": "00:35:23.750",
      "end": "00:35:23.760",
      "text": "layers U for and then towards the end we"
    },
    {
      "start": "00:35:23.760",
      "end": "00:35:26.190",
      "text": "layers U for and then towards the end we see the fully connected uh network uh"
    },
    {
      "start": "00:35:26.190",
      "end": "00:35:26.200",
      "text": "see the fully connected uh network uh"
    },
    {
      "start": "00:35:26.200",
      "end": "00:35:28.790",
      "text": "see the fully connected uh network uh which is the head so in terms of spatial"
    },
    {
      "start": "00:35:28.790",
      "end": "00:35:28.800",
      "text": "which is the head so in terms of spatial"
    },
    {
      "start": "00:35:28.800",
      "end": "00:35:32.230",
      "text": "which is the head so in terms of spatial Dimensions we are actually uh decreasing"
    },
    {
      "start": "00:35:32.230",
      "end": "00:35:32.240",
      "text": "Dimensions we are actually uh decreasing"
    },
    {
      "start": "00:35:32.240",
      "end": "00:35:34.109",
      "text": "Dimensions we are actually uh decreasing the spatial Dimensions because evidently"
    },
    {
      "start": "00:35:34.109",
      "end": "00:35:34.119",
      "text": "the spatial Dimensions because evidently"
    },
    {
      "start": "00:35:34.119",
      "end": "00:35:38.030",
      "text": "the spatial Dimensions because evidently we are using Kels which are larger than"
    },
    {
      "start": "00:35:38.030",
      "end": "00:35:38.040",
      "text": "we are using Kels which are larger than"
    },
    {
      "start": "00:35:38.040",
      "end": "00:35:40.470",
      "text": "we are using Kels which are larger than one by one and"
    },
    {
      "start": "00:35:40.470",
      "end": "00:35:40.480",
      "text": "one by one and"
    },
    {
      "start": "00:35:40.480",
      "end": "00:35:43.750",
      "text": "one by one and uh and but on at the same time what we"
    },
    {
      "start": "00:35:43.750",
      "end": "00:35:43.760",
      "text": "uh and but on at the same time what we"
    },
    {
      "start": "00:35:43.760",
      "end": "00:35:46.589",
      "text": "uh and but on at the same time what we are also are seeing is we see an"
    },
    {
      "start": "00:35:46.589",
      "end": "00:35:46.599",
      "text": "are also are seeing is we see an"
    },
    {
      "start": "00:35:46.599",
      "end": "00:35:50.069",
      "text": "are also are seeing is we see an increase in the depth Dimension so in"
    },
    {
      "start": "00:35:50.069",
      "end": "00:35:50.079",
      "text": "increase in the depth Dimension so in"
    },
    {
      "start": "00:35:50.079",
      "end": "00:35:53.349",
      "text": "increase in the depth Dimension so in terms of numbers over here 224x 224"
    },
    {
      "start": "00:35:53.349",
      "end": "00:35:53.359",
      "text": "terms of numbers over here 224x 224"
    },
    {
      "start": "00:35:53.359",
      "end": "00:35:55.390",
      "text": "terms of numbers over here 224x 224 pixels are the spatial dimensions of the"
    },
    {
      "start": "00:35:55.390",
      "end": "00:35:55.400",
      "text": "pixels are the spatial dimensions of the"
    },
    {
      "start": "00:35:55.400",
      "end": "00:35:56.390",
      "text": "pixels are the spatial dimensions of the input"
    },
    {
      "start": "00:35:56.390",
      "end": "00:35:56.400",
      "text": "input"
    },
    {
      "start": "00:35:56.400",
      "end": "00:35:59.790",
      "text": "input images um and then uh"
    },
    {
      "start": "00:35:59.790",
      "end": "00:35:59.800",
      "text": "images um and then uh"
    },
    {
      "start": "00:35:59.800",
      "end": "00:36:03.670",
      "text": "images um and then uh um and then we have a 64 to be the depth"
    },
    {
      "start": "00:36:03.670",
      "end": "00:36:03.680",
      "text": "um and then we have a 64 to be the depth"
    },
    {
      "start": "00:36:03.680",
      "end": "00:36:06.150",
      "text": "um and then we have a 64 to be the depth dimension of the or equivalent the"
    },
    {
      "start": "00:36:06.150",
      "end": "00:36:06.160",
      "text": "dimension of the or equivalent the"
    },
    {
      "start": "00:36:06.160",
      "end": "00:36:10.150",
      "text": "dimension of the or equivalent the number of neurons in the U that we have"
    },
    {
      "start": "00:36:10.150",
      "end": "00:36:10.160",
      "text": "number of neurons in the U that we have"
    },
    {
      "start": "00:36:10.160",
      "end": "00:36:12.630",
      "text": "number of neurons in the U that we have in or the number of filters that we have"
    },
    {
      "start": "00:36:12.630",
      "end": "00:36:12.640",
      "text": "in or the number of filters that we have"
    },
    {
      "start": "00:36:12.640",
      "end": "00:36:15.230",
      "text": "in or the number of filters that we have in in that layer so this is also our"
    },
    {
      "start": "00:36:15.230",
      "end": "00:36:15.240",
      "text": "in in that layer so this is also our"
    },
    {
      "start": "00:36:15.240",
      "end": "00:36:17.750",
      "text": "in in that layer so this is also our responsibility so our responsibility are"
    },
    {
      "start": "00:36:17.750",
      "end": "00:36:17.760",
      "text": "responsibility so our responsibility are"
    },
    {
      "start": "00:36:17.760",
      "end": "00:36:20.069",
      "text": "responsibility so our responsibility are twofold one is to with a padding and"
    },
    {
      "start": "00:36:20.069",
      "end": "00:36:20.079",
      "text": "twofold one is to with a padding and"
    },
    {
      "start": "00:36:20.079",
      "end": "00:36:22.750",
      "text": "twofold one is to with a padding and stride parameters to massage these kind"
    },
    {
      "start": "00:36:22.750",
      "end": "00:36:22.760",
      "text": "stride parameters to massage these kind"
    },
    {
      "start": "00:36:22.760",
      "end": "00:36:25.390",
      "text": "stride parameters to massage these kind of special dimensions we need and at the"
    },
    {
      "start": "00:36:25.390",
      "end": "00:36:25.400",
      "text": "of special dimensions we need and at the"
    },
    {
      "start": "00:36:25.400",
      "end": "00:36:26.829",
      "text": "of special dimensions we need and at the same time also select the number of"
    },
    {
      "start": "00:36:26.829",
      "end": "00:36:26.839",
      "text": "same time also select the number of"
    },
    {
      "start": "00:36:26.839",
      "end": "00:36:28.470",
      "text": "same time also select the number of filters how many any convolutional"
    },
    {
      "start": "00:36:28.470",
      "end": "00:36:28.480",
      "text": "filters how many any convolutional"
    },
    {
      "start": "00:36:28.480",
      "end": "00:36:30.230",
      "text": "filters how many any convolutional neurons are we going to engage in that"
    },
    {
      "start": "00:36:30.230",
      "end": "00:36:30.240",
      "text": "neurons are we going to engage in that"
    },
    {
      "start": "00:36:30.240",
      "end": "00:36:32.910",
      "text": "neurons are we going to engage in that layer so as you can see we go from 64"
    },
    {
      "start": "00:36:32.910",
      "end": "00:36:32.920",
      "text": "layer so as you can see we go from 64"
    },
    {
      "start": "00:36:32.920",
      "end": "00:36:38.349",
      "text": "layer so as you can see we go from 64 128 256 512 that is really the uh end"
    },
    {
      "start": "00:36:38.349",
      "end": "00:36:38.359",
      "text": "128 256 512 that is really the uh end"
    },
    {
      "start": "00:36:38.359",
      "end": "00:36:40.470",
      "text": "128 256 512 that is really the uh end game with respect to number of filters"
    },
    {
      "start": "00:36:40.470",
      "end": "00:36:40.480",
      "text": "game with respect to number of filters"
    },
    {
      "start": "00:36:40.480",
      "end": "00:36:42.270",
      "text": "game with respect to number of filters the intuition behind the increase in the"
    },
    {
      "start": "00:36:42.270",
      "end": "00:36:42.280",
      "text": "the intuition behind the increase in the"
    },
    {
      "start": "00:36:42.280",
      "end": "00:36:44.630",
      "text": "the intuition behind the increase in the number of filters as the network becomes"
    },
    {
      "start": "00:36:44.630",
      "end": "00:36:44.640",
      "text": "number of filters as the network becomes"
    },
    {
      "start": "00:36:44.640",
      "end": "00:36:46.950",
      "text": "number of filters as the network becomes uh becomes deeper and deeper is the"
    },
    {
      "start": "00:36:46.950",
      "end": "00:36:46.960",
      "text": "uh becomes deeper and deeper is the"
    },
    {
      "start": "00:36:46.960",
      "end": "00:36:49.390",
      "text": "uh becomes deeper and deeper is the following the network is learning more"
    },
    {
      "start": "00:36:49.390",
      "end": "00:36:49.400",
      "text": "following the network is learning more"
    },
    {
      "start": "00:36:49.400",
      "end": "00:36:52.230",
      "text": "following the network is learning more and more complicated features as we are"
    },
    {
      "start": "00:36:52.230",
      "end": "00:36:52.240",
      "text": "and more complicated features as we are"
    },
    {
      "start": "00:36:52.240",
      "end": "00:36:56.109",
      "text": "and more complicated features as we are going deeper the first layers are uh the"
    },
    {
      "start": "00:36:56.109",
      "end": "00:36:56.119",
      "text": "going deeper the first layers are uh the"
    },
    {
      "start": "00:36:56.119",
      "end": "00:36:59.710",
      "text": "going deeper the first layers are uh the um are are learning representations"
    },
    {
      "start": "00:36:59.710",
      "end": "00:36:59.720",
      "text": "um are are learning representations"
    },
    {
      "start": "00:36:59.720",
      "end": "00:37:02.670",
      "text": "um are are learning representations which are uh simple shapes I will call"
    },
    {
      "start": "00:37:02.670",
      "end": "00:37:02.680",
      "text": "which are uh simple shapes I will call"
    },
    {
      "start": "00:37:02.680",
      "end": "00:37:05.230",
      "text": "which are uh simple shapes I will call it similar things that you would expect"
    },
    {
      "start": "00:37:05.230",
      "end": "00:37:05.240",
      "text": "it similar things that you would expect"
    },
    {
      "start": "00:37:05.240",
      "end": "00:37:08.510",
      "text": "it similar things that you would expect to uh uh for you to understand when you"
    },
    {
      "start": "00:37:08.510",
      "end": "00:37:08.520",
      "text": "to uh uh for you to understand when you"
    },
    {
      "start": "00:37:08.520",
      "end": "00:37:10.349",
      "text": "to uh uh for you to understand when you look at if you like at a kind of a"
    },
    {
      "start": "00:37:10.349",
      "end": "00:37:10.359",
      "text": "look at if you like at a kind of a"
    },
    {
      "start": "00:37:10.359",
      "end": "00:37:12.750",
      "text": "look at if you like at a kind of a primitive shape like a circle uh a"
    },
    {
      "start": "00:37:12.750",
      "end": "00:37:12.760",
      "text": "primitive shape like a circle uh a"
    },
    {
      "start": "00:37:12.760",
      "end": "00:37:17.030",
      "text": "primitive shape like a circle uh a triangle or whatever have you and the uh"
    },
    {
      "start": "00:37:17.030",
      "end": "00:37:17.040",
      "text": "triangle or whatever have you and the uh"
    },
    {
      "start": "00:37:17.040",
      "end": "00:37:18.790",
      "text": "triangle or whatever have you and the uh subsequent kind of layers are actually"
    },
    {
      "start": "00:37:18.790",
      "end": "00:37:18.800",
      "text": "subsequent kind of layers are actually"
    },
    {
      "start": "00:37:18.800",
      "end": "00:37:20.430",
      "text": "subsequent kind of layers are actually learning more and more complicated"
    },
    {
      "start": "00:37:20.430",
      "end": "00:37:20.440",
      "text": "learning more and more complicated"
    },
    {
      "start": "00:37:20.440",
      "end": "00:37:22.589",
      "text": "learning more and more complicated representations we'll see in a moment"
    },
    {
      "start": "00:37:22.589",
      "end": "00:37:22.599",
      "text": "representations we'll see in a moment"
    },
    {
      "start": "00:37:22.599",
      "end": "00:37:25.109",
      "text": "representations we'll see in a moment some examples of exactly what these"
    },
    {
      "start": "00:37:25.109",
      "end": "00:37:25.119",
      "text": "some examples of exactly what these"
    },
    {
      "start": "00:37:25.119",
      "end": "00:37:28.430",
      "text": "some examples of exactly what these layers are learning and by suitable"
    },
    {
      "start": "00:37:28.430",
      "end": "00:37:28.440",
      "text": "layers are learning and by suitable"
    },
    {
      "start": "00:37:28.440",
      "end": "00:37:32.390",
      "text": "layers are learning and by suitable visualizations so as you are trying to"
    },
    {
      "start": "00:37:32.390",
      "end": "00:37:32.400",
      "text": "visualizations so as you are trying to"
    },
    {
      "start": "00:37:32.400",
      "end": "00:37:34.950",
      "text": "visualizations so as you are trying to uh create uh combinations of these"
    },
    {
      "start": "00:37:34.950",
      "end": "00:37:34.960",
      "text": "uh create uh combinations of these"
    },
    {
      "start": "00:37:34.960",
      "end": "00:37:37.470",
      "text": "uh create uh combinations of these simpler representations you probably"
    },
    {
      "start": "00:37:37.470",
      "end": "00:37:37.480",
      "text": "simpler representations you probably"
    },
    {
      "start": "00:37:37.480",
      "end": "00:37:40.109",
      "text": "simpler representations you probably need all to be doing more of those"
    },
    {
      "start": "00:37:40.109",
      "end": "00:37:40.119",
      "text": "need all to be doing more of those"
    },
    {
      "start": "00:37:40.119",
      "end": "00:37:42.550",
      "text": "need all to be doing more of those combinations as you go deeper because uh"
    },
    {
      "start": "00:37:42.550",
      "end": "00:37:42.560",
      "text": "combinations as you go deeper because uh"
    },
    {
      "start": "00:37:42.560",
      "end": "00:37:44.589",
      "text": "combinations as you go deeper because uh you are trying to understand whether or"
    },
    {
      "start": "00:37:44.589",
      "end": "00:37:44.599",
      "text": "you are trying to understand whether or"
    },
    {
      "start": "00:37:44.599",
      "end": "00:37:46.950",
      "text": "you are trying to understand whether or not there's one combination that"
    },
    {
      "start": "00:37:46.950",
      "end": "00:37:46.960",
      "text": "not there's one combination that"
    },
    {
      "start": "00:37:46.960",
      "end": "00:37:49.390",
      "text": "not there's one combination that actually magically generating the right"
    },
    {
      "start": "00:37:49.390",
      "end": "00:37:49.400",
      "text": "actually magically generating the right"
    },
    {
      "start": "00:37:49.400",
      "end": "00:37:51.550",
      "text": "actually magically generating the right set of representations in subsequent"
    },
    {
      "start": "00:37:51.550",
      "end": "00:37:51.560",
      "text": "set of representations in subsequent"
    },
    {
      "start": "00:37:51.560",
      "end": "00:37:53.950",
      "text": "set of representations in subsequent deeper layers such that your head can"
    },
    {
      "start": "00:37:53.950",
      "end": "00:37:53.960",
      "text": "deeper layers such that your head can"
    },
    {
      "start": "00:37:53.960",
      "end": "00:37:56.870",
      "text": "deeper layers such that your head can actually do the job so that's the first"
    },
    {
      "start": "00:37:56.870",
      "end": "00:37:56.880",
      "text": "actually do the job so that's the first"
    },
    {
      "start": "00:37:56.880",
      "end": "00:37:58.030",
      "text": "actually do the job so that's the first uh intuition"
    },
    {
      "start": "00:37:58.030",
      "end": "00:37:58.040",
      "text": "uh intuition"
    },
    {
      "start": "00:37:58.040",
      "end": "00:38:01.390",
      "text": "uh intuition regarding the um uh increase in the"
    },
    {
      "start": "00:38:01.390",
      "end": "00:38:01.400",
      "text": "regarding the um uh increase in the"
    },
    {
      "start": "00:38:01.400",
      "end": "00:38:04.750",
      "text": "regarding the um uh increase in the depth of the um of the of the filters"
    },
    {
      "start": "00:38:04.750",
      "end": "00:38:04.760",
      "text": "depth of the um of the of the filters"
    },
    {
      "start": "00:38:04.760",
      "end": "00:38:07.910",
      "text": "depth of the um of the of the filters the second is that you can afford to I"
    },
    {
      "start": "00:38:07.910",
      "end": "00:38:07.920",
      "text": "the second is that you can afford to I"
    },
    {
      "start": "00:38:07.920",
      "end": "00:38:10.670",
      "text": "the second is that you can afford to I mean you can afford having uh that kind"
    },
    {
      "start": "00:38:10.670",
      "end": "00:38:10.680",
      "text": "mean you can afford having uh that kind"
    },
    {
      "start": "00:38:10.680",
      "end": "00:38:13.349",
      "text": "mean you can afford having uh that kind of increase in the depth of the filter"
    },
    {
      "start": "00:38:13.349",
      "end": "00:38:13.359",
      "text": "of increase in the depth of the filter"
    },
    {
      "start": "00:38:13.359",
      "end": "00:38:15.630",
      "text": "of increase in the depth of the filter uh and without really paying too much uh"
    },
    {
      "start": "00:38:15.630",
      "end": "00:38:15.640",
      "text": "uh and without really paying too much uh"
    },
    {
      "start": "00:38:15.640",
      "end": "00:38:17.950",
      "text": "uh and without really paying too much uh complexity uh performance sorry"
    },
    {
      "start": "00:38:17.950",
      "end": "00:38:17.960",
      "text": "complexity uh performance sorry"
    },
    {
      "start": "00:38:17.960",
      "end": "00:38:20.309",
      "text": "complexity uh performance sorry complexity in the in the terms of number"
    },
    {
      "start": "00:38:20.309",
      "end": "00:38:20.319",
      "text": "complexity in the in the terms of number"
    },
    {
      "start": "00:38:20.319",
      "end": "00:38:23.390",
      "text": "complexity in the in the terms of number of operations because your special"
    },
    {
      "start": "00:38:23.390",
      "end": "00:38:23.400",
      "text": "of operations because your special"
    },
    {
      "start": "00:38:23.400",
      "end": "00:38:26.390",
      "text": "of operations because your special dimensions uh of the feature Maps which"
    },
    {
      "start": "00:38:26.390",
      "end": "00:38:26.400",
      "text": "dimensions uh of the feature Maps which"
    },
    {
      "start": "00:38:26.400",
      "end": "00:38:28.670",
      "text": "dimensions uh of the feature Maps which are produced from a earlier uh"
    },
    {
      "start": "00:38:28.670",
      "end": "00:38:28.680",
      "text": "are produced from a earlier uh"
    },
    {
      "start": "00:38:28.680",
      "end": "00:38:31.910",
      "text": "are produced from a earlier uh operations are shrinking so you increase"
    },
    {
      "start": "00:38:31.910",
      "end": "00:38:31.920",
      "text": "operations are shrinking so you increase"
    },
    {
      "start": "00:38:31.920",
      "end": "00:38:35.270",
      "text": "operations are shrinking so you increase the number of uh filter parameters and"
    },
    {
      "start": "00:38:35.270",
      "end": "00:38:35.280",
      "text": "the number of uh filter parameters and"
    },
    {
      "start": "00:38:35.280",
      "end": "00:38:37.309",
      "text": "the number of uh filter parameters and still you're not really paying"
    },
    {
      "start": "00:38:37.309",
      "end": "00:38:37.319",
      "text": "still you're not really paying"
    },
    {
      "start": "00:38:37.319",
      "end": "00:38:40.390",
      "text": "still you're not really paying any any any complexity this sort of"
    },
    {
      "start": "00:38:40.390",
      "end": "00:38:40.400",
      "text": "any any any complexity this sort of"
    },
    {
      "start": "00:38:40.400",
      "end": "00:38:42.470",
      "text": "any any any complexity this sort of penalty because of that okay so these"
    },
    {
      "start": "00:38:42.470",
      "end": "00:38:42.480",
      "text": "penalty because of that okay so these"
    },
    {
      "start": "00:38:42.480",
      "end": "00:38:45.069",
      "text": "penalty because of that okay so these are the two uh things that we need we"
    },
    {
      "start": "00:38:45.069",
      "end": "00:38:45.079",
      "text": "are the two uh things that we need we"
    },
    {
      "start": "00:38:45.079",
      "end": "00:38:46.630",
      "text": "are the two uh things that we need we can actually mention about this kind of"
    },
    {
      "start": "00:38:46.630",
      "end": "00:38:46.640",
      "text": "can actually mention about this kind of"
    },
    {
      "start": "00:38:46.640",
      "end": "00:38:48.910",
      "text": "can actually mention about this kind of architecture that looks again like a"
    },
    {
      "start": "00:38:48.910",
      "end": "00:38:48.920",
      "text": "architecture that looks again like a"
    },
    {
      "start": "00:38:48.920",
      "end": "00:38:51.710",
      "text": "architecture that looks again like a pyramid but this pyramid is a kind of"
    },
    {
      "start": "00:38:51.710",
      "end": "00:38:51.720",
      "text": "pyramid but this pyramid is a kind of"
    },
    {
      "start": "00:38:51.720",
      "end": "00:38:55.390",
      "text": "pyramid but this pyramid is a kind of works in a different way um as as"
    },
    {
      "start": "00:38:55.390",
      "end": "00:38:55.400",
      "text": "works in a different way um as as"
    },
    {
      "start": "00:38:55.400",
      "end": "00:38:56.710",
      "text": "works in a different way um as as compared to what we have seen in fully"
    },
    {
      "start": "00:38:56.710",
      "end": "00:38:56.720",
      "text": "compared to what we have seen in fully"
    },
    {
      "start": "00:38:56.720",
      "end": "00:38:59.470",
      "text": "compared to what we have seen in fully connected architect pictures and now um"
    },
    {
      "start": "00:38:59.470",
      "end": "00:38:59.480",
      "text": "connected architect pictures and now um"
    },
    {
      "start": "00:38:59.480",
      "end": "00:39:01.270",
      "text": "connected architect pictures and now um I think it's worthwhile spending some"
    },
    {
      "start": "00:39:01.270",
      "end": "00:39:01.280",
      "text": "I think it's worthwhile spending some"
    },
    {
      "start": "00:39:01.280",
      "end": "00:39:05.510",
      "text": "I think it's worthwhile spending some time on U uh on on an example and this"
    },
    {
      "start": "00:39:05.510",
      "end": "00:39:05.520",
      "text": "time on U uh on on an example and this"
    },
    {
      "start": "00:39:05.520",
      "end": "00:39:10.589",
      "text": "time on U uh on on an example and this example is um a a python"
    },
    {
      "start": "00:39:10.589",
      "end": "00:39:10.599",
      "text": "example is um a a python"
    },
    {
      "start": "00:39:10.599",
      "end": "00:39:13.630",
      "text": "example is um a a python notebook this example is actually shown"
    },
    {
      "start": "00:39:13.630",
      "end": "00:39:13.640",
      "text": "notebook this example is actually shown"
    },
    {
      "start": "00:39:13.640",
      "end": "00:39:16.430",
      "text": "notebook this example is actually shown over here you can actually click on this"
    },
    {
      "start": "00:39:16.430",
      "end": "00:39:16.440",
      "text": "over here you can actually click on this"
    },
    {
      "start": "00:39:16.440",
      "end": "00:39:19.870",
      "text": "over here you can actually click on this and uh open it in poab for execution uh"
    },
    {
      "start": "00:39:19.870",
      "end": "00:39:19.880",
      "text": "and uh open it in poab for execution uh"
    },
    {
      "start": "00:39:19.880",
      "end": "00:39:22.230",
      "text": "and uh open it in poab for execution uh however the notebook in your case over"
    },
    {
      "start": "00:39:22.230",
      "end": "00:39:22.240",
      "text": "however the notebook in your case over"
    },
    {
      "start": "00:39:22.240",
      "end": "00:39:24.710",
      "text": "however the notebook in your case over here will actually be working as it is"
    },
    {
      "start": "00:39:24.710",
      "end": "00:39:24.720",
      "text": "here will actually be working as it is"
    },
    {
      "start": "00:39:24.720",
      "end": "00:39:27.190",
      "text": "here will actually be working as it is so in uh the next video we'll go through"
    },
    {
      "start": "00:39:27.190",
      "end": "00:39:27.200",
      "text": "so in uh the next video we'll go through"
    },
    {
      "start": "00:39:27.200",
      "end": "00:39:30.470",
      "text": "so in uh the next video we'll go through this example and then see exactly what's"
    },
    {
      "start": "00:39:30.470",
      "end": "00:39:30.480",
      "text": "this example and then see exactly what's"
    },
    {
      "start": "00:39:30.480",
      "end": "00:39:34.190",
      "text": "this example and then see exactly what's going on uh in terms of uh and the API"
    },
    {
      "start": "00:39:34.190",
      "end": "00:39:34.200",
      "text": "going on uh in terms of uh and the API"
    },
    {
      "start": "00:39:34.200",
      "end": "00:39:38.160",
      "text": "going on uh in terms of uh and the API and the implementation of a CNN"
    }
  ]
}