{
  "video_id": "FCQ-rih6cHY",
  "title": "6 residual networks",
  "captions": [
    {
      "start": "00:00:02.909",
      "end": "00:00:02.919",
      "text": "in an earli video we have seen the uh"
    },
    {
      "start": "00:00:02.919",
      "end": "00:00:06.150",
      "text": "in an earli video we have seen the uh convolutional networks and the basic"
    },
    {
      "start": "00:00:06.150",
      "end": "00:00:06.160",
      "text": "convolutional networks and the basic"
    },
    {
      "start": "00:00:06.160",
      "end": "00:00:09.750",
      "text": "convolutional networks and the basic operation uh in this uh video what we"
    },
    {
      "start": "00:00:09.750",
      "end": "00:00:09.760",
      "text": "operation uh in this uh video what we"
    },
    {
      "start": "00:00:09.760",
      "end": "00:00:13.190",
      "text": "operation uh in this uh video what we actually introducing here uh is residual"
    },
    {
      "start": "00:00:13.190",
      "end": "00:00:13.200",
      "text": "actually introducing here uh is residual"
    },
    {
      "start": "00:00:13.200",
      "end": "00:00:16.550",
      "text": "actually introducing here uh is residual networks which is to to this day um"
    },
    {
      "start": "00:00:16.550",
      "end": "00:00:16.560",
      "text": "networks which is to to this day um"
    },
    {
      "start": "00:00:16.560",
      "end": "00:00:18.510",
      "text": "networks which is to to this day um several years after the introduction"
    },
    {
      "start": "00:00:18.510",
      "end": "00:00:18.520",
      "text": "several years after the introduction"
    },
    {
      "start": "00:00:18.520",
      "end": "00:00:21.189",
      "text": "several years after the introduction remain one of the main uh used"
    },
    {
      "start": "00:00:21.189",
      "end": "00:00:21.199",
      "text": "remain one of the main uh used"
    },
    {
      "start": "00:00:21.199",
      "end": "00:00:24.070",
      "text": "remain one of the main uh used architectures uh for feature extraction"
    },
    {
      "start": "00:00:24.070",
      "end": "00:00:24.080",
      "text": "architectures uh for feature extraction"
    },
    {
      "start": "00:00:24.080",
      "end": "00:00:26.790",
      "text": "architectures uh for feature extraction and not only as a basic component of"
    },
    {
      "start": "00:00:26.790",
      "end": "00:00:26.800",
      "text": "and not only as a basic component of"
    },
    {
      "start": "00:00:26.800",
      "end": "00:00:29.710",
      "text": "and not only as a basic component of many more advanced uh CNN architectures"
    },
    {
      "start": "00:00:29.710",
      "end": "00:00:29.720",
      "text": "many more advanced uh CNN architectures"
    },
    {
      "start": "00:00:29.720",
      "end": "00:00:32.630",
      "text": "many more advanced uh CNN architectures and and uh that are doing more more"
    },
    {
      "start": "00:00:32.630",
      "end": "00:00:32.640",
      "text": "and and uh that are doing more more"
    },
    {
      "start": "00:00:32.640",
      "end": "00:00:35.069",
      "text": "and and uh that are doing more more complicated tasks such as object"
    },
    {
      "start": "00:00:35.069",
      "end": "00:00:35.079",
      "text": "complicated tasks such as object"
    },
    {
      "start": "00:00:35.079",
      "end": "00:00:37.430",
      "text": "complicated tasks such as object detection semantic segmentation and"
    },
    {
      "start": "00:00:37.430",
      "end": "00:00:37.440",
      "text": "detection semantic segmentation and"
    },
    {
      "start": "00:00:37.440",
      "end": "00:00:40.670",
      "text": "detection semantic segmentation and others that we will see in another uh in"
    },
    {
      "start": "00:00:40.670",
      "end": "00:00:40.680",
      "text": "others that we will see in another uh in"
    },
    {
      "start": "00:00:40.680",
      "end": "00:00:46.069",
      "text": "others that we will see in another uh in another video uh so the uh history if"
    },
    {
      "start": "00:00:46.069",
      "end": "00:00:46.079",
      "text": "another video uh so the uh history if"
    },
    {
      "start": "00:00:46.079",
      "end": "00:00:48.510",
      "text": "another video uh so the uh history if you like of their introduction uh you"
    },
    {
      "start": "00:00:48.510",
      "end": "00:00:48.520",
      "text": "you like of their introduction uh you"
    },
    {
      "start": "00:00:48.520",
      "end": "00:00:52.430",
      "text": "you like of their introduction uh you know started uh around 2015 where people"
    },
    {
      "start": "00:00:52.430",
      "end": "00:00:52.440",
      "text": "know started uh around 2015 where people"
    },
    {
      "start": "00:00:52.440",
      "end": "00:00:56.069",
      "text": "know started uh around 2015 where people realized that it's um not really"
    },
    {
      "start": "00:00:56.069",
      "end": "00:00:56.079",
      "text": "realized that it's um not really"
    },
    {
      "start": "00:00:56.079",
      "end": "00:01:00.229",
      "text": "realized that it's um not really possible to extend the so-called uh"
    },
    {
      "start": "00:01:00.229",
      "end": "00:01:00.239",
      "text": "possible to extend the so-called uh"
    },
    {
      "start": "00:01:00.239",
      "end": "00:01:02.790",
      "text": "possible to extend the so-called uh architectures of the time let's say the"
    },
    {
      "start": "00:01:02.790",
      "end": "00:01:02.800",
      "text": "architectures of the time let's say the"
    },
    {
      "start": "00:01:02.800",
      "end": "00:01:05.950",
      "text": "architectures of the time let's say the vgg architecture uh we've seen the V"
    },
    {
      "start": "00:01:05.950",
      "end": "00:01:05.960",
      "text": "vgg architecture uh we've seen the V"
    },
    {
      "start": "00:01:05.960",
      "end": "00:01:08.990",
      "text": "vgg architecture uh we've seen the V architecture on on a different U video"
    },
    {
      "start": "00:01:08.990",
      "end": "00:01:09.000",
      "text": "architecture on on a different U video"
    },
    {
      "start": "00:01:09.000",
      "end": "00:01:11.469",
      "text": "architecture on on a different U video earlier in this uh in this actually"
    },
    {
      "start": "00:01:11.469",
      "end": "00:01:11.479",
      "text": "earlier in this uh in this actually"
    },
    {
      "start": "00:01:11.479",
      "end": "00:01:14.670",
      "text": "earlier in this uh in this actually topic over here uh where we have SE we"
    },
    {
      "start": "00:01:14.670",
      "end": "00:01:14.680",
      "text": "topic over here uh where we have SE we"
    },
    {
      "start": "00:01:14.680",
      "end": "00:01:18.550",
      "text": "topic over here uh where we have SE we have seen the sort of uh architecture of"
    },
    {
      "start": "00:01:18.550",
      "end": "00:01:18.560",
      "text": "have seen the sort of uh architecture of"
    },
    {
      "start": "00:01:18.560",
      "end": "00:01:22.510",
      "text": "have seen the sort of uh architecture of the V16 Network and uh what was actually"
    },
    {
      "start": "00:01:22.510",
      "end": "00:01:22.520",
      "text": "the V16 Network and uh what was actually"
    },
    {
      "start": "00:01:22.520",
      "end": "00:01:24.429",
      "text": "the V16 Network and uh what was actually happening then and now that we"
    },
    {
      "start": "00:01:24.429",
      "end": "00:01:24.439",
      "text": "happening then and now that we"
    },
    {
      "start": "00:01:24.439",
      "end": "00:01:26.870",
      "text": "happening then and now that we understand a couple of things about back"
    },
    {
      "start": "00:01:26.870",
      "end": "00:01:26.880",
      "text": "understand a couple of things about back"
    },
    {
      "start": "00:01:26.880",
      "end": "00:01:30.550",
      "text": "understand a couple of things about back propagation uh the uh gradient"
    },
    {
      "start": "00:01:30.550",
      "end": "00:01:30.560",
      "text": "propagation uh the uh gradient"
    },
    {
      "start": "00:01:30.560",
      "end": "00:01:32.429",
      "text": "propagation uh the uh gradient had a lot of problems to"
    },
    {
      "start": "00:01:32.429",
      "end": "00:01:32.439",
      "text": "had a lot of problems to"
    },
    {
      "start": "00:01:32.439",
      "end": "00:01:35.429",
      "text": "had a lot of problems to flow all the way to the input of the"
    },
    {
      "start": "00:01:35.429",
      "end": "00:01:35.439",
      "text": "flow all the way to the input of the"
    },
    {
      "start": "00:01:35.439",
      "end": "00:01:38.550",
      "text": "flow all the way to the input of the network uh and uh the U sort of"
    },
    {
      "start": "00:01:38.550",
      "end": "00:01:38.560",
      "text": "network uh and uh the U sort of"
    },
    {
      "start": "00:01:38.560",
      "end": "00:01:40.670",
      "text": "network uh and uh the U sort of bottlenecks that were actually generated"
    },
    {
      "start": "00:01:40.670",
      "end": "00:01:40.680",
      "text": "bottlenecks that were actually generated"
    },
    {
      "start": "00:01:40.680",
      "end": "00:01:42.590",
      "text": "bottlenecks that were actually generated created a significant problems in the"
    },
    {
      "start": "00:01:42.590",
      "end": "00:01:42.600",
      "text": "created a significant problems in the"
    },
    {
      "start": "00:01:42.600",
      "end": "00:01:45.510",
      "text": "created a significant problems in the training of these uh architectures so"
    },
    {
      "start": "00:01:45.510",
      "end": "00:01:45.520",
      "text": "training of these uh architectures so"
    },
    {
      "start": "00:01:45.520",
      "end": "00:01:46.550",
      "text": "training of these uh architectures so around"
    },
    {
      "start": "00:01:46.550",
      "end": "00:01:46.560",
      "text": "around"
    },
    {
      "start": "00:01:46.560",
      "end": "00:01:49.630",
      "text": "around 2015 a researcher at"
    },
    {
      "start": "00:01:49.630",
      "end": "00:01:49.640",
      "text": "2015 a researcher at"
    },
    {
      "start": "00:01:49.640",
      "end": "00:01:52.830",
      "text": "2015 a researcher at Microsoft uh you know found a solution"
    },
    {
      "start": "00:01:52.830",
      "end": "00:01:52.840",
      "text": "Microsoft uh you know found a solution"
    },
    {
      "start": "00:01:52.840",
      "end": "00:01:56.149",
      "text": "Microsoft uh you know found a solution on how to enable uh that gradient to"
    },
    {
      "start": "00:01:56.149",
      "end": "00:01:56.159",
      "text": "on how to enable uh that gradient to"
    },
    {
      "start": "00:01:56.159",
      "end": "00:01:57.670",
      "text": "on how to enable uh that gradient to flow uh"
    },
    {
      "start": "00:01:57.670",
      "end": "00:01:57.680",
      "text": "flow uh"
    },
    {
      "start": "00:01:57.680",
      "end": "00:02:00.550",
      "text": "flow uh freely in uh in a much deeper"
    },
    {
      "start": "00:02:00.550",
      "end": "00:02:00.560",
      "text": "freely in uh in a much deeper"
    },
    {
      "start": "00:02:00.560",
      "end": "00:02:02.789",
      "text": "freely in uh in a much deeper architectures such as uh the ones that"
    },
    {
      "start": "00:02:02.789",
      "end": "00:02:02.799",
      "text": "architectures such as uh the ones that"
    },
    {
      "start": "00:02:02.799",
      "end": "00:02:05.670",
      "text": "architectures such as uh the ones that we will see in a moment and uh the uh"
    },
    {
      "start": "00:02:05.670",
      "end": "00:02:05.680",
      "text": "we will see in a moment and uh the uh"
    },
    {
      "start": "00:02:05.680",
      "end": "00:02:08.749",
      "text": "we will see in a moment and uh the uh this gave their uh the name residual"
    },
    {
      "start": "00:02:08.749",
      "end": "00:02:08.759",
      "text": "this gave their uh the name residual"
    },
    {
      "start": "00:02:08.759",
      "end": "00:02:11.270",
      "text": "this gave their uh the name residual because it in that architecture we"
    },
    {
      "start": "00:02:11.270",
      "end": "00:02:11.280",
      "text": "because it in that architecture we"
    },
    {
      "start": "00:02:11.280",
      "end": "00:02:13.550",
      "text": "because it in that architecture we Implement what we call a residual unit"
    },
    {
      "start": "00:02:13.550",
      "end": "00:02:13.560",
      "text": "Implement what we call a residual unit"
    },
    {
      "start": "00:02:13.560",
      "end": "00:02:16.190",
      "text": "Implement what we call a residual unit and from from now on we'll refer to to"
    },
    {
      "start": "00:02:16.190",
      "end": "00:02:16.200",
      "text": "and from from now on we'll refer to to"
    },
    {
      "start": "00:02:16.200",
      "end": "00:02:19.670",
      "text": "and from from now on we'll refer to to those networks as rest nets all right so"
    },
    {
      "start": "00:02:19.670",
      "end": "00:02:19.680",
      "text": "those networks as rest nets all right so"
    },
    {
      "start": "00:02:19.680",
      "end": "00:02:22.070",
      "text": "those networks as rest nets all right so in order for us to understand what is"
    },
    {
      "start": "00:02:22.070",
      "end": "00:02:22.080",
      "text": "in order for us to understand what is"
    },
    {
      "start": "00:02:22.080",
      "end": "00:02:23.630",
      "text": "in order for us to understand what is going on with rest Nets or what I'm"
    },
    {
      "start": "00:02:23.630",
      "end": "00:02:23.640",
      "text": "going on with rest Nets or what I'm"
    },
    {
      "start": "00:02:23.640",
      "end": "00:02:27.630",
      "text": "going on with rest Nets or what I'm going to do now is I'm going to draw uh"
    },
    {
      "start": "00:02:27.630",
      "end": "00:02:27.640",
      "text": "going to do now is I'm going to draw uh"
    },
    {
      "start": "00:02:27.640",
      "end": "00:02:31.190",
      "text": "going to do now is I'm going to draw uh a very small rest architecture just"
    },
    {
      "start": "00:02:31.190",
      "end": "00:02:31.200",
      "text": "a very small rest architecture just"
    },
    {
      "start": "00:02:31.200",
      "end": "00:02:33.150",
      "text": "a very small rest architecture just consisting of three"
    },
    {
      "start": "00:02:33.150",
      "end": "00:02:33.160",
      "text": "consisting of three"
    },
    {
      "start": "00:02:33.160",
      "end": "00:02:37.030",
      "text": "consisting of three units U and if I may draw the"
    },
    {
      "start": "00:02:37.030",
      "end": "00:02:37.040",
      "text": "units U and if I may draw the"
    },
    {
      "start": "00:02:37.040",
      "end": "00:02:41.030",
      "text": "units U and if I may draw the architecture will that's my uh unit"
    },
    {
      "start": "00:02:41.030",
      "end": "00:02:41.040",
      "text": "architecture will that's my uh unit"
    },
    {
      "start": "00:02:41.040",
      "end": "00:02:45.350",
      "text": "architecture will that's my uh unit which I'll abstract with the letter"
    },
    {
      "start": "00:02:45.350",
      "end": "00:02:45.360",
      "text": "which I'll abstract with the letter"
    },
    {
      "start": "00:02:45.360",
      "end": "00:02:49.589",
      "text": "which I'll abstract with the letter F1 so the input to the so I'll use a bit"
    },
    {
      "start": "00:02:49.589",
      "end": "00:02:49.599",
      "text": "F1 so the input to the so I'll use a bit"
    },
    {
      "start": "00:02:49.599",
      "end": "00:02:51.750",
      "text": "F1 so the input to the so I'll use a bit different terminology from what I was"
    },
    {
      "start": "00:02:51.750",
      "end": "00:02:51.760",
      "text": "different terminology from what I was"
    },
    {
      "start": "00:02:51.760",
      "end": "00:02:53.750",
      "text": "different terminology from what I was used kind of earlier so I'll be calling"
    },
    {
      "start": "00:02:53.750",
      "end": "00:02:53.760",
      "text": "used kind of earlier so I'll be calling"
    },
    {
      "start": "00:02:53.760",
      "end": "00:02:57.630",
      "text": "used kind of earlier so I'll be calling set of X I'll be calling it y0 I could"
    },
    {
      "start": "00:02:57.630",
      "end": "00:02:57.640",
      "text": "set of X I'll be calling it y0 I could"
    },
    {
      "start": "00:02:57.640",
      "end": "00:03:00.229",
      "text": "set of X I'll be calling it y0 I could have used it also x0 but in my not over"
    },
    {
      "start": "00:03:00.229",
      "end": "00:03:00.239",
      "text": "have used it also x0 but in my not over"
    },
    {
      "start": "00:03:00.239",
      "end": "00:03:04.750",
      "text": "have used it also x0 but in my not over here I have uh the uh this as y z okay"
    },
    {
      "start": "00:03:04.750",
      "end": "00:03:04.760",
      "text": "here I have uh the uh this as y z okay"
    },
    {
      "start": "00:03:04.760",
      "end": "00:03:10.110",
      "text": "here I have uh the uh this as y z okay so the y z goes into a block that will"
    },
    {
      "start": "00:03:10.110",
      "end": "00:03:10.120",
      "text": "so the y z goes into a block that will"
    },
    {
      "start": "00:03:10.120",
      "end": "00:03:12.470",
      "text": "so the y z goes into a block that will consist of one or more convolutional"
    },
    {
      "start": "00:03:12.470",
      "end": "00:03:12.480",
      "text": "consist of one or more convolutional"
    },
    {
      "start": "00:03:12.480",
      "end": "00:03:13.350",
      "text": "consist of one or more convolutional kind of"
    },
    {
      "start": "00:03:13.350",
      "end": "00:03:13.360",
      "text": "kind of"
    },
    {
      "start": "00:03:13.360",
      "end": "00:03:16.190",
      "text": "kind of layers and in the residual architecture"
    },
    {
      "start": "00:03:16.190",
      "end": "00:03:16.200",
      "text": "layers and in the residual architecture"
    },
    {
      "start": "00:03:16.200",
      "end": "00:03:20.350",
      "text": "layers and in the residual architecture and this is uh why we call it residuals"
    },
    {
      "start": "00:03:20.350",
      "end": "00:03:20.360",
      "text": "and this is uh why we call it residuals"
    },
    {
      "start": "00:03:20.360",
      "end": "00:03:22.710",
      "text": "and this is uh why we call it residuals we take the"
    },
    {
      "start": "00:03:22.710",
      "end": "00:03:22.720",
      "text": "we take the"
    },
    {
      "start": "00:03:22.720",
      "end": "00:03:27.550",
      "text": "we take the input and add it with a"
    },
    {
      "start": "00:03:27.550",
      "end": "00:03:27.560",
      "text": "input and add it with a"
    },
    {
      "start": "00:03:27.560",
      "end": "00:03:31.910",
      "text": "input and add it with a unit uh gain into to the output to the"
    },
    {
      "start": "00:03:31.910",
      "end": "00:03:31.920",
      "text": "unit uh gain into to the output to the"
    },
    {
      "start": "00:03:31.920",
      "end": "00:03:35.670",
      "text": "unit uh gain into to the output to the output okay so to form what we call now"
    },
    {
      "start": "00:03:35.670",
      "end": "00:03:35.680",
      "text": "output okay so to form what we call now"
    },
    {
      "start": "00:03:35.680",
      "end": "00:03:41.589",
      "text": "output okay so to form what we call now a y1 the y1 is uh being added"
    },
    {
      "start": "00:03:41.589",
      "end": "00:03:41.599",
      "text": "a y1 the y1 is uh being added"
    },
    {
      "start": "00:03:41.599",
      "end": "00:03:49.350",
      "text": "a y1 the y1 is uh being added into again with exactly the same"
    },
    {
      "start": "00:03:59.949",
      "end": "00:03:59.959",
      "text": "output Y2"
    },
    {
      "start": "00:03:59.959",
      "end": "00:04:06.270",
      "text": "output Y2 and uh the Y2 is similarly"
    },
    {
      "start": "00:04:15.110",
      "end": "00:04:15.120",
      "text": "final Y3 output okay so this is the kind"
    },
    {
      "start": "00:04:15.120",
      "end": "00:04:17.430",
      "text": "final Y3 output okay so this is the kind of a basic rest net kind of"
    },
    {
      "start": "00:04:17.430",
      "end": "00:04:17.440",
      "text": "of a basic rest net kind of"
    },
    {
      "start": "00:04:17.440",
      "end": "00:04:20.909",
      "text": "of a basic rest net kind of architecture uh in U and if you compare"
    },
    {
      "start": "00:04:20.909",
      "end": "00:04:20.919",
      "text": "architecture uh in U and if you compare"
    },
    {
      "start": "00:04:20.919",
      "end": "00:04:23.909",
      "text": "architecture uh in U and if you compare what we have seen earlier with the cnns"
    },
    {
      "start": "00:04:23.909",
      "end": "00:04:23.919",
      "text": "what we have seen earlier with the cnns"
    },
    {
      "start": "00:04:23.919",
      "end": "00:04:26.310",
      "text": "what we have seen earlier with the cnns we had convolutional layers Max pool"
    },
    {
      "start": "00:04:26.310",
      "end": "00:04:26.320",
      "text": "we had convolutional layers Max pool"
    },
    {
      "start": "00:04:26.320",
      "end": "00:04:28.510",
      "text": "we had convolutional layers Max pool layers and so nonlinear evidently over"
    },
    {
      "start": "00:04:28.510",
      "end": "00:04:28.520",
      "text": "layers and so nonlinear evidently over"
    },
    {
      "start": "00:04:28.520",
      "end": "00:04:30.830",
      "text": "layers and so nonlinear evidently over here but we never had this kind of skip"
    },
    {
      "start": "00:04:30.830",
      "end": "00:04:30.840",
      "text": "here but we never had this kind of skip"
    },
    {
      "start": "00:04:30.840",
      "end": "00:04:35.590",
      "text": "here but we never had this kind of skip over connection uh as we call it okay so"
    },
    {
      "start": "00:04:35.590",
      "end": "00:04:35.600",
      "text": "over connection uh as we call it okay so"
    },
    {
      "start": "00:04:35.600",
      "end": "00:04:38.830",
      "text": "over connection uh as we call it okay so I want to just uh go ahead and write now"
    },
    {
      "start": "00:04:38.830",
      "end": "00:04:38.840",
      "text": "I want to just uh go ahead and write now"
    },
    {
      "start": "00:04:38.840",
      "end": "00:04:41.189",
      "text": "I want to just uh go ahead and write now the"
    },
    {
      "start": "00:04:41.189",
      "end": "00:04:41.199",
      "text": "the"
    },
    {
      "start": "00:04:41.199",
      "end": "00:04:45.110",
      "text": "the um expression of the output of each of"
    },
    {
      "start": "00:04:45.110",
      "end": "00:04:45.120",
      "text": "um expression of the output of each of"
    },
    {
      "start": "00:04:45.120",
      "end": "00:04:46.790",
      "text": "um expression of the output of each of these uh"
    },
    {
      "start": "00:04:46.790",
      "end": "00:04:46.800",
      "text": "these uh"
    },
    {
      "start": "00:04:46.800",
      "end": "00:04:49.070",
      "text": "these uh blocks with respect"
    },
    {
      "start": "00:04:49.070",
      "end": "00:04:49.080",
      "text": "blocks with respect"
    },
    {
      "start": "00:04:49.080",
      "end": "00:04:53.070",
      "text": "blocks with respect to the input so I hope you"
    },
    {
      "start": "00:04:53.070",
      "end": "00:04:53.080",
      "text": "to the input so I hope you"
    },
    {
      "start": "00:04:53.080",
      "end": "00:04:56.270",
      "text": "to the input so I hope you agree uh that this is exactly what each"
    },
    {
      "start": "00:04:56.270",
      "end": "00:04:56.280",
      "text": "agree uh that this is exactly what each"
    },
    {
      "start": "00:04:56.280",
      "end": "00:05:00.710",
      "text": "agree uh that this is exactly what each of these blocks is"
    },
    {
      "start": "00:05:00.710",
      "end": "00:05:00.720",
      "text": "of these blocks is"
    },
    {
      "start": "00:05:00.720",
      "end": "00:05:05.430",
      "text": "of these blocks is Implement okay so we have uh the FI of Y"
    },
    {
      "start": "00:05:05.430",
      "end": "00:05:05.440",
      "text": "Implement okay so we have uh the FI of Y"
    },
    {
      "start": "00:05:05.440",
      "end": "00:05:08.870",
      "text": "Implement okay so we have uh the FI of Y IUS one plus the Y IUS one in each of"
    },
    {
      "start": "00:05:08.870",
      "end": "00:05:08.880",
      "text": "IUS one plus the Y IUS one in each of"
    },
    {
      "start": "00:05:08.880",
      "end": "00:05:11.189",
      "text": "IUS one plus the Y IUS one in each of these so if I may write down these"
    },
    {
      "start": "00:05:11.189",
      "end": "00:05:11.199",
      "text": "these so if I may write down these"
    },
    {
      "start": "00:05:11.199",
      "end": "00:05:14.990",
      "text": "these so if I may write down these equations for uh let's say the"
    },
    {
      "start": "00:05:14.990",
      "end": "00:05:15.000",
      "text": "equations for uh let's say the"
    },
    {
      "start": "00:05:15.000",
      "end": "00:05:20.350",
      "text": "equations for uh let's say the Y3 is equal to F3 of Y2 +"
    },
    {
      "start": "00:05:20.350",
      "end": "00:05:20.360",
      "text": "Y3 is equal to F3 of Y2 +"
    },
    {
      "start": "00:05:20.360",
      "end": "00:05:24.990",
      "text": "Y3 is equal to F3 of Y2 + Y2 um the Y2"
    },
    {
      "start": "00:05:24.990",
      "end": "00:05:25.000",
      "text": "Y2 um the Y2"
    },
    {
      "start": "00:05:25.000",
      "end": "00:05:30.230",
      "text": "Y2 um the Y2 itself is FS2 of y1 + y1"
    },
    {
      "start": "00:05:30.230",
      "end": "00:05:30.240",
      "text": "itself is FS2 of y1 + y1"
    },
    {
      "start": "00:05:30.240",
      "end": "00:05:36.749",
      "text": "itself is FS2 of y1 + y1 and the y1 is fub1 of y0 + y0 these are"
    },
    {
      "start": "00:05:36.749",
      "end": "00:05:36.759",
      "text": "and the y1 is fub1 of y0 + y0 these are"
    },
    {
      "start": "00:05:36.759",
      "end": "00:05:39.590",
      "text": "and the y1 is fub1 of y0 + y0 these are the three equations for each of the"
    },
    {
      "start": "00:05:39.590",
      "end": "00:05:39.600",
      "text": "the three equations for each of the"
    },
    {
      "start": "00:05:39.600",
      "end": "00:05:41.990",
      "text": "the three equations for each of the three blocks that I have here and what I"
    },
    {
      "start": "00:05:41.990",
      "end": "00:05:42.000",
      "text": "three blocks that I have here and what I"
    },
    {
      "start": "00:05:42.000",
      "end": "00:05:44.029",
      "text": "three blocks that I have here and what I want to do now is I want to start"
    },
    {
      "start": "00:05:44.029",
      "end": "00:05:44.039",
      "text": "want to do now is I want to start"
    },
    {
      "start": "00:05:44.039",
      "end": "00:05:49.230",
      "text": "want to do now is I want to start replacing the Y2 uh and y1 uh into the"
    },
    {
      "start": "00:05:49.230",
      "end": "00:05:49.240",
      "text": "replacing the Y2 uh and y1 uh into the"
    },
    {
      "start": "00:05:49.240",
      "end": "00:05:51.990",
      "text": "replacing the Y2 uh and y1 uh into the equation Y3 because I want to write down"
    },
    {
      "start": "00:05:51.990",
      "end": "00:05:52.000",
      "text": "equation Y3 because I want to write down"
    },
    {
      "start": "00:05:52.000",
      "end": "00:05:55.909",
      "text": "equation Y3 because I want to write down the equation the the form of the Y3 as a"
    },
    {
      "start": "00:05:55.909",
      "end": "00:05:55.919",
      "text": "the equation the the form of the Y3 as a"
    },
    {
      "start": "00:05:55.919",
      "end": "00:06:02.749",
      "text": "the equation the the form of the Y3 as a function of only the y0 and the two um"
    },
    {
      "start": "00:06:02.749",
      "end": "00:06:02.759",
      "text": "function of only the y0 and the two um"
    },
    {
      "start": "00:06:02.759",
      "end": "00:06:04.870",
      "text": "function of only the y0 and the two um functions that are involved in the"
    },
    {
      "start": "00:06:04.870",
      "end": "00:06:04.880",
      "text": "functions that are involved in the"
    },
    {
      "start": "00:06:04.880",
      "end": "00:06:08.070",
      "text": "functions that are involved in the blocks F1 and F2 okay so all right so"
    },
    {
      "start": "00:06:08.070",
      "end": "00:06:08.080",
      "text": "blocks F1 and F2 okay so all right so"
    },
    {
      "start": "00:06:08.080",
      "end": "00:06:10.589",
      "text": "blocks F1 and F2 okay so all right so what I'm going to do now is I'm going to"
    },
    {
      "start": "00:06:10.589",
      "end": "00:06:10.599",
      "text": "what I'm going to do now is I'm going to"
    },
    {
      "start": "00:06:10.599",
      "end": "00:06:12.110",
      "text": "what I'm going to do now is I'm going to write it as"
    },
    {
      "start": "00:06:12.110",
      "end": "00:06:12.120",
      "text": "write it as"
    },
    {
      "start": "00:06:12.120",
      "end": "00:06:15.309",
      "text": "write it as F3 of"
    },
    {
      "start": "00:06:15.309",
      "end": "00:06:15.319",
      "text": "F3 of"
    },
    {
      "start": "00:06:15.319",
      "end": "00:06:22.270",
      "text": "F3 of Y2 I'm sorry F3 of"
    },
    {
      "start": "00:06:26.870",
      "end": "00:06:26.880",
      "text": "FS2 of y1 +"
    },
    {
      "start": "00:06:26.880",
      "end": "00:06:31.950",
      "text": "FS2 of y1 + y1 + FS2 of Y y 1 +"
    },
    {
      "start": "00:06:31.950",
      "end": "00:06:31.960",
      "text": "y1 + FS2 of Y y 1 +"
    },
    {
      "start": "00:06:31.960",
      "end": "00:06:35.990",
      "text": "y1 + FS2 of Y y 1 + y1 okay so I just replace it Y2 with it"
    },
    {
      "start": "00:06:35.990",
      "end": "00:06:36.000",
      "text": "y1 okay so I just replace it Y2 with it"
    },
    {
      "start": "00:06:36.000",
      "end": "00:06:46.990",
      "text": "y1 okay so I just replace it Y2 with it equal and now I can uh uh replace"
    },
    {
      "start": "00:06:49.909",
      "end": "00:06:49.919",
      "text": "now let me write it over here because I"
    },
    {
      "start": "00:06:49.919",
      "end": "00:06:54.029",
      "text": "now let me write it over here because I just need a long line to replace"
    },
    {
      "start": "00:06:54.029",
      "end": "00:06:54.039",
      "text": "just need a long line to replace"
    },
    {
      "start": "00:06:54.039",
      "end": "00:06:56.990",
      "text": "just need a long line to replace it to make the final replacement so it"
    },
    {
      "start": "00:06:56.990",
      "end": "00:06:57.000",
      "text": "it to make the final replacement so it"
    },
    {
      "start": "00:06:57.000",
      "end": "00:06:58.510",
      "text": "it to make the final replacement so it is"
    },
    {
      "start": "00:06:58.510",
      "end": "00:06:58.520",
      "text": "is"
    },
    {
      "start": "00:06:58.520",
      "end": "00:07:01.749",
      "text": "is F3 of F2 now I'm going to replace the F"
    },
    {
      "start": "00:07:01.749",
      "end": "00:07:01.759",
      "text": "F3 of F2 now I'm going to replace the F"
    },
    {
      "start": "00:07:01.759",
      "end": "00:07:07.629",
      "text": "F3 of F2 now I'm going to replace the F y1 with its equal to uh obtain the"
    },
    {
      "start": "00:07:07.629",
      "end": "00:07:07.639",
      "text": "y1 with its equal to uh obtain the"
    },
    {
      "start": "00:07:07.639",
      "end": "00:07:18.790",
      "text": "y1 with its equal to uh obtain the final"
    },
    {
      "start": "00:07:21.110",
      "end": "00:07:21.120",
      "text": "expression and this is now the second"
    },
    {
      "start": "00:07:21.120",
      "end": "00:07:26.469",
      "text": "expression and this is now the second square"
    },
    {
      "start": "00:07:29.550",
      "end": "00:07:29.560",
      "text": "bracket okay so it is really this"
    },
    {
      "start": "00:07:29.560",
      "end": "00:07:32.550",
      "text": "bracket okay so it is really this bracket over here"
    },
    {
      "start": "00:07:32.550",
      "end": "00:07:32.560",
      "text": "bracket over here"
    },
    {
      "start": "00:07:32.560",
      "end": "00:07:34.550",
      "text": "bracket over here plus"
    },
    {
      "start": "00:07:34.550",
      "end": "00:07:34.560",
      "text": "plus"
    },
    {
      "start": "00:07:34.560",
      "end": "00:07:36.909",
      "text": "plus plus I have"
    },
    {
      "start": "00:07:36.909",
      "end": "00:07:36.919",
      "text": "plus I have"
    },
    {
      "start": "00:07:36.919",
      "end": "00:07:40.950",
      "text": "plus I have FS2 of FS1 of y0 +"
    },
    {
      "start": "00:07:40.950",
      "end": "00:07:40.960",
      "text": "FS2 of FS1 of y0 +"
    },
    {
      "start": "00:07:40.960",
      "end": "00:07:43.230",
      "text": "FS2 of FS1 of y0 + y0 plus"
    },
    {
      "start": "00:07:43.230",
      "end": "00:07:43.240",
      "text": "y0 plus"
    },
    {
      "start": "00:07:43.240",
      "end": "00:07:46.350",
      "text": "y0 plus fub1 of y0 + y"
    },
    {
      "start": "00:07:46.350",
      "end": "00:07:46.360",
      "text": "fub1 of y0 + y"
    },
    {
      "start": "00:07:46.360",
      "end": "00:07:51.749",
      "text": "fub1 of y0 + y z okay so this is uh my final expression"
    },
    {
      "start": "00:07:51.749",
      "end": "00:07:51.759",
      "text": "z okay so this is uh my final expression"
    },
    {
      "start": "00:07:51.759",
      "end": "00:07:53.430",
      "text": "z okay so this is uh my final expression with respect"
    },
    {
      "start": "00:07:53.430",
      "end": "00:07:53.440",
      "text": "with respect"
    },
    {
      "start": "00:07:53.440",
      "end": "00:07:58.070",
      "text": "with respect to the output of Y3 and why I did that I"
    },
    {
      "start": "00:07:58.070",
      "end": "00:07:58.080",
      "text": "to the output of Y3 and why I did that I"
    },
    {
      "start": "00:07:58.080",
      "end": "00:08:00.589",
      "text": "to the output of Y3 and why I did that I want to take this kind of architecture"
    },
    {
      "start": "00:08:00.589",
      "end": "00:08:00.599",
      "text": "want to take this kind of architecture"
    },
    {
      "start": "00:08:00.599",
      "end": "00:08:04.309",
      "text": "want to take this kind of architecture and write its equivalent that we just"
    },
    {
      "start": "00:08:04.309",
      "end": "00:08:04.319",
      "text": "and write its equivalent that we just"
    },
    {
      "start": "00:08:04.319",
      "end": "00:08:07.629",
      "text": "and write its equivalent that we just based on this equation and that kind of"
    },
    {
      "start": "00:08:07.629",
      "end": "00:08:07.639",
      "text": "based on this equation and that kind of"
    },
    {
      "start": "00:08:07.639",
      "end": "00:08:10.670",
      "text": "based on this equation and that kind of re- plotting or redraw drawing of this"
    },
    {
      "start": "00:08:10.670",
      "end": "00:08:10.680",
      "text": "re- plotting or redraw drawing of this"
    },
    {
      "start": "00:08:10.680",
      "end": "00:08:12.350",
      "text": "re- plotting or redraw drawing of this kind of architecture will help me kind"
    },
    {
      "start": "00:08:12.350",
      "end": "00:08:12.360",
      "text": "kind of architecture will help me kind"
    },
    {
      "start": "00:08:12.360",
      "end": "00:08:14.350",
      "text": "kind of architecture will help me kind of understand a couple of things about"
    },
    {
      "start": "00:08:14.350",
      "end": "00:08:14.360",
      "text": "of understand a couple of things about"
    },
    {
      "start": "00:08:14.360",
      "end": "00:08:18.110",
      "text": "of understand a couple of things about the advantages of rest Nets and why they"
    },
    {
      "start": "00:08:18.110",
      "end": "00:08:18.120",
      "text": "the advantages of rest Nets and why they"
    },
    {
      "start": "00:08:18.120",
      "end": "00:08:20.510",
      "text": "the advantages of rest Nets and why they solve the problem of gradient flow"
    },
    {
      "start": "00:08:20.510",
      "end": "00:08:20.520",
      "text": "solve the problem of gradient flow"
    },
    {
      "start": "00:08:20.520",
      "end": "00:08:21.710",
      "text": "solve the problem of gradient flow throughout the"
    },
    {
      "start": "00:08:21.710",
      "end": "00:08:21.720",
      "text": "throughout the"
    },
    {
      "start": "00:08:21.720",
      "end": "00:08:25.710",
      "text": "throughout the network okay so I am going to start so"
    },
    {
      "start": "00:08:25.710",
      "end": "00:08:25.720",
      "text": "network okay so I am going to start so"
    },
    {
      "start": "00:08:25.720",
      "end": "00:08:29.990",
      "text": "network okay so I am going to start so I'm dividing this into um two parts uh I"
    },
    {
      "start": "00:08:29.990",
      "end": "00:08:30.000",
      "text": "I'm dividing this into um two parts uh I"
    },
    {
      "start": "00:08:30.000",
      "end": "00:08:33.149",
      "text": "I'm dividing this into um two parts uh I am going to um"
    },
    {
      "start": "00:08:33.149",
      "end": "00:08:33.159",
      "text": "am going to um"
    },
    {
      "start": "00:08:33.159",
      "end": "00:08:36.589",
      "text": "am going to um first uh draw"
    },
    {
      "start": "00:08:36.589",
      "end": "00:08:36.599",
      "text": "first uh draw"
    },
    {
      "start": "00:08:36.599",
      "end": "00:08:40.509",
      "text": "first uh draw the long part over here this F3"
    },
    {
      "start": "00:08:40.509",
      "end": "00:08:40.519",
      "text": "the long part over here this F3"
    },
    {
      "start": "00:08:40.519",
      "end": "00:08:43.550",
      "text": "the long part over here this F3 expression here at the at the bottom so"
    },
    {
      "start": "00:08:43.550",
      "end": "00:08:43.560",
      "text": "expression here at the at the bottom so"
    },
    {
      "start": "00:08:43.560",
      "end": "00:08:47.430",
      "text": "expression here at the at the bottom so I am going to take this accepts as input"
    },
    {
      "start": "00:08:47.430",
      "end": "00:08:47.440",
      "text": "I am going to take this accepts as input"
    },
    {
      "start": "00:08:47.440",
      "end": "00:08:50.430",
      "text": "I am going to take this accepts as input y0 that's the only input in this"
    },
    {
      "start": "00:08:50.430",
      "end": "00:08:50.440",
      "text": "y0 that's the only input in this"
    },
    {
      "start": "00:08:50.440",
      "end": "00:08:54.910",
      "text": "y0 that's the only input in this diagram um so y0 is going into the"
    },
    {
      "start": "00:08:54.910",
      "end": "00:08:54.920",
      "text": "diagram um so y0 is going into the"
    },
    {
      "start": "00:08:54.920",
      "end": "00:08:57.750",
      "text": "diagram um so y0 is going into the function"
    },
    {
      "start": "00:09:00.230",
      "end": "00:09:00.240",
      "text": "F1 F1"
    },
    {
      "start": "00:09:00.240",
      "end": "00:09:03.430",
      "text": "F1 F1 we are adding now the function"
    },
    {
      "start": "00:09:03.430",
      "end": "00:09:03.440",
      "text": "we are adding now the function"
    },
    {
      "start": "00:09:03.440",
      "end": "00:09:08.310",
      "text": "we are adding now the function uh the the y z into it okay so that's"
    },
    {
      "start": "00:09:08.310",
      "end": "00:09:08.320",
      "text": "uh the the y z into it okay so that's"
    },
    {
      "start": "00:09:08.320",
      "end": "00:09:11.710",
      "text": "uh the the y z into it okay so that's basically uh this"
    },
    {
      "start": "00:09:11.710",
      "end": "00:09:11.720",
      "text": "basically uh this"
    },
    {
      "start": "00:09:11.720",
      "end": "00:09:14.750",
      "text": "basically uh this term all right so then we take the FS2"
    },
    {
      "start": "00:09:14.750",
      "end": "00:09:14.760",
      "text": "term all right so then we take the FS2"
    },
    {
      "start": "00:09:14.760",
      "end": "00:09:16.870",
      "text": "term all right so then we take the FS2 of this term so the output of this is"
    },
    {
      "start": "00:09:16.870",
      "end": "00:09:16.880",
      "text": "of this term so the output of this is"
    },
    {
      "start": "00:09:16.880",
      "end": "00:09:19.670",
      "text": "of this term so the output of this is being fed to"
    },
    {
      "start": "00:09:19.670",
      "end": "00:09:19.680",
      "text": "being fed to"
    },
    {
      "start": "00:09:19.680",
      "end": "00:09:27.069",
      "text": "being fed to F2 and uh what we do is uh we add for"
    },
    {
      "start": "00:09:27.069",
      "end": "00:09:27.079",
      "text": "F2 and uh what we do is uh we add for"
    },
    {
      "start": "00:09:27.079",
      "end": "00:09:31.030",
      "text": "F2 and uh what we do is uh we add for this FS2 we add this term over here F1 y"
    },
    {
      "start": "00:09:31.030",
      "end": "00:09:31.040",
      "text": "this FS2 we add this term over here F1 y"
    },
    {
      "start": "00:09:31.040",
      "end": "00:09:42.949",
      "text": "this FS2 we add this term over here F1 y 0 + y0 so we add to it"
    },
    {
      "start": "00:09:44.509",
      "end": "00:09:44.519",
      "text": "another"
    },
    {
      "start": "00:09:44.519",
      "end": "00:09:51.350",
      "text": "another block involving the function"
    },
    {
      "start": "00:09:54.829",
      "end": "00:09:54.839",
      "text": "F1 okay so this is basically this inner"
    },
    {
      "start": "00:09:54.839",
      "end": "00:09:57.630",
      "text": "F1 okay so this is basically this inner term over here and then finally we are"
    },
    {
      "start": "00:09:57.630",
      "end": "00:09:57.640",
      "text": "term over here and then finally we are"
    },
    {
      "start": "00:09:57.640",
      "end": "00:10:00.190",
      "text": "term over here and then finally we are taking the F3 of that so this is"
    },
    {
      "start": "00:10:00.190",
      "end": "00:10:00.200",
      "text": "taking the F3 of that so this is"
    },
    {
      "start": "00:10:00.200",
      "end": "00:10:09.110",
      "text": "taking the F3 of that so this is basically my F3 so if I am a um"
    },
    {
      "start": "00:10:13.110",
      "end": "00:10:13.120",
      "text": "Circle if I may Circle this uh this will"
    },
    {
      "start": "00:10:13.120",
      "end": "00:10:14.750",
      "text": "Circle if I may Circle this uh this will be let's say"
    },
    {
      "start": "00:10:14.750",
      "end": "00:10:14.760",
      "text": "be let's say"
    },
    {
      "start": "00:10:14.760",
      "end": "00:10:19.750",
      "text": "be let's say a this a will be available over"
    },
    {
      "start": "00:10:19.750",
      "end": "00:10:19.760",
      "text": "a this a will be available over"
    },
    {
      "start": "00:10:19.760",
      "end": "00:10:22.269",
      "text": "a this a will be available over here okay so we have now finished with"
    },
    {
      "start": "00:10:22.269",
      "end": "00:10:22.279",
      "text": "here okay so we have now finished with"
    },
    {
      "start": "00:10:22.279",
      "end": "00:10:25.350",
      "text": "here okay so we have now finished with the plotting of the first term and now"
    },
    {
      "start": "00:10:25.350",
      "end": "00:10:25.360",
      "text": "the plotting of the first term and now"
    },
    {
      "start": "00:10:25.360",
      "end": "00:10:27.509",
      "text": "the plotting of the first term and now let's look at the second"
    },
    {
      "start": "00:10:27.509",
      "end": "00:10:27.519",
      "text": "let's look at the second"
    },
    {
      "start": "00:10:27.519",
      "end": "00:10:32.069",
      "text": "let's look at the second term so the second term is simply FS2 of"
    },
    {
      "start": "00:10:32.069",
      "end": "00:10:32.079",
      "text": "term so the second term is simply FS2 of"
    },
    {
      "start": "00:10:32.079",
      "end": "00:10:42.310",
      "text": "term so the second term is simply FS2 of y1 y 0 + y0 so I am going to go again"
    },
    {
      "start": "00:10:54.470",
      "end": "00:10:54.480",
      "text": "line so I'm going to just take again"
    },
    {
      "start": "00:10:54.480",
      "end": "00:10:56.269",
      "text": "line so I'm going to just take again fub1 of"
    },
    {
      "start": "00:10:56.269",
      "end": "00:10:56.279",
      "text": "fub1 of"
    },
    {
      "start": "00:10:56.279",
      "end": "00:10:59.710",
      "text": "fub1 of y0 + y0"
    },
    {
      "start": "00:10:59.710",
      "end": "00:10:59.720",
      "text": "y0 + y0"
    },
    {
      "start": "00:10:59.720",
      "end": "00:11:05.389",
      "text": "y0 + y0 and I'm simply going to take the F2 of"
    },
    {
      "start": "00:11:09.790",
      "end": "00:11:09.800",
      "text": "that and uh this thing over here"
    },
    {
      "start": "00:11:09.800",
      "end": "00:11:14.150",
      "text": "that and uh this thing over here is the point"
    },
    {
      "start": "00:11:19.069",
      "end": "00:11:19.079",
      "text": "B however however uh this so this is"
    },
    {
      "start": "00:11:19.079",
      "end": "00:11:25.150",
      "text": "B however however uh this so this is basically B let me uh throw it over"
    },
    {
      "start": "00:11:28.670",
      "end": "00:11:28.680",
      "text": "here to B now what we have is we simply"
    },
    {
      "start": "00:11:28.680",
      "end": "00:11:37.710",
      "text": "here to B now what we have is we simply add another of these"
    },
    {
      "start": "00:11:40.670",
      "end": "00:11:40.680",
      "text": "guys we add to"
    },
    {
      "start": "00:11:40.680",
      "end": "00:11:44.590",
      "text": "guys we add to be this and I would like to Circle that"
    },
    {
      "start": "00:11:44.590",
      "end": "00:11:44.600",
      "text": "be this and I would like to Circle that"
    },
    {
      "start": "00:11:44.600",
      "end": "00:11:48.190",
      "text": "be this and I would like to Circle that over because we see here three things"
    },
    {
      "start": "00:11:48.190",
      "end": "00:11:48.200",
      "text": "over because we see here three things"
    },
    {
      "start": "00:11:48.200",
      "end": "00:11:52.910",
      "text": "over because we see here three things being involved a b and c so this is"
    },
    {
      "start": "00:11:56.069",
      "end": "00:11:56.079",
      "text": "C and then B and"
    },
    {
      "start": "00:11:56.079",
      "end": "00:12:04.269",
      "text": "C and then B and C are added to a"
    },
    {
      "start": "00:12:07.590",
      "end": "00:12:07.600",
      "text": "and this will actually be my"
    },
    {
      "start": "00:12:07.600",
      "end": "00:12:10.069",
      "text": "and this will actually be my Y3 and now that we have this kind of"
    },
    {
      "start": "00:12:10.069",
      "end": "00:12:10.079",
      "text": "Y3 and now that we have this kind of"
    },
    {
      "start": "00:12:10.079",
      "end": "00:12:12.710",
      "text": "Y3 and now that we have this kind of diagram we actually can make some really"
    },
    {
      "start": "00:12:12.710",
      "end": "00:12:12.720",
      "text": "diagram we actually can make some really"
    },
    {
      "start": "00:12:12.720",
      "end": "00:12:17.470",
      "text": "diagram we actually can make some really nice conclusions out of it uh as you can"
    },
    {
      "start": "00:12:17.470",
      "end": "00:12:17.480",
      "text": "nice conclusions out of it uh as you can"
    },
    {
      "start": "00:12:17.480",
      "end": "00:12:21.030",
      "text": "nice conclusions out of it uh as you can see uh the gradient in the backward pass"
    },
    {
      "start": "00:12:21.030",
      "end": "00:12:21.040",
      "text": "see uh the gradient in the backward pass"
    },
    {
      "start": "00:12:21.040",
      "end": "00:12:22.509",
      "text": "see uh the gradient in the backward pass so the point number one I want to"
    },
    {
      "start": "00:12:22.509",
      "end": "00:12:22.519",
      "text": "so the point number one I want to"
    },
    {
      "start": "00:12:22.519",
      "end": "00:12:29.350",
      "text": "so the point number one I want to mention is about the gradient flow"
    },
    {
      "start": "00:12:31.030",
      "end": "00:12:31.040",
      "text": "so you can see the gradient flow in the"
    },
    {
      "start": "00:12:31.040",
      "end": "00:12:33.750",
      "text": "so you can see the gradient flow in the backward pass during back propagation"
    },
    {
      "start": "00:12:33.750",
      "end": "00:12:33.760",
      "text": "backward pass during back propagation"
    },
    {
      "start": "00:12:33.760",
      "end": "00:12:38.870",
      "text": "backward pass during back propagation now has a a diverse set of paths and to"
    },
    {
      "start": "00:12:38.870",
      "end": "00:12:38.880",
      "text": "now has a a diverse set of paths and to"
    },
    {
      "start": "00:12:38.880",
      "end": "00:12:41.629",
      "text": "now has a a diverse set of paths and to actually flow all the way to the input"
    },
    {
      "start": "00:12:41.629",
      "end": "00:12:41.639",
      "text": "actually flow all the way to the input"
    },
    {
      "start": "00:12:41.639",
      "end": "00:12:44.670",
      "text": "actually flow all the way to the input let's say it has this path that simply"
    },
    {
      "start": "00:12:44.670",
      "end": "00:12:44.680",
      "text": "let's say it has this path that simply"
    },
    {
      "start": "00:12:44.680",
      "end": "00:12:47.550",
      "text": "let's say it has this path that simply just follows all the way to the input y"
    },
    {
      "start": "00:12:47.550",
      "end": "00:12:47.560",
      "text": "just follows all the way to the input y"
    },
    {
      "start": "00:12:47.560",
      "end": "00:12:50.470",
      "text": "just follows all the way to the input y z the other path that goes"
    },
    {
      "start": "00:12:50.470",
      "end": "00:12:50.480",
      "text": "z the other path that goes"
    },
    {
      "start": "00:12:50.480",
      "end": "00:12:54.590",
      "text": "z the other path that goes through this F1 to go to the input this"
    },
    {
      "start": "00:12:54.590",
      "end": "00:12:54.600",
      "text": "through this F1 to go to the input this"
    },
    {
      "start": "00:12:54.600",
      "end": "00:12:57.389",
      "text": "through this F1 to go to the input this path through F2 and F the concatenation"
    },
    {
      "start": "00:12:57.389",
      "end": "00:12:57.399",
      "text": "path through F2 and F the concatenation"
    },
    {
      "start": "00:12:57.399",
      "end": "00:13:00.629",
      "text": "path through F2 and F the concatenation F2 and and fub1 or via this skip"
    },
    {
      "start": "00:13:00.629",
      "end": "00:13:00.639",
      "text": "F2 and and fub1 or via this skip"
    },
    {
      "start": "00:13:00.639",
      "end": "00:13:02.829",
      "text": "F2 and and fub1 or via this skip connection to go to F0 and so on and so"
    },
    {
      "start": "00:13:02.829",
      "end": "00:13:02.839",
      "text": "connection to go to F0 and so on and so"
    },
    {
      "start": "00:13:02.839",
      "end": "00:13:08.069",
      "text": "connection to go to F0 and so on and so on so what we see here is we have a a"
    },
    {
      "start": "00:13:08.069",
      "end": "00:13:08.079",
      "text": "on so what we see here is we have a a"
    },
    {
      "start": "00:13:08.079",
      "end": "00:13:13.750",
      "text": "on so what we see here is we have a a diverse uh set of"
    },
    {
      "start": "00:13:20.670",
      "end": "00:13:20.680",
      "text": "through uh"
    },
    {
      "start": "00:13:20.680",
      "end": "00:13:23.949",
      "text": "through uh each"
    },
    {
      "start": "00:13:25.949",
      "end": "00:13:25.959",
      "text": "goes"
    },
    {
      "start": "00:13:25.959",
      "end": "00:13:30.430",
      "text": "goes through um of uh s of of gates I will"
    },
    {
      "start": "00:13:30.430",
      "end": "00:13:30.440",
      "text": "through um of uh s of of gates I will"
    },
    {
      "start": "00:13:30.440",
      "end": "00:13:32.750",
      "text": "through um of uh s of of gates I will call it because this is what we have"
    },
    {
      "start": "00:13:32.750",
      "end": "00:13:32.760",
      "text": "call it because this is what we have"
    },
    {
      "start": "00:13:32.760",
      "end": "00:13:35.230",
      "text": "call it because this is what we have used as a term from back"
    },
    {
      "start": "00:13:35.230",
      "end": "00:13:35.240",
      "text": "used as a term from back"
    },
    {
      "start": "00:13:35.240",
      "end": "00:13:41.310",
      "text": "used as a term from back propagation of"
    },
    {
      "start": "00:13:44.069",
      "end": "00:13:44.079",
      "text": "varing uh"
    },
    {
      "start": "00:13:44.079",
      "end": "00:13:47.110",
      "text": "varing uh depth okay for varing depth so that's"
    },
    {
      "start": "00:13:47.110",
      "end": "00:13:47.120",
      "text": "depth okay for varing depth so that's"
    },
    {
      "start": "00:13:47.120",
      "end": "00:13:49.389",
      "text": "depth okay for varing depth so that's kind of important earlier what we had"
    },
    {
      "start": "00:13:49.389",
      "end": "00:13:49.399",
      "text": "kind of important earlier what we had"
    },
    {
      "start": "00:13:49.399",
      "end": "00:13:51.470",
      "text": "kind of important earlier what we had without those kind of skip connections"
    },
    {
      "start": "00:13:51.470",
      "end": "00:13:51.480",
      "text": "without those kind of skip connections"
    },
    {
      "start": "00:13:51.480",
      "end": "00:13:55.030",
      "text": "without those kind of skip connections we had simply F1 con with two3 in the"
    },
    {
      "start": "00:13:55.030",
      "end": "00:13:55.040",
      "text": "we had simply F1 con with two3 in the"
    },
    {
      "start": "00:13:55.040",
      "end": "00:13:57.829",
      "text": "we had simply F1 con with two3 in the So-Cal let's say V architecture so here"
    },
    {
      "start": "00:13:57.829",
      "end": "00:13:57.839",
      "text": "So-Cal let's say V architecture so here"
    },
    {
      "start": "00:13:57.839",
      "end": "00:14:01.710",
      "text": "So-Cal let's say V architecture so here we had a a back propagation that it was"
    },
    {
      "start": "00:14:01.710",
      "end": "00:14:01.720",
      "text": "we had a a back propagation that it was"
    },
    {
      "start": "00:14:01.720",
      "end": "00:14:04.670",
      "text": "we had a a back propagation that it was involving um just a single trajectory a"
    },
    {
      "start": "00:14:04.670",
      "end": "00:14:04.680",
      "text": "involving um just a single trajectory a"
    },
    {
      "start": "00:14:04.680",
      "end": "00:14:06.269",
      "text": "involving um just a single trajectory a single path through all all of these"
    },
    {
      "start": "00:14:06.269",
      "end": "00:14:06.279",
      "text": "single path through all all of these"
    },
    {
      "start": "00:14:06.279",
      "end": "00:14:08.389",
      "text": "single path through all all of these Gates and at some point the gradient was"
    },
    {
      "start": "00:14:08.389",
      "end": "00:14:08.399",
      "text": "Gates and at some point the gradient was"
    },
    {
      "start": "00:14:08.399",
      "end": "00:14:10.990",
      "text": "Gates and at some point the gradient was actually dying and of course a dying"
    },
    {
      "start": "00:14:10.990",
      "end": "00:14:11.000",
      "text": "actually dying and of course a dying"
    },
    {
      "start": "00:14:11.000",
      "end": "00:14:13.069",
      "text": "actually dying and of course a dying gradient means that specific"
    },
    {
      "start": "00:14:13.069",
      "end": "00:14:13.079",
      "text": "gradient means that specific"
    },
    {
      "start": "00:14:13.079",
      "end": "00:14:16.150",
      "text": "gradient means that specific functionality of my network uh they are"
    },
    {
      "start": "00:14:16.150",
      "end": "00:14:16.160",
      "text": "functionality of my network uh they are"
    },
    {
      "start": "00:14:16.160",
      "end": "00:14:18.150",
      "text": "functionality of my network uh they are being uh updated the parameters are"
    },
    {
      "start": "00:14:18.150",
      "end": "00:14:18.160",
      "text": "being uh updated the parameters are"
    },
    {
      "start": "00:14:18.160",
      "end": "00:14:20.590",
      "text": "being uh updated the parameters are being updated very very slowly or just"
    },
    {
      "start": "00:14:20.590",
      "end": "00:14:20.600",
      "text": "being updated very very slowly or just"
    },
    {
      "start": "00:14:20.600",
      "end": "00:14:23.590",
      "text": "being updated very very slowly or just simply seize to be updated so that's not"
    },
    {
      "start": "00:14:23.590",
      "end": "00:14:23.600",
      "text": "simply seize to be updated so that's not"
    },
    {
      "start": "00:14:23.600",
      "end": "00:14:25.509",
      "text": "simply seize to be updated so that's not uh really I mean this is one of the key"
    },
    {
      "start": "00:14:25.509",
      "end": "00:14:25.519",
      "text": "uh really I mean this is one of the key"
    },
    {
      "start": "00:14:25.519",
      "end": "00:14:27.829",
      "text": "uh really I mean this is one of the key observations that led to some kind of"
    },
    {
      "start": "00:14:27.829",
      "end": "00:14:27.839",
      "text": "observations that led to some kind of"
    },
    {
      "start": "00:14:27.839",
      "end": "00:14:31.350",
      "text": "observations that led to some kind of leveling of of the performance of these"
    },
    {
      "start": "00:14:31.350",
      "end": "00:14:31.360",
      "text": "leveling of of the performance of these"
    },
    {
      "start": "00:14:31.360",
      "end": "00:14:34.110",
      "text": "leveling of of the performance of these earlier kind of architectures uh as the"
    },
    {
      "start": "00:14:34.110",
      "end": "00:14:34.120",
      "text": "earlier kind of architectures uh as the"
    },
    {
      "start": "00:14:34.120",
      "end": "00:14:36.350",
      "text": "earlier kind of architectures uh as the number of layers were being added up in"
    },
    {
      "start": "00:14:36.350",
      "end": "00:14:36.360",
      "text": "number of layers were being added up in"
    },
    {
      "start": "00:14:36.360",
      "end": "00:14:39.269",
      "text": "number of layers were being added up in this kind of architecture we are"
    },
    {
      "start": "00:14:39.269",
      "end": "00:14:39.279",
      "text": "this kind of architecture we are"
    },
    {
      "start": "00:14:39.279",
      "end": "00:14:40.990",
      "text": "this kind of architecture we are effectively Implement what is actually"
    },
    {
      "start": "00:14:40.990",
      "end": "00:14:41.000",
      "text": "effectively Implement what is actually"
    },
    {
      "start": "00:14:41.000",
      "end": "00:14:44.030",
      "text": "effectively Implement what is actually known as Highway networks and those"
    },
    {
      "start": "00:14:44.030",
      "end": "00:14:44.040",
      "text": "known as Highway networks and those"
    },
    {
      "start": "00:14:44.040",
      "end": "00:14:46.749",
      "text": "known as Highway networks and those Highway highways that we creating for"
    },
    {
      "start": "00:14:46.749",
      "end": "00:14:46.759",
      "text": "Highway highways that we creating for"
    },
    {
      "start": "00:14:46.759",
      "end": "00:14:50.110",
      "text": "Highway highways that we creating for the gradient uh empirically has shown"
    },
    {
      "start": "00:14:50.110",
      "end": "00:14:50.120",
      "text": "the gradient uh empirically has shown"
    },
    {
      "start": "00:14:50.120",
      "end": "00:14:51.829",
      "text": "the gradient uh empirically has shown that we are actually can go much much"
    },
    {
      "start": "00:14:51.829",
      "end": "00:14:51.839",
      "text": "that we are actually can go much much"
    },
    {
      "start": "00:14:51.839",
      "end": "00:14:55.230",
      "text": "that we are actually can go much much deeper so we'll see now some depths uh"
    },
    {
      "start": "00:14:55.230",
      "end": "00:14:55.240",
      "text": "deeper so we'll see now some depths uh"
    },
    {
      "start": "00:14:55.240",
      "end": "00:14:57.430",
      "text": "deeper so we'll see now some depths uh uh typical depths that we experience in"
    },
    {
      "start": "00:14:57.430",
      "end": "00:14:57.440",
      "text": "uh typical depths that we experience in"
    },
    {
      "start": "00:14:57.440",
      "end": "00:14:59.629",
      "text": "uh typical depths that we experience in uh we we have in a resent architect in a"
    },
    {
      "start": "00:14:59.629",
      "end": "00:14:59.639",
      "text": "uh we we have in a resent architect in a"
    },
    {
      "start": "00:14:59.639",
      "end": "00:15:01.509",
      "text": "uh we we have in a resent architect in a moment the"
    },
    {
      "start": "00:15:01.509",
      "end": "00:15:01.519",
      "text": "moment the"
    },
    {
      "start": "00:15:01.519",
      "end": "00:15:04.870",
      "text": "moment the second uh aspect of that is a bit more"
    },
    {
      "start": "00:15:04.870",
      "end": "00:15:04.880",
      "text": "second uh aspect of that is a bit more"
    },
    {
      "start": "00:15:04.880",
      "end": "00:15:06.990",
      "text": "second uh aspect of that is a bit more nuanced and it has to do with what we"
    },
    {
      "start": "00:15:06.990",
      "end": "00:15:07.000",
      "text": "nuanced and it has to do with what we"
    },
    {
      "start": "00:15:07.000",
      "end": "00:15:14.509",
      "text": "nuanced and it has to do with what we call an ensample"
    },
    {
      "start": "00:15:16.749",
      "end": "00:15:16.759",
      "text": "learning so in this kind of Ensemble"
    },
    {
      "start": "00:15:16.759",
      "end": "00:15:19.590",
      "text": "learning so in this kind of Ensemble learning architecture what we see is we"
    },
    {
      "start": "00:15:19.590",
      "end": "00:15:19.600",
      "text": "learning architecture what we see is we"
    },
    {
      "start": "00:15:19.600",
      "end": "00:15:23.310",
      "text": "learning architecture what we see is we see U uh the concatenation the the"
    },
    {
      "start": "00:15:23.310",
      "end": "00:15:23.320",
      "text": "see U uh the concatenation the the"
    },
    {
      "start": "00:15:23.320",
      "end": "00:15:26.189",
      "text": "see U uh the concatenation the the combination of three predictors here"
    },
    {
      "start": "00:15:26.189",
      "end": "00:15:26.199",
      "text": "combination of three predictors here"
    },
    {
      "start": "00:15:26.199",
      "end": "00:15:28.189",
      "text": "combination of three predictors here three main prediction architectures each"
    },
    {
      "start": "00:15:28.189",
      "end": "00:15:28.199",
      "text": "three main prediction architectures each"
    },
    {
      "start": "00:15:28.199",
      "end": "00:15:31.069",
      "text": "three main prediction architectures each of those predictors has a"
    },
    {
      "start": "00:15:31.069",
      "end": "00:15:31.079",
      "text": "of those predictors has a"
    },
    {
      "start": "00:15:31.079",
      "end": "00:15:34.430",
      "text": "of those predictors has a varying uh kind of functionality so we"
    },
    {
      "start": "00:15:34.430",
      "end": "00:15:34.440",
      "text": "varying uh kind of functionality so we"
    },
    {
      "start": "00:15:34.440",
      "end": "00:15:38.269",
      "text": "varying uh kind of functionality so we see a fairly involved predictor which we"
    },
    {
      "start": "00:15:38.269",
      "end": "00:15:38.279",
      "text": "see a fairly involved predictor which we"
    },
    {
      "start": "00:15:38.279",
      "end": "00:15:40.749",
      "text": "see a fairly involved predictor which we call a we see another predictor which"
    },
    {
      "start": "00:15:40.749",
      "end": "00:15:40.759",
      "text": "call a we see another predictor which"
    },
    {
      "start": "00:15:40.759",
      "end": "00:15:43.030",
      "text": "call a we see another predictor which call B and another predictor that we"
    },
    {
      "start": "00:15:43.030",
      "end": "00:15:43.040",
      "text": "call B and another predictor that we"
    },
    {
      "start": "00:15:43.040",
      "end": "00:15:46.550",
      "text": "call B and another predictor that we call C and what we see at the output are"
    },
    {
      "start": "00:15:46.550",
      "end": "00:15:46.560",
      "text": "call C and what we see at the output are"
    },
    {
      "start": "00:15:46.560",
      "end": "00:15:50.309",
      "text": "call C and what we see at the output are the kind of combination of of those"
    },
    {
      "start": "00:15:50.309",
      "end": "00:15:50.319",
      "text": "the kind of combination of of those"
    },
    {
      "start": "00:15:50.319",
      "end": "00:15:53.550",
      "text": "the kind of combination of of those simply um I mean if you are familiar"
    },
    {
      "start": "00:15:53.550",
      "end": "00:15:53.560",
      "text": "simply um I mean if you are familiar"
    },
    {
      "start": "00:15:53.560",
      "end": "00:15:55.949",
      "text": "simply um I mean if you are familiar with ample kind of methods which I'll"
    },
    {
      "start": "00:15:55.949",
      "end": "00:15:55.959",
      "text": "with ample kind of methods which I'll"
    },
    {
      "start": "00:15:55.959",
      "end": "00:15:57.309",
      "text": "with ample kind of methods which I'll provide some kind of background in a"
    },
    {
      "start": "00:15:57.309",
      "end": "00:15:57.319",
      "text": "provide some kind of background in a"
    },
    {
      "start": "00:15:57.319",
      "end": "00:16:00.509",
      "text": "provide some kind of background in a moment we are adding the individual"
    },
    {
      "start": "00:16:00.509",
      "end": "00:16:00.519",
      "text": "moment we are adding the individual"
    },
    {
      "start": "00:16:00.519",
      "end": "00:16:02.230",
      "text": "moment we are adding the individual prediction uh"
    },
    {
      "start": "00:16:02.230",
      "end": "00:16:02.240",
      "text": "prediction uh"
    },
    {
      "start": "00:16:02.240",
      "end": "00:16:06.790",
      "text": "prediction uh results given the input y z uh at the to"
    },
    {
      "start": "00:16:06.790",
      "end": "00:16:06.800",
      "text": "results given the input y z uh at the to"
    },
    {
      "start": "00:16:06.800",
      "end": "00:16:09.230",
      "text": "results given the input y z uh at the to to obtain our final prediction output"
    },
    {
      "start": "00:16:09.230",
      "end": "00:16:09.240",
      "text": "to obtain our final prediction output"
    },
    {
      "start": "00:16:09.240",
      "end": "00:16:12.749",
      "text": "to obtain our final prediction output the the so-called Y3 hat okay and and so"
    },
    {
      "start": "00:16:12.749",
      "end": "00:16:12.759",
      "text": "the the so-called Y3 hat okay and and so"
    },
    {
      "start": "00:16:12.759",
      "end": "00:16:13.870",
      "text": "the the so-called Y3 hat okay and and so that's"
    },
    {
      "start": "00:16:13.870",
      "end": "00:16:13.880",
      "text": "that's"
    },
    {
      "start": "00:16:13.880",
      "end": "00:16:19.590",
      "text": "that's um uh um ample methods have uh proven in"
    },
    {
      "start": "00:16:19.590",
      "end": "00:16:19.600",
      "text": "um uh um ample methods have uh proven in"
    },
    {
      "start": "00:16:19.600",
      "end": "00:16:22.269",
      "text": "um uh um ample methods have uh proven in the field to be a very powerful uh"
    },
    {
      "start": "00:16:22.269",
      "end": "00:16:22.279",
      "text": "the field to be a very powerful uh"
    },
    {
      "start": "00:16:22.279",
      "end": "00:16:25.309",
      "text": "the field to be a very powerful uh approach uh in solving um you know"
    },
    {
      "start": "00:16:25.309",
      "end": "00:16:25.319",
      "text": "approach uh in solving um you know"
    },
    {
      "start": "00:16:25.319",
      "end": "00:16:28.710",
      "text": "approach uh in solving um you know complex kind of tasks and uh in fact"
    },
    {
      "start": "00:16:28.710",
      "end": "00:16:28.720",
      "text": "complex kind of tasks and uh in fact"
    },
    {
      "start": "00:16:28.720",
      "end": "00:16:30.749",
      "text": "complex kind of tasks and uh in fact some methods are being used both for"
    },
    {
      "start": "00:16:30.749",
      "end": "00:16:30.759",
      "text": "some methods are being used both for"
    },
    {
      "start": "00:16:30.759",
      "end": "00:16:33.470",
      "text": "some methods are being used both for structure and unstructured data and in"
    },
    {
      "start": "00:16:33.470",
      "end": "00:16:33.480",
      "text": "structure and unstructured data and in"
    },
    {
      "start": "00:16:33.480",
      "end": "00:16:35.749",
      "text": "structure and unstructured data and in the structure kind of data field you"
    },
    {
      "start": "00:16:35.749",
      "end": "00:16:35.759",
      "text": "the structure kind of data field you"
    },
    {
      "start": "00:16:35.759",
      "end": "00:16:38.150",
      "text": "the structure kind of data field you have methods such as gradient boosting"
    },
    {
      "start": "00:16:38.150",
      "end": "00:16:38.160",
      "text": "have methods such as gradient boosting"
    },
    {
      "start": "00:16:38.160",
      "end": "00:16:40.309",
      "text": "have methods such as gradient boosting and so on providing some real"
    },
    {
      "start": "00:16:40.309",
      "end": "00:16:40.319",
      "text": "and so on providing some real"
    },
    {
      "start": "00:16:40.319",
      "end": "00:16:43.710",
      "text": "and so on providing some real state-of-the-art results today so a few"
    },
    {
      "start": "00:16:43.710",
      "end": "00:16:43.720",
      "text": "state-of-the-art results today so a few"
    },
    {
      "start": "00:16:43.720",
      "end": "00:16:46.710",
      "text": "state-of-the-art results today so a few words about ample methods is arguably a"
    },
    {
      "start": "00:16:46.710",
      "end": "00:16:46.720",
      "text": "words about ample methods is arguably a"
    },
    {
      "start": "00:16:46.720",
      "end": "00:16:48.710",
      "text": "words about ample methods is arguably a parenthesis uh but I think it's a kind"
    },
    {
      "start": "00:16:48.710",
      "end": "00:16:48.720",
      "text": "parenthesis uh but I think it's a kind"
    },
    {
      "start": "00:16:48.720",
      "end": "00:16:49.910",
      "text": "parenthesis uh but I think it's a kind of"
    },
    {
      "start": "00:16:49.910",
      "end": "00:16:49.920",
      "text": "of"
    },
    {
      "start": "00:16:49.920",
      "end": "00:16:52.389",
      "text": "of worthwhile uh sort of discussing a"
    },
    {
      "start": "00:16:52.389",
      "end": "00:16:52.399",
      "text": "worthwhile uh sort of discussing a"
    },
    {
      "start": "00:16:52.399",
      "end": "00:17:00.350",
      "text": "worthwhile uh sort of discussing a little bit about ensample methods"
    },
    {
      "start": "00:17:02.710",
      "end": "00:17:02.720",
      "text": "so there are various asample methods but"
    },
    {
      "start": "00:17:02.720",
      "end": "00:17:05.549",
      "text": "so there are various asample methods but I think a common denominator for many of"
    },
    {
      "start": "00:17:05.549",
      "end": "00:17:05.559",
      "text": "I think a common denominator for many of"
    },
    {
      "start": "00:17:05.559",
      "end": "00:17:10.110",
      "text": "I think a common denominator for many of them is that the um prediction why hat"
    },
    {
      "start": "00:17:10.110",
      "end": "00:17:10.120",
      "text": "them is that the um prediction why hat"
    },
    {
      "start": "00:17:10.120",
      "end": "00:17:12.870",
      "text": "them is that the um prediction why hat that we get from the so-called ensample"
    },
    {
      "start": "00:17:12.870",
      "end": "00:17:12.880",
      "text": "that we get from the so-called ensample"
    },
    {
      "start": "00:17:12.880",
      "end": "00:17:21.230",
      "text": "that we get from the so-called ensample also known as committee"
    },
    {
      "start": "00:17:24.110",
      "end": "00:17:24.120",
      "text": "methods where we for form a committee a"
    },
    {
      "start": "00:17:24.120",
      "end": "00:17:27.110",
      "text": "methods where we for form a committee a group of experts or weak Learners as we"
    },
    {
      "start": "00:17:27.110",
      "end": "00:17:27.120",
      "text": "group of experts or weak Learners as we"
    },
    {
      "start": "00:17:27.120",
      "end": "00:17:30.590",
      "text": "group of experts or weak Learners as we call them um is uh let me call it why"
    },
    {
      "start": "00:17:30.590",
      "end": "00:17:30.600",
      "text": "call them um is uh let me call it why"
    },
    {
      "start": "00:17:30.600",
      "end": "00:17:35.070",
      "text": "call them um is uh let me call it why hat committee is simply uh the average"
    },
    {
      "start": "00:17:35.070",
      "end": "00:17:35.080",
      "text": "hat committee is simply uh the average"
    },
    {
      "start": "00:17:35.080",
      "end": "00:17:38.070",
      "text": "hat committee is simply uh the average let me call it 1 / capital K of the"
    },
    {
      "start": "00:17:38.070",
      "end": "00:17:38.080",
      "text": "let me call it 1 / capital K of the"
    },
    {
      "start": "00:17:38.080",
      "end": "00:17:40.669",
      "text": "let me call it 1 / capital K of the summation from small letter K is equal"
    },
    {
      "start": "00:17:40.669",
      "end": "00:17:40.679",
      "text": "summation from small letter K is equal"
    },
    {
      "start": "00:17:40.679",
      "end": "00:17:43.990",
      "text": "summation from small letter K is equal to 1 to capital K where capital K is the"
    },
    {
      "start": "00:17:43.990",
      "end": "00:17:44.000",
      "text": "to 1 to capital K where capital K is the"
    },
    {
      "start": "00:17:44.000",
      "end": "00:17:46.789",
      "text": "to 1 to capital K where capital K is the number of predictors that we have here"
    },
    {
      "start": "00:17:46.789",
      "end": "00:17:46.799",
      "text": "number of predictors that we have here"
    },
    {
      "start": "00:17:46.799",
      "end": "00:17:48.510",
      "text": "number of predictors that we have here we had three in the rest net"
    },
    {
      "start": "00:17:48.510",
      "end": "00:17:48.520",
      "text": "we had three in the rest net"
    },
    {
      "start": "00:17:48.520",
      "end": "00:17:51.789",
      "text": "we had three in the rest net architecture of Y hat subk so the"
    },
    {
      "start": "00:17:51.789",
      "end": "00:17:51.799",
      "text": "architecture of Y hat subk so the"
    },
    {
      "start": "00:17:51.799",
      "end": "00:17:54.190",
      "text": "architecture of Y hat subk so the premise of emble method is that we don't"
    },
    {
      "start": "00:17:54.190",
      "end": "00:17:54.200",
      "text": "premise of emble method is that we don't"
    },
    {
      "start": "00:17:54.200",
      "end": "00:17:56.390",
      "text": "premise of emble method is that we don't necessarily to have the single server"
    },
    {
      "start": "00:17:56.390",
      "end": "00:17:56.400",
      "text": "necessarily to have the single server"
    },
    {
      "start": "00:17:56.400",
      "end": "00:17:58.950",
      "text": "necessarily to have the single server bullet uh that will solve the very"
    },
    {
      "start": "00:17:58.950",
      "end": "00:17:58.960",
      "text": "bullet uh that will solve the very"
    },
    {
      "start": "00:17:58.960",
      "end": "00:18:01.789",
      "text": "bullet uh that will solve the very complicated kind of task of us uh that"
    },
    {
      "start": "00:18:01.789",
      "end": "00:18:01.799",
      "text": "complicated kind of task of us uh that"
    },
    {
      "start": "00:18:01.799",
      "end": "00:18:05.110",
      "text": "complicated kind of task of us uh that we have in front of us but uh a number"
    },
    {
      "start": "00:18:05.110",
      "end": "00:18:05.120",
      "text": "we have in front of us but uh a number"
    },
    {
      "start": "00:18:05.120",
      "end": "00:18:12.430",
      "text": "we have in front of us but uh a number of what we call the so-called weak"
    },
    {
      "start": "00:18:16.310",
      "end": "00:18:16.320",
      "text": "predictors uh that it will U not perform"
    },
    {
      "start": "00:18:16.320",
      "end": "00:18:19.149",
      "text": "predictors uh that it will U not perform individually very well but on aggregate"
    },
    {
      "start": "00:18:19.149",
      "end": "00:18:19.159",
      "text": "individually very well but on aggregate"
    },
    {
      "start": "00:18:19.159",
      "end": "00:18:21.270",
      "text": "individually very well but on aggregate they will actually perform much"
    },
    {
      "start": "00:18:21.270",
      "end": "00:18:21.280",
      "text": "they will actually perform much"
    },
    {
      "start": "00:18:21.280",
      "end": "00:18:23.430",
      "text": "they will actually perform much better that and that is really the"
    },
    {
      "start": "00:18:23.430",
      "end": "00:18:23.440",
      "text": "better that and that is really the"
    },
    {
      "start": "00:18:23.440",
      "end": "00:18:26.950",
      "text": "better that and that is really the premise of that and you know one uh"
    },
    {
      "start": "00:18:26.950",
      "end": "00:18:26.960",
      "text": "premise of that and you know one uh"
    },
    {
      "start": "00:18:26.960",
      "end": "00:18:29.549",
      "text": "premise of that and you know one uh parallel uh architecture with have in"
    },
    {
      "start": "00:18:29.549",
      "end": "00:18:29.559",
      "text": "parallel uh architecture with have in"
    },
    {
      "start": "00:18:29.559",
      "end": "00:18:32.190",
      "text": "parallel uh architecture with have in the earlier method uh that we call the"
    },
    {
      "start": "00:18:32.190",
      "end": "00:18:32.200",
      "text": "the earlier method uh that we call the"
    },
    {
      "start": "00:18:32.200",
      "end": "00:18:34.430",
      "text": "the earlier method uh that we call the rest net is kind of resembles that kind"
    },
    {
      "start": "00:18:34.430",
      "end": "00:18:34.440",
      "text": "rest net is kind of resembles that kind"
    },
    {
      "start": "00:18:34.440",
      "end": "00:18:36.510",
      "text": "rest net is kind of resembles that kind of architecture because we have some"
    },
    {
      "start": "00:18:36.510",
      "end": "00:18:36.520",
      "text": "of architecture because we have some"
    },
    {
      "start": "00:18:36.520",
      "end": "00:18:38.990",
      "text": "of architecture because we have some kind of a summation combination of these"
    },
    {
      "start": "00:18:38.990",
      "end": "00:18:39.000",
      "text": "kind of a summation combination of these"
    },
    {
      "start": "00:18:39.000",
      "end": "00:18:41.510",
      "text": "kind of a summation combination of these weak predictions the so-called abs and"
    },
    {
      "start": "00:18:41.510",
      "end": "00:18:41.520",
      "text": "weak predictions the so-called abs and"
    },
    {
      "start": "00:18:41.520",
      "end": "00:18:44.909",
      "text": "weak predictions the so-called abs and C's that I have explained earlier uh so"
    },
    {
      "start": "00:18:44.909",
      "end": "00:18:44.919",
      "text": "C's that I have explained earlier uh so"
    },
    {
      "start": "00:18:44.919",
      "end": "00:18:48.110",
      "text": "C's that I have explained earlier uh so the um uh in Sample methods in general"
    },
    {
      "start": "00:18:48.110",
      "end": "00:18:48.120",
      "text": "the um uh in Sample methods in general"
    },
    {
      "start": "00:18:48.120",
      "end": "00:18:50.669",
      "text": "the um uh in Sample methods in general we have we can consider performance wise"
    },
    {
      "start": "00:18:50.669",
      "end": "00:18:50.679",
      "text": "we have we can consider performance wise"
    },
    {
      "start": "00:18:50.679",
      "end": "00:18:53.390",
      "text": "we have we can consider performance wise to consist of uh in somewhere in between"
    },
    {
      "start": "00:18:53.390",
      "end": "00:18:53.400",
      "text": "to consist of uh in somewhere in between"
    },
    {
      "start": "00:18:53.400",
      "end": "00:18:57.230",
      "text": "to consist of uh in somewhere in between two bounds so the lower bound the So-Cal"
    },
    {
      "start": "00:18:57.230",
      "end": "00:18:57.240",
      "text": "two bounds so the lower bound the So-Cal"
    },
    {
      "start": "00:18:57.240",
      "end": "00:19:00.270",
      "text": "two bounds so the lower bound the So-Cal lower performance"
    },
    {
      "start": "00:19:00.270",
      "end": "00:19:00.280",
      "text": "lower performance"
    },
    {
      "start": "00:19:00.280",
      "end": "00:19:04.110",
      "text": "lower performance bound is obtained uh evidently when"
    },
    {
      "start": "00:19:04.110",
      "end": "00:19:04.120",
      "text": "bound is obtained uh evidently when"
    },
    {
      "start": "00:19:04.120",
      "end": "00:19:07.149",
      "text": "bound is obtained uh evidently when you're you have very correlated"
    },
    {
      "start": "00:19:07.149",
      "end": "00:19:07.159",
      "text": "you're you have very correlated"
    },
    {
      "start": "00:19:07.159",
      "end": "00:19:10.710",
      "text": "you're you have very correlated predictions and if you are not able to"
    },
    {
      "start": "00:19:10.710",
      "end": "00:19:10.720",
      "text": "predictions and if you are not able to"
    },
    {
      "start": "00:19:10.720",
      "end": "00:19:12.750",
      "text": "predictions and if you are not able to randomize the operation of each of these"
    },
    {
      "start": "00:19:12.750",
      "end": "00:19:12.760",
      "text": "randomize the operation of each of these"
    },
    {
      "start": "00:19:12.760",
      "end": "00:19:16.549",
      "text": "randomize the operation of each of these predictors somehow uh we are going to"
    },
    {
      "start": "00:19:16.549",
      "end": "00:19:16.559",
      "text": "predictors somehow uh we are going to"
    },
    {
      "start": "00:19:16.559",
      "end": "00:19:18.909",
      "text": "predictors somehow uh we are going to exhibit this kind of lower bound where"
    },
    {
      "start": "00:19:18.909",
      "end": "00:19:18.919",
      "text": "exhibit this kind of lower bound where"
    },
    {
      "start": "00:19:18.919",
      "end": "00:19:21.270",
      "text": "exhibit this kind of lower bound where either you form a committee or not you"
    },
    {
      "start": "00:19:21.270",
      "end": "00:19:21.280",
      "text": "either you form a committee or not you"
    },
    {
      "start": "00:19:21.280",
      "end": "00:19:23.590",
      "text": "either you form a committee or not you get exactly the same performance it's"
    },
    {
      "start": "00:19:23.590",
      "end": "00:19:23.600",
      "text": "get exactly the same performance it's"
    },
    {
      "start": "00:19:23.600",
      "end": "00:19:26.430",
      "text": "get exactly the same performance it's just like the analogy or the equivalent"
    },
    {
      "start": "00:19:26.430",
      "end": "00:19:26.440",
      "text": "just like the analogy or the equivalent"
    },
    {
      "start": "00:19:26.440",
      "end": "00:19:28.710",
      "text": "just like the analogy or the equivalent analogy I would like to uh sort of share"
    },
    {
      "start": "00:19:28.710",
      "end": "00:19:28.720",
      "text": "analogy I would like to uh sort of share"
    },
    {
      "start": "00:19:28.720",
      "end": "00:19:31.070",
      "text": "analogy I would like to uh sort of share sh is uh you have a committee of let's"
    },
    {
      "start": "00:19:31.070",
      "end": "00:19:31.080",
      "text": "sh is uh you have a committee of let's"
    },
    {
      "start": "00:19:31.080",
      "end": "00:19:33.990",
      "text": "sh is uh you have a committee of let's say a human uh Committee of human"
    },
    {
      "start": "00:19:33.990",
      "end": "00:19:34.000",
      "text": "say a human uh Committee of human"
    },
    {
      "start": "00:19:34.000",
      "end": "00:19:36.510",
      "text": "say a human uh Committee of human experts but each expert went to exactly"
    },
    {
      "start": "00:19:36.510",
      "end": "00:19:36.520",
      "text": "experts but each expert went to exactly"
    },
    {
      "start": "00:19:36.520",
      "end": "00:19:38.990",
      "text": "experts but each expert went to exactly the same school studied exactly the same"
    },
    {
      "start": "00:19:38.990",
      "end": "00:19:39.000",
      "text": "the same school studied exactly the same"
    },
    {
      "start": "00:19:39.000",
      "end": "00:19:42.270",
      "text": "the same school studied exactly the same field had exactly the same uh University"
    },
    {
      "start": "00:19:42.270",
      "end": "00:19:42.280",
      "text": "field had exactly the same uh University"
    },
    {
      "start": "00:19:42.280",
      "end": "00:19:44.310",
      "text": "field had exactly the same uh University professors and they are actually now"
    },
    {
      "start": "00:19:44.310",
      "end": "00:19:44.320",
      "text": "professors and they are actually now"
    },
    {
      "start": "00:19:44.320",
      "end": "00:19:47.230",
      "text": "professors and they are actually now called to solve the problem and guess"
    },
    {
      "start": "00:19:47.230",
      "end": "00:19:47.240",
      "text": "called to solve the problem and guess"
    },
    {
      "start": "00:19:47.240",
      "end": "00:19:48.630",
      "text": "called to solve the problem and guess what each one of them is actually"
    },
    {
      "start": "00:19:48.630",
      "end": "00:19:48.640",
      "text": "what each one of them is actually"
    },
    {
      "start": "00:19:48.640",
      "end": "00:19:50.950",
      "text": "what each one of them is actually offering exactly the same view well"
    },
    {
      "start": "00:19:50.950",
      "end": "00:19:50.960",
      "text": "offering exactly the same view well"
    },
    {
      "start": "00:19:50.960",
      "end": "00:19:52.470",
      "text": "offering exactly the same view well that's basically where the point where"
    },
    {
      "start": "00:19:52.470",
      "end": "00:19:52.480",
      "text": "that's basically where the point where"
    },
    {
      "start": "00:19:52.480",
      "end": "00:19:54.310",
      "text": "that's basically where the point where you experiencing a lower performance"
    },
    {
      "start": "00:19:54.310",
      "end": "00:19:54.320",
      "text": "you experiencing a lower performance"
    },
    {
      "start": "00:19:54.320",
      "end": "00:19:56.830",
      "text": "you experiencing a lower performance bound and the upper performance bound is"
    },
    {
      "start": "00:19:56.830",
      "end": "00:19:56.840",
      "text": "bound and the upper performance bound is"
    },
    {
      "start": "00:19:56.840",
      "end": "00:19:59.270",
      "text": "bound and the upper performance bound is a bit more nuanced a bit more"
    },
    {
      "start": "00:19:59.270",
      "end": "00:19:59.280",
      "text": "a bit more nuanced a bit more"
    },
    {
      "start": "00:19:59.280",
      "end": "00:20:02.190",
      "text": "a bit more nuanced a bit more complicated to kind of understand but"
    },
    {
      "start": "00:20:02.190",
      "end": "00:20:02.200",
      "text": "complicated to kind of understand but"
    },
    {
      "start": "00:20:02.200",
      "end": "00:20:04.110",
      "text": "complicated to kind of understand but the best"
    },
    {
      "start": "00:20:04.110",
      "end": "00:20:04.120",
      "text": "the best"
    },
    {
      "start": "00:20:04.120",
      "end": "00:20:06.909",
      "text": "the best performance uh what we can actually"
    },
    {
      "start": "00:20:06.909",
      "end": "00:20:06.919",
      "text": "performance uh what we can actually"
    },
    {
      "start": "00:20:06.919",
      "end": "00:20:09.669",
      "text": "performance uh what we can actually get um I think it's better understood"
    },
    {
      "start": "00:20:09.669",
      "end": "00:20:09.679",
      "text": "get um I think it's better understood"
    },
    {
      "start": "00:20:09.679",
      "end": "00:20:12.510",
      "text": "get um I think it's better understood with an analogy um you don't expect"
    },
    {
      "start": "00:20:12.510",
      "end": "00:20:12.520",
      "text": "with an analogy um you don't expect"
    },
    {
      "start": "00:20:12.520",
      "end": "00:20:14.669",
      "text": "with an analogy um you don't expect every Committee Member to not make"
    },
    {
      "start": "00:20:14.669",
      "end": "00:20:14.679",
      "text": "every Committee Member to not make"
    },
    {
      "start": "00:20:14.679",
      "end": "00:20:17.950",
      "text": "every Committee Member to not make mistakes they will make mistakes but uh"
    },
    {
      "start": "00:20:17.950",
      "end": "00:20:17.960",
      "text": "mistakes they will make mistakes but uh"
    },
    {
      "start": "00:20:17.960",
      "end": "00:20:20.630",
      "text": "mistakes they will make mistakes but uh what you want to do is to have a"
    },
    {
      "start": "00:20:20.630",
      "end": "00:20:20.640",
      "text": "what you want to do is to have a"
    },
    {
      "start": "00:20:20.640",
      "end": "00:20:22.430",
      "text": "what you want to do is to have a committee that they don't make the same"
    },
    {
      "start": "00:20:22.430",
      "end": "00:20:22.440",
      "text": "committee that they don't make the same"
    },
    {
      "start": "00:20:22.440",
      "end": "00:20:24.990",
      "text": "committee that they don't make the same mistake at the same time so the"
    },
    {
      "start": "00:20:24.990",
      "end": "00:20:25.000",
      "text": "mistake at the same time so the"
    },
    {
      "start": "00:20:25.000",
      "end": "00:20:26.230",
      "text": "mistake at the same time so the so-called"
    },
    {
      "start": "00:20:26.230",
      "end": "00:20:26.240",
      "text": "so-called"
    },
    {
      "start": "00:20:26.240",
      "end": "00:20:29.430",
      "text": "so-called uncorrelated uh errors are are involved"
    },
    {
      "start": "00:20:29.430",
      "end": "00:20:29.440",
      "text": "uncorrelated uh errors are are involved"
    },
    {
      "start": "00:20:29.440",
      "end": "00:20:32.470",
      "text": "uncorrelated uh errors are are involved in uh sort of show showing some kind of"
    },
    {
      "start": "00:20:32.470",
      "end": "00:20:32.480",
      "text": "in uh sort of show showing some kind of"
    },
    {
      "start": "00:20:32.480",
      "end": "00:20:34.270",
      "text": "in uh sort of show showing some kind of a performance bound that that is kind of"
    },
    {
      "start": "00:20:34.270",
      "end": "00:20:34.280",
      "text": "a performance bound that that is kind of"
    },
    {
      "start": "00:20:34.280",
      "end": "00:20:37.310",
      "text": "a performance bound that that is kind of outside of the scope of this course but"
    },
    {
      "start": "00:20:37.310",
      "end": "00:20:37.320",
      "text": "outside of the scope of this course but"
    },
    {
      "start": "00:20:37.320",
      "end": "00:20:40.270",
      "text": "outside of the scope of this course but uh I think it's worthwhile um providing"
    },
    {
      "start": "00:20:40.270",
      "end": "00:20:40.280",
      "text": "uh I think it's worthwhile um providing"
    },
    {
      "start": "00:20:40.280",
      "end": "00:20:43.149",
      "text": "uh I think it's worthwhile um providing some kind of guidance as to where and"
    },
    {
      "start": "00:20:43.149",
      "end": "00:20:43.159",
      "text": "some kind of guidance as to where and"
    },
    {
      "start": "00:20:43.159",
      "end": "00:20:44.909",
      "text": "some kind of guidance as to where and how we will be able to achieve that"
    },
    {
      "start": "00:20:44.909",
      "end": "00:20:44.919",
      "text": "how we will be able to achieve that"
    },
    {
      "start": "00:20:44.919",
      "end": "00:20:47.870",
      "text": "how we will be able to achieve that upper bound uh so the the main three"
    },
    {
      "start": "00:20:47.870",
      "end": "00:20:47.880",
      "text": "upper bound uh so the the main three"
    },
    {
      "start": "00:20:47.880",
      "end": "00:20:49.510",
      "text": "upper bound uh so the the main three ways that we can achieve this kind of"
    },
    {
      "start": "00:20:49.510",
      "end": "00:20:49.520",
      "text": "ways that we can achieve this kind of"
    },
    {
      "start": "00:20:49.520",
      "end": "00:20:51.870",
      "text": "ways that we can achieve this kind of upper bound or try to achieve the best"
    },
    {
      "start": "00:20:51.870",
      "end": "00:20:51.880",
      "text": "upper bound or try to achieve the best"
    },
    {
      "start": "00:20:51.880",
      "end": "00:20:53.990",
      "text": "upper bound or try to achieve the best possible performance out of ample"
    },
    {
      "start": "00:20:53.990",
      "end": "00:20:54.000",
      "text": "possible performance out of ample"
    },
    {
      "start": "00:20:54.000",
      "end": "00:20:58.070",
      "text": "possible performance out of ample methods the first is the data component"
    },
    {
      "start": "00:20:58.070",
      "end": "00:20:58.080",
      "text": "methods the first is the data component"
    },
    {
      "start": "00:20:58.080",
      "end": "00:20:59.950",
      "text": "methods the first is the data component can we"
    },
    {
      "start": "00:20:59.950",
      "end": "00:20:59.960",
      "text": "can we"
    },
    {
      "start": "00:20:59.960",
      "end": "00:21:04.029",
      "text": "can we provide in some way uh different data to"
    },
    {
      "start": "00:21:04.029",
      "end": "00:21:04.039",
      "text": "provide in some way uh different data to"
    },
    {
      "start": "00:21:04.039",
      "end": "00:21:06.950",
      "text": "provide in some way uh different data to different of to the various kind of weak"
    },
    {
      "start": "00:21:06.950",
      "end": "00:21:06.960",
      "text": "different of to the various kind of weak"
    },
    {
      "start": "00:21:06.960",
      "end": "00:21:09.350",
      "text": "different of to the various kind of weak predictors that we have here so that we"
    },
    {
      "start": "00:21:09.350",
      "end": "00:21:09.360",
      "text": "predictors that we have here so that we"
    },
    {
      "start": "00:21:09.360",
      "end": "00:21:12.590",
      "text": "predictors that we have here so that we do not cause um exactly the same"
    },
    {
      "start": "00:21:12.590",
      "end": "00:21:12.600",
      "text": "do not cause um exactly the same"
    },
    {
      "start": "00:21:12.600",
      "end": "00:21:15.830",
      "text": "do not cause um exactly the same conclusion for each one of them so the"
    },
    {
      "start": "00:21:15.830",
      "end": "00:21:15.840",
      "text": "conclusion for each one of them so the"
    },
    {
      "start": "00:21:15.840",
      "end": "00:21:20.190",
      "text": "conclusion for each one of them so the second is to somehow randomize their"
    },
    {
      "start": "00:21:20.190",
      "end": "00:21:20.200",
      "text": "second is to somehow randomize their"
    },
    {
      "start": "00:21:20.200",
      "end": "00:21:22.110",
      "text": "second is to somehow randomize their operation um"
    },
    {
      "start": "00:21:22.110",
      "end": "00:21:22.120",
      "text": "operation um"
    },
    {
      "start": "00:21:22.120",
      "end": "00:21:27.269",
      "text": "operation um so"
    },
    {
      "start": "00:21:30.630",
      "end": "00:21:30.640",
      "text": "randomization is um the second kind of"
    },
    {
      "start": "00:21:30.640",
      "end": "00:21:32.669",
      "text": "randomization is um the second kind of approach there and I can actually can"
    },
    {
      "start": "00:21:32.669",
      "end": "00:21:32.679",
      "text": "approach there and I can actually can"
    },
    {
      "start": "00:21:32.679",
      "end": "00:21:34.230",
      "text": "approach there and I can actually can offer an example of"
    },
    {
      "start": "00:21:34.230",
      "end": "00:21:34.240",
      "text": "offer an example of"
    },
    {
      "start": "00:21:34.240",
      "end": "00:21:36.230",
      "text": "offer an example of randomization maybe we can actually"
    },
    {
      "start": "00:21:36.230",
      "end": "00:21:36.240",
      "text": "randomization maybe we can actually"
    },
    {
      "start": "00:21:36.240",
      "end": "00:21:39.630",
      "text": "randomization maybe we can actually offer a different um set of"
    },
    {
      "start": "00:21:39.630",
      "end": "00:21:39.640",
      "text": "offer a different um set of"
    },
    {
      "start": "00:21:39.640",
      "end": "00:21:42.470",
      "text": "offer a different um set of hyperparameters um sort of picked by"
    },
    {
      "start": "00:21:42.470",
      "end": "00:21:42.480",
      "text": "hyperparameters um sort of picked by"
    },
    {
      "start": "00:21:42.480",
      "end": "00:21:43.710",
      "text": "hyperparameters um sort of picked by some kind of"
    },
    {
      "start": "00:21:43.710",
      "end": "00:21:43.720",
      "text": "some kind of"
    },
    {
      "start": "00:21:43.720",
      "end": "00:21:46.789",
      "text": "some kind of distribution uh in this uh architecture"
    },
    {
      "start": "00:21:46.789",
      "end": "00:21:46.799",
      "text": "distribution uh in this uh architecture"
    },
    {
      "start": "00:21:46.799",
      "end": "00:21:50.909",
      "text": "distribution uh in this uh architecture see over here uh in in this course u in"
    },
    {
      "start": "00:21:50.909",
      "end": "00:21:50.919",
      "text": "see over here uh in in this course u in"
    },
    {
      "start": "00:21:50.919",
      "end": "00:21:52.750",
      "text": "see over here uh in in this course u in some other approaches where we have"
    },
    {
      "start": "00:21:52.750",
      "end": "00:21:52.760",
      "text": "some other approaches where we have"
    },
    {
      "start": "00:21:52.760",
      "end": "00:21:55.430",
      "text": "some other approaches where we have let's say uh decision trees involved in"
    },
    {
      "start": "00:21:55.430",
      "end": "00:21:55.440",
      "text": "let's say uh decision trees involved in"
    },
    {
      "start": "00:21:55.440",
      "end": "00:21:57.269",
      "text": "let's say uh decision trees involved in these predictors again for structure"
    },
    {
      "start": "00:21:57.269",
      "end": "00:21:57.279",
      "text": "these predictors again for structure"
    },
    {
      "start": "00:21:57.279",
      "end": "00:21:59.310",
      "text": "these predictors again for structure data I'm referring to then we can"
    },
    {
      "start": "00:21:59.310",
      "end": "00:21:59.320",
      "text": "data I'm referring to then we can"
    },
    {
      "start": "00:21:59.320",
      "end": "00:22:01.669",
      "text": "data I'm referring to then we can randomize their operation by picking"
    },
    {
      "start": "00:22:01.669",
      "end": "00:22:01.679",
      "text": "randomize their operation by picking"
    },
    {
      "start": "00:22:01.679",
      "end": "00:22:04.510",
      "text": "randomize their operation by picking different uh features that they split uh"
    },
    {
      "start": "00:22:04.510",
      "end": "00:22:04.520",
      "text": "different uh features that they split uh"
    },
    {
      "start": "00:22:04.520",
      "end": "00:22:07.830",
      "text": "different uh features that they split uh their uh sort of trees and there are so"
    },
    {
      "start": "00:22:07.830",
      "end": "00:22:07.840",
      "text": "their uh sort of trees and there are so"
    },
    {
      "start": "00:22:07.840",
      "end": "00:22:10.110",
      "text": "their uh sort of trees and there are so many approaches that are you know I"
    },
    {
      "start": "00:22:10.110",
      "end": "00:22:10.120",
      "text": "many approaches that are you know I"
    },
    {
      "start": "00:22:10.120",
      "end": "00:22:12.630",
      "text": "many approaches that are you know I guess too many to to quote over here but"
    },
    {
      "start": "00:22:12.630",
      "end": "00:22:12.640",
      "text": "guess too many to to quote over here but"
    },
    {
      "start": "00:22:12.640",
      "end": "00:22:14.110",
      "text": "guess too many to to quote over here but the third approach is a bit more"
    },
    {
      "start": "00:22:14.110",
      "end": "00:22:14.120",
      "text": "the third approach is a bit more"
    },
    {
      "start": "00:22:14.120",
      "end": "00:22:16.070",
      "text": "the third approach is a bit more relevant in this specific rest not"
    },
    {
      "start": "00:22:16.070",
      "end": "00:22:16.080",
      "text": "relevant in this specific rest not"
    },
    {
      "start": "00:22:16.080",
      "end": "00:22:25.470",
      "text": "relevant in this specific rest not architecture is to Simply use different"
    },
    {
      "start": "00:22:34.149",
      "end": "00:22:34.159",
      "text": "so the weak Learners that we called over"
    },
    {
      "start": "00:22:34.159",
      "end": "00:22:37.430",
      "text": "so the weak Learners that we called over here are uh involved in the rest net"
    },
    {
      "start": "00:22:37.430",
      "end": "00:22:37.440",
      "text": "here are uh involved in the rest net"
    },
    {
      "start": "00:22:37.440",
      "end": "00:22:41.430",
      "text": "here are uh involved in the rest net architecture and uh so here we have a"
    },
    {
      "start": "00:22:41.430",
      "end": "00:22:41.440",
      "text": "architecture and uh so here we have a"
    },
    {
      "start": "00:22:41.440",
      "end": "00:22:44.029",
      "text": "architecture and uh so here we have a predictor of some complexity we have"
    },
    {
      "start": "00:22:44.029",
      "end": "00:22:44.039",
      "text": "predictor of some complexity we have"
    },
    {
      "start": "00:22:44.039",
      "end": "00:22:46.190",
      "text": "predictor of some complexity we have here another"
    },
    {
      "start": "00:22:46.190",
      "end": "00:22:46.200",
      "text": "here another"
    },
    {
      "start": "00:22:46.200",
      "end": "00:22:49.110",
      "text": "here another predictor larger complexity and yet"
    },
    {
      "start": "00:22:49.110",
      "end": "00:22:49.120",
      "text": "predictor larger complexity and yet"
    },
    {
      "start": "00:22:49.120",
      "end": "00:22:51.549",
      "text": "predictor larger complexity and yet another predictor or even larger"
    },
    {
      "start": "00:22:51.549",
      "end": "00:22:51.559",
      "text": "another predictor or even larger"
    },
    {
      "start": "00:22:51.559",
      "end": "00:22:54.350",
      "text": "another predictor or even larger complexity we have effectively"
    },
    {
      "start": "00:22:54.350",
      "end": "00:22:54.360",
      "text": "complexity we have effectively"
    },
    {
      "start": "00:22:54.360",
      "end": "00:22:56.710",
      "text": "complexity we have effectively implementing um you know the third"
    },
    {
      "start": "00:22:56.710",
      "end": "00:22:56.720",
      "text": "implementing um you know the third"
    },
    {
      "start": "00:22:56.720",
      "end": "00:22:59.190",
      "text": "implementing um you know the third approach where we have um"
    },
    {
      "start": "00:22:59.190",
      "end": "00:22:59.200",
      "text": "approach where we have um"
    },
    {
      "start": "00:22:59.200",
      "end": "00:23:01.750",
      "text": "approach where we have um those different week Learners each one"
    },
    {
      "start": "00:23:01.750",
      "end": "00:23:01.760",
      "text": "those different week Learners each one"
    },
    {
      "start": "00:23:01.760",
      "end": "00:23:04.950",
      "text": "those different week Learners each one is offering a view and then uh finally"
    },
    {
      "start": "00:23:04.950",
      "end": "00:23:04.960",
      "text": "is offering a view and then uh finally"
    },
    {
      "start": "00:23:04.960",
      "end": "00:23:06.950",
      "text": "is offering a view and then uh finally the network is deciding based on the"
    },
    {
      "start": "00:23:06.950",
      "end": "00:23:06.960",
      "text": "the network is deciding based on the"
    },
    {
      "start": "00:23:06.960",
      "end": "00:23:10.070",
      "text": "the network is deciding based on the composition of those views okay so that"
    },
    {
      "start": "00:23:10.070",
      "end": "00:23:10.080",
      "text": "composition of those views okay so that"
    },
    {
      "start": "00:23:10.080",
      "end": "00:23:13.630",
      "text": "composition of those views okay so that has been shown to uh sort of provide"
    },
    {
      "start": "00:23:13.630",
      "end": "00:23:13.640",
      "text": "has been shown to uh sort of provide"
    },
    {
      "start": "00:23:13.640",
      "end": "00:23:15.669",
      "text": "has been shown to uh sort of provide performance advantages and and that's"
    },
    {
      "start": "00:23:15.669",
      "end": "00:23:15.679",
      "text": "performance advantages and and that's"
    },
    {
      "start": "00:23:15.679",
      "end": "00:23:17.870",
      "text": "performance advantages and and that's what we kind of had this discussion"
    },
    {
      "start": "00:23:17.870",
      "end": "00:23:17.880",
      "text": "what we kind of had this discussion"
    },
    {
      "start": "00:23:17.880",
      "end": "00:23:20.630",
      "text": "what we kind of had this discussion about and Sample methods and the third"
    },
    {
      "start": "00:23:20.630",
      "end": "00:23:20.640",
      "text": "about and Sample methods and the third"
    },
    {
      "start": "00:23:20.640",
      "end": "00:23:23.070",
      "text": "about and Sample methods and the third uh kind of Advantage I wanted to quote"
    },
    {
      "start": "00:23:23.070",
      "end": "00:23:23.080",
      "text": "uh kind of Advantage I wanted to quote"
    },
    {
      "start": "00:23:23.080",
      "end": "00:23:29.590",
      "text": "uh kind of Advantage I wanted to quote here for rest n is there scalability"
    },
    {
      "start": "00:23:30.750",
      "end": "00:23:30.760",
      "text": "so the"
    },
    {
      "start": "00:23:30.760",
      "end": "00:23:33.149",
      "text": "so the scalability um should be understood from"
    },
    {
      "start": "00:23:33.149",
      "end": "00:23:33.159",
      "text": "scalability um should be understood from"
    },
    {
      "start": "00:23:33.159",
      "end": "00:23:35.669",
      "text": "scalability um should be understood from the point of view of uh"
    },
    {
      "start": "00:23:35.669",
      "end": "00:23:35.679",
      "text": "the point of view of uh"
    },
    {
      "start": "00:23:35.679",
      "end": "00:23:39.669",
      "text": "the point of view of uh complexity um we are effectively able to"
    },
    {
      "start": "00:23:39.669",
      "end": "00:23:39.679",
      "text": "complexity um we are effectively able to"
    },
    {
      "start": "00:23:39.679",
      "end": "00:23:42.870",
      "text": "complexity um we are effectively able to have three six n or whatever number of"
    },
    {
      "start": "00:23:42.870",
      "end": "00:23:42.880",
      "text": "have three six n or whatever number of"
    },
    {
      "start": "00:23:42.880",
      "end": "00:23:45.029",
      "text": "have three six n or whatever number of uh residual blocks each one of them will"
    },
    {
      "start": "00:23:45.029",
      "end": "00:23:45.039",
      "text": "uh residual blocks each one of them will"
    },
    {
      "start": "00:23:45.039",
      "end": "00:23:49.870",
      "text": "uh residual blocks each one of them will actually be uh exactly the same um as uh"
    },
    {
      "start": "00:23:49.870",
      "end": "00:23:49.880",
      "text": "actually be uh exactly the same um as uh"
    },
    {
      "start": "00:23:49.880",
      "end": "00:23:52.269",
      "text": "actually be uh exactly the same um as uh you know any other block over here and"
    },
    {
      "start": "00:23:52.269",
      "end": "00:23:52.279",
      "text": "you know any other block over here and"
    },
    {
      "start": "00:23:52.279",
      "end": "00:23:54.390",
      "text": "you know any other block over here and therefore we are able to"
    },
    {
      "start": "00:23:54.390",
      "end": "00:23:54.400",
      "text": "therefore we are able to"
    },
    {
      "start": "00:23:54.400",
      "end": "00:23:55.990",
      "text": "therefore we are able to accommodate"
    },
    {
      "start": "00:23:55.990",
      "end": "00:23:56.000",
      "text": "accommodate"
    },
    {
      "start": "00:23:56.000",
      "end": "00:23:58.950",
      "text": "accommodate architectures that are have various"
    },
    {
      "start": "00:23:58.950",
      "end": "00:23:58.960",
      "text": "architectures that are have various"
    },
    {
      "start": "00:23:58.960",
      "end": "00:24:01.750",
      "text": "architectures that are have various various number of these blocks let's say"
    },
    {
      "start": "00:24:01.750",
      "end": "00:24:01.760",
      "text": "various number of these blocks let's say"
    },
    {
      "start": "00:24:01.760",
      "end": "00:24:06.470",
      "text": "various number of these blocks let's say we see resets with 18 layers 34 layers"
    },
    {
      "start": "00:24:06.470",
      "end": "00:24:06.480",
      "text": "we see resets with 18 layers 34 layers"
    },
    {
      "start": "00:24:06.480",
      "end": "00:24:12.909",
      "text": "we see resets with 18 layers 34 layers you know 50 layers 150 uh 102 layers"
    },
    {
      "start": "00:24:12.909",
      "end": "00:24:12.919",
      "text": "you know 50 layers 150 uh 102 layers"
    },
    {
      "start": "00:24:12.919",
      "end": "00:24:16.149",
      "text": "you know 50 layers 150 uh 102 layers even 150 layers these are the numbers"
    },
    {
      "start": "00:24:16.149",
      "end": "00:24:16.159",
      "text": "even 150 layers these are the numbers"
    },
    {
      "start": "00:24:16.159",
      "end": "00:24:18.789",
      "text": "even 150 layers these are the numbers that we have uh we have defined already"
    },
    {
      "start": "00:24:18.789",
      "end": "00:24:18.799",
      "text": "that we have uh we have defined already"
    },
    {
      "start": "00:24:18.799",
      "end": "00:24:20.549",
      "text": "that we have uh we have defined already existing architectures and this is kind"
    },
    {
      "start": "00:24:20.549",
      "end": "00:24:20.559",
      "text": "existing architectures and this is kind"
    },
    {
      "start": "00:24:20.559",
      "end": "00:24:23.269",
      "text": "existing architectures and this is kind of important when you have perception"
    },
    {
      "start": "00:24:23.269",
      "end": "00:24:23.279",
      "text": "of important when you have perception"
    },
    {
      "start": "00:24:23.279",
      "end": "00:24:25.870",
      "text": "of important when you have perception systems that need to comply to some"
    },
    {
      "start": "00:24:25.870",
      "end": "00:24:25.880",
      "text": "systems that need to comply to some"
    },
    {
      "start": "00:24:25.880",
      "end": "00:24:28.149",
      "text": "systems that need to comply to some realtime latency requirement evidently"
    },
    {
      "start": "00:24:28.149",
      "end": "00:24:28.159",
      "text": "realtime latency requirement evidently"
    },
    {
      "start": "00:24:28.159",
      "end": "00:24:30.470",
      "text": "realtime latency requirement evidently the larger the number of layers you have"
    },
    {
      "start": "00:24:30.470",
      "end": "00:24:30.480",
      "text": "the larger the number of layers you have"
    },
    {
      "start": "00:24:30.480",
      "end": "00:24:33.470",
      "text": "the larger the number of layers you have the longer the latencies that you are"
    },
    {
      "start": "00:24:33.470",
      "end": "00:24:33.480",
      "text": "the longer the latencies that you are"
    },
    {
      "start": "00:24:33.480",
      "end": "00:24:36.590",
      "text": "the longer the latencies that you are going to experience taking an image"
    },
    {
      "start": "00:24:36.590",
      "end": "00:24:36.600",
      "text": "going to experience taking an image"
    },
    {
      "start": "00:24:36.600",
      "end": "00:24:40.149",
      "text": "going to experience taking an image through this kind of pipeline so if we"
    },
    {
      "start": "00:24:40.149",
      "end": "00:24:40.159",
      "text": "through this kind of pipeline so if we"
    },
    {
      "start": "00:24:40.159",
      "end": "00:24:43.750",
      "text": "through this kind of pipeline so if we um have let's say a latency of let's say"
    },
    {
      "start": "00:24:43.750",
      "end": "00:24:43.760",
      "text": "um have let's say a latency of let's say"
    },
    {
      "start": "00:24:43.760",
      "end": "00:24:44.750",
      "text": "um have let's say a latency of let's say 80"
    },
    {
      "start": "00:24:44.750",
      "end": "00:24:44.760",
      "text": "80"
    },
    {
      "start": "00:24:44.760",
      "end": "00:24:48.430",
      "text": "80 MCS uh we can um and and therefore we"
    },
    {
      "start": "00:24:48.430",
      "end": "00:24:48.440",
      "text": "MCS uh we can um and and therefore we"
    },
    {
      "start": "00:24:48.440",
      "end": "00:24:51.630",
      "text": "MCS uh we can um and and therefore we are not able to accommodate 102 uh 102"
    },
    {
      "start": "00:24:51.630",
      "end": "00:24:51.640",
      "text": "are not able to accommodate 102 uh 102"
    },
    {
      "start": "00:24:51.640",
      "end": "00:24:53.269",
      "text": "are not able to accommodate 102 uh 102 layers where definitely going to be"
    },
    {
      "start": "00:24:53.269",
      "end": "00:24:53.279",
      "text": "layers where definitely going to be"
    },
    {
      "start": "00:24:53.279",
      "end": "00:24:56.190",
      "text": "layers where definitely going to be accommodating let's say 50 layers and"
    },
    {
      "start": "00:24:56.190",
      "end": "00:24:56.200",
      "text": "accommodating let's say 50 layers and"
    },
    {
      "start": "00:24:56.200",
      "end": "00:24:58.830",
      "text": "accommodating let's say 50 layers and the exactly the same technology exactly"
    },
    {
      "start": "00:24:58.830",
      "end": "00:24:58.840",
      "text": "the exactly the same technology exactly"
    },
    {
      "start": "00:24:58.840",
      "end": "00:25:02.430",
      "text": "the exactly the same technology exactly the same uh thinking um and behavior of"
    },
    {
      "start": "00:25:02.430",
      "end": "00:25:02.440",
      "text": "the same uh thinking um and behavior of"
    },
    {
      "start": "00:25:02.440",
      "end": "00:25:06.430",
      "text": "the same uh thinking um and behavior of rest Nets will uh be in either of the uh"
    },
    {
      "start": "00:25:06.430",
      "end": "00:25:06.440",
      "text": "rest Nets will uh be in either of the uh"
    },
    {
      "start": "00:25:06.440",
      "end": "00:25:08.149",
      "text": "rest Nets will uh be in either of the uh numbers quoted here in terms of number"
    },
    {
      "start": "00:25:08.149",
      "end": "00:25:08.159",
      "text": "numbers quoted here in terms of number"
    },
    {
      "start": "00:25:08.159",
      "end": "00:25:09.909",
      "text": "numbers quoted here in terms of number of layers so all of these three"
    },
    {
      "start": "00:25:09.909",
      "end": "00:25:09.919",
      "text": "of layers so all of these three"
    },
    {
      "start": "00:25:09.919",
      "end": "00:25:12.470",
      "text": "of layers so all of these three advantages are coming together to"
    },
    {
      "start": "00:25:12.470",
      "end": "00:25:12.480",
      "text": "advantages are coming together to"
    },
    {
      "start": "00:25:12.480",
      "end": "00:25:14.669",
      "text": "advantages are coming together to provide a fairly robust architecture has"
    },
    {
      "start": "00:25:14.669",
      "end": "00:25:14.679",
      "text": "provide a fairly robust architecture has"
    },
    {
      "start": "00:25:14.679",
      "end": "00:25:17.190",
      "text": "provide a fairly robust architecture has actually proven in the field in both"
    },
    {
      "start": "00:25:17.190",
      "end": "00:25:17.200",
      "text": "actually proven in the field in both"
    },
    {
      "start": "00:25:17.200",
      "end": "00:25:19.269",
      "text": "actually proven in the field in both real time and unreal time applications"
    },
    {
      "start": "00:25:19.269",
      "end": "00:25:19.279",
      "text": "real time and unreal time applications"
    },
    {
      "start": "00:25:19.279",
      "end": "00:25:23.190",
      "text": "real time and unreal time applications and able to uh extract uh features"
    },
    {
      "start": "00:25:23.190",
      "end": "00:25:23.200",
      "text": "and able to uh extract uh features"
    },
    {
      "start": "00:25:23.200",
      "end": "00:25:26.310",
      "text": "and able to uh extract uh features provide if you like representations on"
    },
    {
      "start": "00:25:26.310",
      "end": "00:25:26.320",
      "text": "provide if you like representations on"
    },
    {
      "start": "00:25:26.320",
      "end": "00:25:30.190",
      "text": "provide if you like representations on uh visual uh imagery that we have the"
    },
    {
      "start": "00:25:30.190",
      "end": "00:25:30.200",
      "text": "uh visual uh imagery that we have the"
    },
    {
      "start": "00:25:30.200",
      "end": "00:25:31.669",
      "text": "uh visual uh imagery that we have the the imageries that we are feeding into"
    },
    {
      "start": "00:25:31.669",
      "end": "00:25:31.679",
      "text": "the imageries that we are feeding into"
    },
    {
      "start": "00:25:31.679",
      "end": "00:25:34.679",
      "text": "the imageries that we are feeding into them"
    }
  ]
}