We have seen earlier the regression problem where we have effectively to model a conditional probability distribution at the output of our predictor. Now we are actually switching to a new task, it's a classification task where again we will solve this task using the Vaping block diagram. Again, we will need to model our predictor with a conditional probability distribution, but in classification, our target variables are distinct and discrete random variables rather than continuous. So in this kind of setting, I'll motivate the classification task with a simple use case. It is actually going to be called the radar problem and that's what we will start with next.
In this setting, the use case, the application we will see is a well-known application back in the Second World War, the Battle of England was won primarily from the erection of these towers. This was actually called the radar towers whose job it was to transmit a signal towards France where from France the Nazi airplanes were coming in to bomb London. Every time that the waveform was impinging into some large object in the sky like a plane, it was returning back into what we call the radar receiver. There was a kind of human operator over there in each kind of tower with access to a kind of telephone device. Every time that there was a strong return of a strong signal that was received in the radar receiver antenna, he was calling London and millions of people were sounding the sirens and running to the tube stations to save their lives.
This application is evidently present in any modern car today that has exactly the same ability to have radars located in the front of the car to send exactly the same signals. Every time that you have a feature in your car that is called automatic distance keeping to the vehicle in front of you, that is exactly the same thing. It was returning back that reflection from the car in front and the controller is actually trying to keep the velocities between your car and the car in front of you constant and therefore maintain a desired distance between the two cars. But anyway, I would motivate it with this sort of application which is the World War II application because also back then a lot of the terminology that we will cover today was also first invented.
Just to see exactly what is actually happening here, we have a kind of a time plot of a quantity that we will be calling X and it will be designating for us the strength of received signal strength or power. Very simplistically, we have some fluctuation received power when we have a return, a strong return from a plane, and in nights where we don't, the attacks were usually during the night, when we have no return we still have some fluctuating signal power much smaller than that. Our receiver is going to have just one knob, that knob is going to be called the threshold, we'll symbolize it with W. It's a scalar value that anything that exceeds it is going to let's assume that this threshold value is set to this kind of level, everything that exceeds it is going to be called predicted, that is well not predicted, is we're going to sound the alarm and anything that it is not exceeding it we are going to not alarm anyone, alert anyone and we will call that the no attack case. So our problem is a binary classification problem, what we call binary because our now target variable as compared to that regression can only take two values, one we will call this the so-called positive condition, the attack is going on, and zero we will be calling this the so-called negative condition.
And our job here now that we are in the 2020s, we are going to solve this problem of determining the value of that kind of threshold using kind of machine learning approaches. So we have what we will do is we will task a military person over here to sit and observe what is really happening every single day. So first night records the signal strength X1 and records also whether attack has happened or not X2 the same way and so on. If they survive, we will keep them, if they not, we have to replace them with somebody else. So XM, YM, that's our let's say we have aggregated M examples of what has happened at our receiver. And as before we progress into specifying what is really the problem statement, I just want to convey some kind of an intuitive fashion of what is happening. So this was the so-called attack signal strength and this was the no attack signal strength, the sort of time series of all these kind of observations night after night. And we have the problem to solve is to come up with an optimal value for the threshold. You can understand that the threshold is quite critical in determining whether how the system operates. If we set the threshold too high, this means that we will be missing quite a lot of attacks and evidently people will die. If we set the threshold too low, this means that we will be waking up everyone unnecessarily. The first night they will believe us and you know return to their beds disappointed somehow or relieved. The second night they will still believe us, they will go down to the tube but after the third night they will stop believing us and when a real attack happens, people will also die. So the system will lose complete credibility. So the choice of this W is quite critical. So our predictor, the Y hat that we have to predict at this moment in time, we will treat this as a one and zero, later will become a number between zero and one, is also going to return our prediction, predictor is going also to return one or zero for the positive and negative condition respectively.
Okay, so that is the problem statement, how to set up this W optimally. And as you can understand, I can just, after just before in the regression kind of problem, we had introduced the probabilistic nature of every predictor. So what we will now is we draw two probability distributions and let me just draw this probability distribution, let's say this. So this is a probability distribution of X, we have here on the x-axis our signal strength and one of them is going to be called the probability of X and when no attack is happening and this is the probability of X when the attack is happening. And as you can see, these two prob distributions can be easily obtained, as histograms by just going back to our data tape, the data set that we have created and recorded and select all the rows where the Y target variable is zero and obtain this histogram and visit all the corresponding rows where the Y is equal to one and plot this corresponding histogram. So in terms of plotting the histograms, this is definitely a very, I will call it an easy exercise. And as you probably notice from the shape of these histograms, we have not really made any assumption with respect to Gaussianity or nothing like that, they are definitely plotted as non-Gaussian type of probability distributions. And the moment I have, and also another sort of evident thing that is actually going on with this problem is that there is a very strong overlap between the two histograms when we have the signal strength between no attacks and attacks, as you can see also here from the time series plot, there's a quite significant overlap between the two. And that's of course due to properties of radio wave propagation, the waveform emitted from this kind of radar station can be pinched on the sea surface and go into some kind of other transverse other kind of paths. The so-called multipath fading situation, some of you may have observed fading while listening to analog radio stations such as AM and FM back in the old days, this were the only radio stations that we had access to. And also you may have sort of experienced exactly the same situation where you are going in and out of coverage holes using your cellular devices. The important thing about the sort of overlap is that let's assume that I have selected here a value for my W and the moment I have, if you like a threshold W, I can start clear defining certain areas under those probability distributions that will be of great interest to me. So I want to shade the first probability tail which is this one, I want also to shade this area and also want to shade with horizontal stripes this area. So these three areas are, I think, will be quite important. Now the overlap means that since there's no absolutely clear separation between the two prob distributions, we are always going to make some form of mistake, we always going to have mistakes. And in fact, we can clearly distinguish four conditions and we will tabulate them with what we call the confusion matrix. On the one axis of the confusion matrix, we'll be assigning this axis to the so-called ground truth and the other to the prediction, the Y hat. And when the Y hat is positive and negative and this positive and negative agrees to the with the ground truth, then we will be calling this correspondingly true positive and true negative. In fact, it's actually quite common to write first the letter, the second letter as a mnemonic rule, write first the second letter and put a word the letter T in front every time that you have agreement with ground truth. In the case where you predict there is an attack going on but you are wrong, you are prepending it with the letter F stands for false, so we have false positive here and here we have also false negative, we are predicting negative but we are wrong and therefore we have the so-called false negative events. The overlap as compared to the case which is quite unrealistic in practice where we have some form of significant separation between the two histograms like this and this and therefore it's easy to select something of a threshold W that will separate the two conditions perfectly, the so-called linearly separable case is not present here. So we are going to, so let me just delete it to avoid any confusion, is not present here. So we always going to have, in other words, these two type of events present in our problem.
And before I describe what was actually happening every time we get this threshold W to not be set optimally, when the threshold W is set too high, then we are missing the events that are actually attacks that are actually going will happen and therefore we are going to be increasing our false negative, so we are predicting that no attacks is happening while in fact they are. And if the W is set too low, we are going to be increasing the false positive rate and in fact, we will be alerting sort of the people to go down to the tube but unfortunately no attack is actually on. Now that we have recognized that we always going to make mistake as manifested by this confusion matrix, we are interested to just qualify these mistakes and quantify those mistakes by just understanding the probability of making a mistake. This is definitely the probability of when we make where our prediction Y hat is not equal to the ground truth Y and this is happens in two instances, the first instance is when we have the probability when we make the prediction that no attack is happening when in fact there is an attack plus the events when we are making the opposite claim. And I think it's worthwhile now trying to understand what is happening in this, what are those probabilities and how they related to these histograms we have plotted. The moment we have specified the threshold location over here W, we have split the region into two parts, the first region is called R0 and the second region is called R1 and now that we have this region names, I think the region names are also intuitively kind of understood because this zero index here corresponds to the case where we declare anything as we said below the threshold W, there's no attack, we are predicting no attack, so that's the what the zero is here and anything above the W, we have, we predicting attack is happening and that's why the one is there. We can actually start putting this probabilities, quantifying these probabilities based on the area under the those curves and we, I hope you all remember that probability for continuous random variables such as signal strength over here is sort of manifested by such kind of areas. So what I'm going to do now is I'm going to declare that this probability, the first probability over here is equal to the probability that I am making a prediction such as my X belongs to the region R0 when in fact the ground truth is one. So I converted the Y is equal to zero to all the events which are to the left of W, so all the events where X belongs to this kind of region are zero and the do the same belong to the region R1 when Y is equal to Z, all events of X greater than W, in other words all X's which are belonging to the region R1. So it is exactly equivalent to those convention that I had about what is Y hat is equal to one and what Y hat is equal to zero. So this one, the probability that X belongs to the region R0 when Y is one corresponds to the left tail of this probability distribution. So this probability distribution but only the left tail, so you can see here that the whole probability distribution here, the whole histogram is P of X, Y = to 1 but here I'm interesting only for the X equal to R0, so it's the summation of this vertically striped and this bubbly kind of area over there. So I am going to write it as an integral, probability of X, Y is = to 1 DX and I'm going to take this and actually do exactly the same for the R1, probability of X, Y is equal to 0 DX. And now if I actually start relating what I actually wrote here with the counts that I have counted, I can count through a random realization of this experiment from my kind of a looking at the predictor output and looking at the ground truth over here, I can understand that this is corresponds to the false negative rate and this corresponds to the false rate and definitely this is the false negative because I am actually predicting that no attack is happening and in fact I'm wrong and the corresponding here case where I'm predicting that the attack is happening and in fact I'm also wrong, so the false positive and the false negative, the false negative and the false positive are related to the entries of the confusion matrix here that are definitely present and countable using this kind of histograms. And as we discussed, our role here is to find the optimal W and I just want you to understand how visually we can be persuaded that is in fact there is an optimal W and that optimal W will minimize the probability of making the mistakes, you cannot make it zero because as we discussed we do not face in this situation linearly separable data set but at the very least we can minimize the summation of false positives and false negative events. And imagine that you are moving that W in the left side over here, so trying to move this line to the left and look what's happening, as you're moving into the left gradually, you will come, so maybe two snapshots are enough to see what is happening. So in the first value of this W to the left of the previous kind of W, what we are actually achieving is we are going to, whatever we are losing in terms of area out of our this vertically striped area, we will be gaining in terms of the horizontally striped area. Having said that, we actually start seeing reduction of this bubbly area and this area will start to be reduced and reduced and reduced up to the point where we reach what will be calling the W star, the optimal W and thus optimal W is the W that minimized this probability of mistake simply because in that location the bubbly area got eliminated completely and the summation of the therefore of the false positives and false negatives that included it is the minimum possible. So actually we can write that sort of optimizing the W towards W star will be using the well-known to us stochastic gradient descent algorithm that minimizes the probability of mistakes, probability of making a mistake, so the misclassification error or also misclassification error rate. So this will be done.
Now that we have some kind of a visual motivation of what we're trying to achieve here, we now need to understand how we can also motivate in the next discussion an objective function and that it is going to be suitable for our problem here which is the classification problem in a similar way as we have done with the earlier loss function we have used initially was called mean square error and then it was also called cross entropy. So we'll do that next, the come up with this objective function before we go and discuss that, review the so-called classification metrics. The classification metrics that there are a couple of classification metrics will be of interest to us, they will be entirely based of course on the previously described confusion matrix. And the first metric I want to address is called the true positive rate, the second metric is well the true positive rate is comes with many names and many of them have been sort of originating from various kind of domains, electrical engineering, computer science and others. So in computer science this also is called recall, in electrical engineering this is also called probability of detection and many other domains quote it as it's one and the same thing. And I just want to mention all of them just in case you come up with come across one of the of the many. So this is the ratio between true positive and true positive plus false negative. So this is a ratio that is definitely going to be of concern to us and of interest to us every time we have to evaluate a classifier. And the second metric that I want to quote and have some discussion about those metrics a bit later is a so-called precision. And this precision is another ratio of true positive divided by true positive plus false positive. And if you follow the this video where we have plotted these histograms in the binary classifier when the so-called the radar problem and you probably understood the tradeoff that exists between false positives and false negatives as we were moving, in fact the as we were moving the value of the threshold W, we were changing the areas under those two histograms and of course here we were trading all false positive or false negatives in our attempt to find this optimal kind of W. In a very similar way we can actually claim that now that we have the those metrics, the tradeoff between false positives and false negatives is evident over here in the following tradeoff. So let me write it this down, so we can say that because as W changes, there is a tradeoff between false positives and false negatives, we can actually claim that there is a between recall and precision because recall and precision everything is exactly the same in terms of numerator and portion of the denominator but only the false POS and false negatives are present there. So this is actually an important tradeoff that will be of great interest to us as we will always finding ourselves making that kind of tradeoff for classification architectures we will be designing soon. The other metric, it's not really a different metric but it's a way to present performance metrics, classification metrics is this what we call the so-called receiver operating characteristic and we actually call it receiver operating characteristic from those days in the 40s when they were deploying this kind of radars. And I will describe it as the curve that we can plot by changing the threshold W in the x-axis over here, it is the false positive rate also known as a false alarm from those days, the probability of the probability of false alarm PFA and the Y axis is called recall, evidently the same thing as a true positive rate and definitely we have a probability of false positive rate that goes from one from 0 to one and the probability of recall true positive
