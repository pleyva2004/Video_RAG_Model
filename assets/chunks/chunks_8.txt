To start understanding what is really the fundamental operation happening inside those convolutional neuron networks, let me just start with a simple problem. This problem goes as follows: I have somewhere in this kind of time axis a signal. This is the duration of this signal and the shape of the signal is not really important, but what is really important is the assumption that I do know the shape of that signal. Let's assume that I have, let's say, call this signal X of t and ask you the question as to can we come up with a method that we can sort of provide the location of that signal where about in this buffer, let's say U of the signal is located.
A simple kind of approach that we can think of is the following: since we know the shape of this kind of signal, I can actually start at the beginning of this buffer at this location, let's say zero, and for every position, hypothesize that the signal is located at this specific point and start making an operation that will effectively mean taking the dot product between the contents of that buffer and that signal. This means multiplying every element of this buffer with the amplitude, let's say the amplitude was one of the signal, and summing over all of the elements. So, if we do that, then it's a whole bunch of zeros times one, then we will be getting a result that it will be zero evidently.
We will be getting in fact all zeros results up to the point where we start having my hypothetical kind of a signal be right at the location of that true location of that kind of signal. After this point, as you can understand, we going to have some overlap between this signal and this, so we be starting getting some nonzero results out of this operation. Right where exactly the signal is located right under it, then we will start getting a peak and then evidently we'll start going back to zero and so on and so on. This is basically an approach if we take the AR Marx of what this kind of operation, this will be let's say the tau, the location that sort of indicates the sort of that we have predicted as far as this kind of signal is concerned.
What we just did is an example of what we call a one-dimensional correlation operation, cross-correlation operation because we are trying to correlate a hypothetical signal located in this hypoth over here against some other signal, the X of t. So, I will actually call this simplistically let's say Y of T. I'm actually correlating X of T and Y of T and this kind of correlation operation is able to retrieve for me in this simple one single dimensional kind of space the location of X of t. This is exactly what is been done in a kind of a two-dimensional and three-dimensional kind of space inside the convolution kind of neuron network.
In fact, now what we will do is we will expand into another example of where we have now this taxi image and we try to understand how we will be able to detect the presence of that kind of taxi in that image. But before we go there, I wanted to actually share with you some details in our site where we have, if you like, an Americal example confusingly the true sort of operation of what is actually called convolution is implemented inside the pytor tensor fls and so on all these kind of machine learning frameworks as correlation operations and with the exception that we actually flip the in the time domain that signal Y of t. We are, you know, the two operations as it actually clearly shown in your in your s l later on the two operations of convolution and cross-correlation result into identical results and for the purposes of our purposes from a pure implementation efficiency perspective we always prefer to implement them as cross-correlation despite the fact that we are referred to refer to them as convolution operations.
Let me go into the following kind of discussion now where we have we are going back to that kind of a taxi image and let me just write over here if I kind of try to squeeze it so this is our image that we have seen earlier with this Yellow Cab in the middle and here I have right in the middle a kind of a taxi. Okay, so all right, and I ask you exactly the same question: how we can potentially detect this kind of Taxi in this kind of image? Okay, all right, and maybe the, I mean if we have known the exact shape of this object like we have assumed earlier, then the operation actually would be straightforward. We'll take this template again, we'll call it Y now, and we will start sliding this kind of template across this kind of image to be able to at some point where the template is exactly present right on top of that U object in the image X, we will then declare that that's basically the location of that of that object.
The problem however is that in this kind of approach we have first assume that we will know exactly the shape of that object which is not realistic because the object is definitely going to vary quite a lot, let's say the object may be rotated, translated in sort of or being sort of because of the lighting condition maybe not sort of very evident it's exact shape, it's shadowed for example or uded by other objects and the other assumption is that in terms of computational efficiency the larger our kind of prototype is in terms of number of pixels the more expensive this kind of operation becomes. So in order to solve these two problems what we will do what we would suggest is we will not abandon this kind of sliding operation that we will called cross-correlation a bit earlier but if in fact what we will actually do now is we'll use a much smaller prototype and we are now pH the problem as to what is really the contents of that sort of prototype that we will be calling from now on a kernel.
Let me just draw the kernel over here and maybe I can start answering the question as to what should be the contents of this kernel that will be able to detect this cab over here. All right, so this image is extremely simple in fact it has zeros in these pixels and all the other pixels which we have not drawn anything are 255 so 255 corresponds to Pure White and zero corresponds to Black. So since I have a black and white image I can suggest that maybe if I can U have a Kel who's pixels so this is a kernel which is the size of that is not necessarily accidental it's 3x3 in this case and if I Locate over here in this pixels I made them let's say zeros and over here I made them 255 then you can all understand that as I'm sliding around this kind of Kernel I will definitely go and at some point hit this location over here with this kernel and at that moment in that location then I will be getting some definitely significant Peak if I may call it like that out of my cross-correlation operation.
We'll see the details the mathematical details of that cross-correlation operation shortly but that's basically what is going to happen then and so exactly the same thing will actually happen in this location and potentially in this type of locations and so on but I don't think that we have the complete story yet because I can suggest an additional kind of Kernel again it will be 3x3 and this kernel if it is sort of programmed to contain this type of information where now the black pixels are like this and the whites are over there they're kind of a diagonally then we will be able to pick up probably this feature over here where the wind screen is and so on and so on so we can actually suggest other kernels as well where we now have the other diagonal these wheels can be detected by having some something else some other kind of Kernel where maybe these guys will be need to be sort of colored like this colored in quotes or program like this with 255 and zeros and as you can understand all of these kernels if they are positioned at some point in this kind of image and I'll be calling now from now on this aggregation of kernels as a filter so filter for me will be this kind of a three-dimensional structure that it will have 3x3 let's say spatial coordinates so this is the spatial let me call it extent and it would have some kind of a depth D and this depth let's write depth is of course the number of Kels that I employ in this filter okay so over here that is basically a structure that I will see will be a fairly I call it useful for me to be able to detect now pixels sorry features from images.
And now let's see the mathematical description of what we have just described let me go back to the site and in that site we have the so-called two-dimensional the extension of the so-called two-dimensional cross-correlation operation and it's ex actually shown here in this kind of image this in this picture so we have an input image of pixels and we have a kernel of 2x2 in case and the Kel is going to be positioned on all possible locations in this image in this input image so in this specific case it is position at this moment in time this location over here and we are going to be forming the dot product between the kernel and the input image and evidently the dot product is a * W + B * x + e * y + f * z and that will actually be a scalar that it will give us the feature value extracted feature value out of that operation and we will do exactly the same thing over and over again we're going to slide the kernel into another location bcfg we'll do the dot product cdgh another dot product with it and to cut a long story short we are going to be getting a 2x3 output image and from now on we'll be calling this output images input and output images feature Maps because they are mapping the features that we have extracted with the usage of kernels here we see just a single kernel but in general we're going to have multiple kernels be involved in the shape and form of filters in these operations and so basically this is what we will be doing from now on and we will be sort of need to discuss next some architectural elements of you know this that are sort of encompassing this operation over here but also enhance it with further correlation type of structures inside convolution your Networks.
